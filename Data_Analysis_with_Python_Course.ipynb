{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed528722-ab4a-49f2-8fc1-218fbc02f00d",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td><p style=\"font-size:45px; color: #55BBD2\">Data Analysis with Python</p></td>\n",
    "    <td><img src=\"course_images/lmb_logo.svg\" alt=\"LMB Logo\" width=\"500\" height=\"600\" align=\"right\"></td>\n",
    "  </tr>\n",
    "</table>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><p style=\"font-size:15px; color: #55BBD2\">Version: May 2023</p></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d506e1f-4929-4ec6-a2cb-f5e6d9f38e17",
   "metadata": {},
   "source": [
    "# Licence\n",
    "\n",
    "This manual is © 2023, Steven Wingett\n",
    "\n",
    "This manual is distributed under the creative commons Attribution-Non-Commercial-Share Alike 2.0 licence. This means that you are free:\n",
    "\n",
    "•\tto copy, distribute, display, and perform the work\n",
    "\n",
    "•\tto make derivative works\n",
    "\n",
    "\n",
    "Under the following conditions:\n",
    "\n",
    "•\tAttribution. You must give the original author credit.\n",
    "\n",
    "•\tNon-Commercial. You may not use this work for commercial purposes.\n",
    "\n",
    "•\tShare Alike. If you alter, transform, or build upon this work, you may distribute the resulting work only under a licence identical to this one.\n",
    "\n",
    "Please note that:\n",
    "\n",
    "•\tFor any reuse or distribution, you must make clear to others the licence terms of this work.\n",
    "•\tAny of these conditions can be waived if you get permission from the copyright holder.\n",
    "•\tNothing in this license impairs or restricts the author's moral rights.\n",
    "\n",
    "Full details of this licence can be found at \n",
    "http://creativecommons.org/licenses/by-nc-sa/2.0/uk/legalcode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b2ad24-afe6-4f0f-a99c-7dbb23afa535",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Aim \n",
    "This course is intended for people who want to learn how to analyse data programmatically.  \n",
    "\n",
    "## Overview\n",
    "The course introduces the Python programming language and how its functionality can be extended with libraries such as **pandas** in order to manipulate, filter and perform statistical tests on datasets, as well as plot complex figures.\n",
    "\n",
    "## Prerequisites\n",
    "**Do I need to know how to program in Python already?**\n",
    "\n",
    "No, but having said that, completing a basic primer in the language would be helpful, before (or even after) attending this course.\n",
    "\n",
    "## Contents\n",
    "This course has four main subject areas:  \n",
    "\n",
    "1. Introducing Jupyter Notebooks as a way to write and document code as well as to share and present results.  \n",
    "\n",
    "2. Showing how specialist Python modules are used for manipulating datasets.\n",
    "\n",
    "3. How Python modules can be deployed for mathematical operations and statistical analyses.  \n",
    "\n",
    "4.  Presenting results using different plotting techniques. \n",
    "\n",
    "Although there will be a life sciences focus to some of the examples and exercises in this course, most of the concepts described are applicable to the vast majority of numerical disciplines.\n",
    "\n",
    "## Goals \n",
    "On completing the course, participants should be able to at least start analysing complex datasets they have generated themselves or have obtained from other sources.  By using these skills and learning more about the countless publicly available scientific Python modules, attendees should be able to tackle a wide range of real-world research challenges.  Specific goal included:\n",
    "\n",
    "* Learn how to handle and analyse large datasets encountered in life sciences research\n",
    "\n",
    "* Documenting code and analysis using Jupyter Notebooks\n",
    "\n",
    "* Share findings with other researchers\n",
    "\n",
    "* Learn about the Python analysis library pandas\n",
    "\n",
    "* Plotting complex figures with Seaborn and Matplotlib\n",
    "\n",
    "* Producing interactive charts with Plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1a15d8-c932-4f5f-b6cc-b4b161dd5188",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>A note on R</b>\n",
    "<br>\n",
    "<br>\n",
    "If you already use the programming language R, and the associated integrated development suite RStudio, much of this course will be familiar to you.  And indeed it should, for this course covers many of the same ideas used to program in R, although the syntax (language structure) is somewhat different.\n",
    "    \n",
    "An adequate comparison of R vs Python is beyond the scope of this course introduction, but in simple terms R was designed at its inception as a language for statistics and data manipulation.  Python is a general-purpose computing language to which modules have been added specifically for data analysis.  Most notable among these is the module **pandas** which we shall be using in this course.  The pandas module resembles the statistical language R a great deal.  \n",
    "    \n",
    "This of course beckons the question: which is best to learn?  Well, there is no clear winner.  Perhaps someone completely new to programming would be better learning R, since the barrier to entry is lower.  By that we mean that to use pandas effectively requires some knowledge of Python.  In contrast, someone starting out in R will be able to make data tables and plot graphs almost immediately.  On the other hand, using Python and pandas together is more versatile and arguably paves the way for the budding coder to write scripts applicable to a wider range of applications. \n",
    "    \n",
    "In practice however, for someone who wishes that coding will from a substantial component of his or her research output, knowledge of both languages is probably required.  It is quite common for example, to have to use other people’s scripts which could have been written in either R or Python.  In addition, both languages can make use of modules which import a range of functionality, but these modules are often \"tied\" to one particular programming language.  A case in point is the RNA-seq differential calling package DESeq2 which requires R.  In contrast, the machine learning suite Keras needs Python.   \n",
    "    \n",
    "So, in summary, there are pros and cons to each language and in the end it is often down to the individual user to decide which one is preferred.  Learning either language is, however, a good way to start using programmatic data analysis techniques.\n",
    "    \n",
    "Since by attending this course you have made a decision to learn more about Python, you should be pleased to learn that within a just a few hours you can expect to be able to perform fairly sophisticated data analyses using this language.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731991f9-d61d-44fa-99f0-2a1e5a465d97",
   "metadata": {},
   "source": [
    "# JupyterLab\n",
    "\n",
    "## JupyterLab overview\n",
    "You may be familiar already with how to write and run scripts using a text editor.  While this is certainly adequate, it is not the smoothest way to handle experimental data.  A much better way to do this is provided by **Project Jupyter (https://jupyter.org)** which was designed explicitly for interactive data science and scientific computing.\n",
    "\n",
    "To provide some background: Project Jupyter is a non-profit open-source initiative, which began with IPython (Interactive Python) back in 2014 when the IPython notebook was re-branded under the Jupyter name.  The name itself is a reference to the core programming languages supported by Jupyter:  Julia, Python, and R.  Although, it is probably fair to say that Jupyter is best associated in people's minds with Python.  \n",
    "\n",
    "The **Jupyter Notebook** is an intuitive web-based application that scores in the area of research science, for it allows programmers to create and share documents that contain live code, equations, plots and formatted descriptive text.  \n",
    "\n",
    "When most people think of Jupyter they tend to think of the Jupyter Notebook, but for this course we will be using another web-based tool named **JupyterLab**.  Its central component is still the Jupyter Notebook, but it contains additional features useful in data science.\n",
    "\n",
    "## Installing JupyterLab\n",
    "We assume that you are proficient at installing applications on your own machine and so shan’t talk you through all the installation options on a multiplicity of different operating systems.  Besides, this is already well documented on the Jupyter website: https://jupyter.org/install.  \n",
    "\n",
    "If that online overview doesn’t help, then please refer to the extensive official Jupyter documentation: https://jupyterlab.readthedocs.io/en/stable/getting_started/installation.html\n",
    "\n",
    "In fact, reading the aforementioned instructions may not be necessary at all, since a **pip install** (the Python package installer) will often suffice:\n",
    "\n",
    "    python3 -m pip install jupyterlab\n",
    "\n",
    "(This of course needs Python3 pre-installed.)\n",
    "\n",
    "\n",
    "\n",
    "## Starting and closing JupyterLab\n",
    "\n",
    "### Laptop / desktop installations\n",
    "To start JupyterLab, open a command line environment on your computer.  This should be familiar to Linux users, but on Mac it is the Terminal application and on Windows it the MS-DOS program (i.e. the same environment you used to install Jupyter Lab).\n",
    "\n",
    "To start JupyterLab, enter in the command line\n",
    "\n",
    "    jupyter-lab\n",
    "\n",
    "This command should start a web-server on your machine and open your default web browser (e.g. Chrome, Firefox or Internet Explorer) which should then display the JupyterLab application.  You will need to keep the command line environment window open, since closing it will terminate the web server and end your JupyterLab session.\n",
    "\n",
    "### Anaconda\n",
    "It is worth mentioning at this point that you can also obtain JupyterLab by installing the data science platform **Anaconda**.  Anaconda has open source and free editions and is worth checking out: https://www.anaconda.com.  You may find that it contains far too many packages for your needs, or alternatively it may be ideal for you - allowing you to install most of the software you will ever need in one simple install.\n",
    "\n",
    "Double-click on the Anaconda Navigator icon to open the scientific software suite.  From within there, you should be able to see the JupyterLab logo.  Click the associated \"Launch\" button to open the software.  If you don't see the JupyterLab badge on the Navigator start-up page, then change the \"Channels\" drop-down options to check if it is already installed, or needs installing from within Anaconda.\n",
    "\n",
    "\n",
    "### LMB Servers\n",
    "People enrolled on this course should have an account set up on the LMB's JupyterHub server.  To login, use a machine that **can access the LMB's intranet.**  Go to the following intranet page and enter your username and password:\n",
    "http://10.91.193.124/hub/login\n",
    "\n",
    "Once you have logged-in, your browser URL bar will display something similar to:\n",
    "\n",
    "http://10.91.193.124/user/swingett/tree\n",
    "\n",
    "Manually type in the URL bar changing \"tree\" to \"lab\" and then press enter.  This should open JupyterLab.\n",
    "\n",
    "Once you have done that, download this course material into your folder, which can be done by clicking the following: link/command:\n",
    "\n",
    "http://10.91.193.124/hub/user-redirect/git-pull?repo=https://github.com/StevenWingett/data-analysis-with-python-course&branch=no-answers&app=lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580eb35f-5f04-43b2-aa19-16b087ceb3ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## Exercise 1\n",
    "\n",
    "**a1.** Open JupyterLab (using JupyterHub on the LMB's intranet, or on your local machine.)\n",
    "\n",
    "**a2.** Open the course notebook by clicking on the link given to you.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c78e4ac-a401-45b4-8646-25bc7b382f53",
   "metadata": {},
   "source": [
    "## Navigating JupyterLab\n",
    "\n",
    "The JupyterLab interface comprises three components:\n",
    "1. a main work area containing tabs of documents and activities.\n",
    "2. a collapsible left sidebar containing a file browser, the list of running kernels and terminals, the command palette, the notebook cell tools inspector, and the tabs list.\n",
    "3. top-level menus that expose actions available in JupyterLab with their keyboard shortcuts.\n",
    "\n",
    "We shall discuss in more detail about each of the menus as we describe more about using the various features of JupyterLab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f359fa-d2e9-4398-96ae-9ddc5eaa1f34",
   "metadata": {},
   "source": [
    "<img src='course_images/jupyter_lab_screenshot.png' alt='Alt text' title='Title text'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59618913-4187-426c-9483-16eb230ef249",
   "metadata": {},
   "source": [
    "## Jupyter Notebook\n",
    "\n",
    "Jupyter Notebook is the centrepiece of JupyterLab and it is the main reason why most users install JupyterLab.  (Of course, Jupyter Notebook is also available as a much-used standalone product.)  The application provides a convenient way to write executable code, alongside descriptive text and accompanying graphs and charts.  We shall begin by discussing how to embed Python code.\n",
    "\n",
    "### Creating a New Notebook\n",
    "\n",
    "The Jupyter Notebook layout should be quite intuitive to those familiar with common Desktop applications.  A new document may be opened from the top-level drop-down menu:\n",
    "\n",
    "*File -> New -> Notebook*\n",
    "\n",
    "Also, take a quick look to notice the other options available from the File drop-down menu.  As you may expect, it is from this *File* drop-down menu that you will be able to save Notebooks and open pre-existing Notebooks.\n",
    "\n",
    "### Notebook structure\n",
    "\n",
    "A newly created Notebook will be displayed in the main window.  The Notebook comprises one or more multi-line text input fields termed **cells**.  \n",
    "\n",
    "There are three types of cells: \n",
    "\n",
    "1. code cells - for writing and executing Python code.\n",
    "    \n",
    "2. markdown cells - for writing formatted text, commonly used to explain the code and data.\n",
    "    \n",
    "3. raw cells - for unformatted text which will not be rendered by the Jupyter Notebook.\n",
    "\n",
    "Newly created cells are by default code cells, but may be changed to another type by using a drop-down on the toolbar.  These different cell types have different properties, as described below\n",
    "\n",
    "#### Code cells\n",
    "A code cell allows you to write Python code and has the benefit of syntax highlighting and tab completion.  This code may then be run interactively by pressing **<kbd>Shift</kbd> + <kbd>Enter</kbd>**, or by clicking the **Play** button in the toolbar or **Run** in the menu bar.  \n",
    "\n",
    "Executed code is sent to the Jupyter **kernel** (computing environment) associated with the Notebook and the results returned are displayed in the Notebook as a given cell’s output. The output is typically text but may take the forms, including graphs and HTML tables.\n",
    "\n",
    "Try running the Code Cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4532207-fa12-4d3d-8d66-265b8a586c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This is a Code Cell')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0d41e8-b0f7-4771-9e6b-9613aabf4722",
   "metadata": {},
   "source": [
    "Now is a good time to mention that Code Cells may contain **comments** as well as code.  The hash (#) symbol is used to distinguish comment lines from code lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7733f4-1e68-4885-aa48-b8fb849c1863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a comment line\n",
    "print('This is a code line')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787ef436-e419-4af8-9394-c13148be0dfb",
   "metadata": {},
   "source": [
    "#### Markdown cells\n",
    "Markdown is a **lightweight markup language** that you can use to add formatting to text documents.  As such, these cells provide a good way to include descriptive text, headings and section breaks etc. in a Notebook.\n",
    "\n",
    "Indeed, this cell is a markdown cell and is rendered accordingly.  For example, placing a word between pairs of double asterisks will render the word in **bold**.\n",
    "\n",
    "The following cell gives further details or alternatively, [click here the canonical documentation on Jupyter markdown usage.](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d301c01-2a67-41ec-8e19-1457a28a8d1b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<b>Commonly used markdown</b>\n",
    "    \n",
    "    # Heading 1 \n",
    "    \n",
    "    ## Heading 2\n",
    "    \n",
    "    ## Heading 2.1\n",
    "    \n",
    "    ## Heading 2.2\n",
    "    \n",
    "    *italics*\n",
    "    \n",
    "    **bold**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19118e1e-4b56-4f14-8581-b3a2bc4d4fdc",
   "metadata": {},
   "source": [
    "### Command Mode and Edit Mode\n",
    "When running Jupyter Notebook you can either select **Command Mode** or **Edit Mode**.  The current mode of the Notebook is displayed with a text message at the bottom bar of the JupyterLab window (so long as the status bar is displayed).\n",
    "\n",
    "**Command Mode:** you are able to edit the Notebook, but not type into individual cells.  Most importantly, in Command Mode, the keyboard is mapped to a set of shortcuts that let you perform notebook and cell actions efficiently. For example, if you are in command mode and you press <kbd>C</kbd>, you will copy the current cell.  Enter command mode by pressing <kbd>ESC</kbd> or using the mouse to click an area outside of any of the cells.\n",
    "\n",
    "**Edit Mode:** when a cell is in Edit Mode, you can type into the cell in a similar fashion to a standard text editor.  To enter Edit Mode simply click the cell that needs editing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76187a97-8562-40ac-955f-0fc3a0bc1ee4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<kbd>ESC</kbd> Command Mode view\n",
    "    \n",
    "<kbd>ENTER</kbd> Cell Mode view.\n",
    "\n",
    "<kbd>A</kbd> when in command mode, inserts a cell above the currently selected cell.\n",
    "\n",
    "<kbd>B</kbd> when in command mode, inserts a cell below the currently selected cell.\n",
    "\n",
    "<kbd>D</kbd><kbd>D</kbd> pressing D twice in a quick succession in command mode deletes the currently selected cell. \n",
    "\n",
    "---\n",
    "\n",
    "Jupyter Lab gives you an option to change your <b>cell type</b> when in command mode.  You can use <kbd>M</kbd> to change current cell to a markdown cell, <kbd>Y</kbd> to change it to a code cell and <kbd>R</kbd> to change it to a raw cell.\n",
    "\n",
    "---\n",
    "\n",
    "<kbd>SHIFT</kbd> + <kbd>M</kbd> merges multiple selected cells into one cell. \n",
    "\n",
    "<kbd>CTRL</kbd> + <kbd>SHIFT</kbd> + <kbd>-</kbd> splits the current cell into two cells from where your cursor is located. \n",
    "\n",
    "<kbd>SHIFT</kbd> + <kbd>J</kbd> or <kbd>SHIFT</kbd> + <kbd>DOWN</kbd> selects the next cell in a downward direction.  This assists in making multiple selections of cells.\n",
    "\n",
    "<kbd>SHIFT</kbd> + <kbd>K</kbd> or <kbd>SHIFT</kbd> + <kbd>UP</kbd> selects the next cell in an upwards direction. This assists in making multiple selections of cells.\n",
    "\n",
    "<kbd>CTRL</kbd> + <kbd>/</kbd> helps you by either commenting or un-commenting any line in the Jupyter lab. For this to work, you don’t even need to select the whole line for it will comment or un-comment the line where your cursor is positioned. If you want to do it for more that one line then you will need to first select all the lines that need changing and then use this shortcut.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2409de-fd77-498d-9aec-a81621749435",
   "metadata": {},
   "source": [
    "### Executing cells\n",
    "As discussed previously, code cells may be executed by clicking a cell and pressing <kbd>SHIFT</kbd> + <kbd>ENTER</kbd>.  Alternatively, users may select an option from the *Run* menu.  \n",
    "\n",
    "**Importantly, cells may not run in the order that they appear in the notebook.  The run order is denoted by the numbers next to the cells.**  Also, values are kept in memory after running cells.\n",
    "\n",
    "To reset all these values and the run order, you will need to restart the kernel (*Kernel -> Restart Kernel*)\n",
    "\n",
    "### Special Notebook commands\n",
    "Now we shall look at a range of useful Notebook-specific commands that may be entered into cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f9ecab-0d1f-4aca-89db-ebb4c2088dfc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>A note on Objects</b>\n",
    "\n",
    "You will encounter the term <b>object</b> the more you read about computing.  There are technical definitions as to what constitutes an object.  For the purposes of this course, an object can be thought of as a variable, data structure, function or a method.  Essentially these are ways of storing information and instructions on how to process information.  In fact, Objects may be hybrids of both these terms and contain data and instructions on how to process data.  \n",
    "\n",
    "The take-home message is simply to be aware that much of the computing terminology you encounter is often bundled together under the umbrella term: object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a90f72-24b0-4b12-b349-0350b684f4ed",
   "metadata": {},
   "source": [
    "#### Magic commands\n",
    "Magic commands are commands that can only be run in the Jupyter Notebook (i.e. are separate from the Python language) and extend the functionality of a Notebook. There are are two types of magic commands:\n",
    "\n",
    "**Line magics** - preceded by % and are written on a single line of code\n",
    "\n",
    "**Cell magics** - preceded by %% and encompass an entire cell\n",
    "\n",
    "For example, the line magic **%history** returns the command history of a Notebook, whereas **%who** lists all the names (or variables) currently in memory, or the line magic **%pwd** will print the path of the current working directory.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bec34d-13f2-40fc-a55c-e0b12fa05869",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4f5e1f-faf3-402e-91b6-f6eecf82a285",
   "metadata": {},
   "source": [
    "The **%%writefile** cell magic is used to write the contents of a cell to an external file, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1be8ad-0fd3-4372-b04b-de6d090d4958",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile hello.py\n",
    "print(\"This code is written to hello.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a53d02e-f40b-4f24-9545-0480df680785",
   "metadata": {},
   "source": [
    "To list all the magic commands enter: `%lsmagic`\n",
    "\n",
    "#### Shell commands\n",
    "Many magics have functionality that otherwise would require the Linux command line (in which user types out instructions for the Linux operating system to execute).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73793b0e-dc9e-4b40-ba8e-8cc1a23786ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85922845-ec2e-403c-b44e-fe1b0cf8da30",
   "metadata": {},
   "source": [
    "If however a shell command is required, these can be run directly from a Jupyter Notebook by prefixing them with an exclamation mark: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee2dc3d-f035-4cff-83f9-181a6d9db9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls *.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c0b900-1b06-43da-8020-468e380231c7",
   "metadata": {},
   "source": [
    "Again, don't worry if you are unaware what a shell command is.  The point was included as it may be useful for people already familiar with using a command line environment.\n",
    "\n",
    "#### Installing Python modules via Jupyter Notebook\n",
    "It is possible to perform a wide variety of calculations and manipulations using Python.  This capability is extended substantially by making use of **libraries**, **packages** and **modules**.  \n",
    "\n",
    "These make available to the user a much greater range of data types, functions, and methods.  You will need to import a module before you can use it.  Suppose you wish to install a Python library named \"plotly\", you can achieve this by typing the following in a code cell: \n",
    "\n",
    "    import plotly\n",
    "\n",
    "If executing this code generates no output to the screen, then this means that the module has been successfully imported.  In contrast, you may be presented with an error message, similar to that displayed below:\n",
    "\n",
    "    #ModuleNotFoundError\n",
    "\n",
    "If that is the case, then the required module needs installing into the version of Python used by Jupyter.  Once installed, you should not need to install it again.  \n",
    "\n",
    "Installing plotly can be achieved by typing and running the following in a code cell: \n",
    "\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install plotly\n",
    "\n",
    "This imports the `sys` module which is then used to run `pip`, the bespoke Python module installer.  There will be a flurry of output to the screen on initiating an installation, which should hopefully end with some kind of success message.\n",
    "\n",
    "Running the cell code below will install Python modules required for this course.  Once you have done that you are good to go and you should not have to install these packages again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4f4bbe-201b-42c1-9afc-e3c612e9c536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install plotly\n",
    "!{sys.executable} -m pip install seaborn\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed88262-368b-4d8f-81be-1bd0cbf052b3",
   "metadata": {},
   "source": [
    "### Embedding items in a Notebook\n",
    "#### Tables\n",
    "Later in this course we shall discuss how to store data in special data structures resembling tables.  These data structures may be embedded in a Jupyter Notebook, as shown below.  Again, don’t be concerned by some of the unfamiliar code below as we shall discuss this in more detail shortly, but just pay attention to the rendering of the table embedded in the Notebook.  (Note that for brevity’s sake not all 150 rows of the table are shown and consequently the ellipsis symbol (…) denotes the gap in the output.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a38647-bb5d-4150-b6c7-8047b5e7468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "iris = sns.load_dataset('iris')\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7536d1cb-bfad-4944-94c5-4222bc34b924",
   "metadata": {},
   "source": [
    "#### Embedding graphs\n",
    "The example below uses the module matplotlib to plot the iris data.  This will render beneath your Python code a scatter plot of the sepal width vs the sepal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b01fb2-2c18-463d-9329-942058c2c7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris = sns.load_dataset('iris')\n",
    "x = iris.sepal_length\n",
    "y = iris.sepal_width\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ed775f-1e4b-423b-b335-168733e70d23",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### LaTeX\n",
    "LaTeX is a popular way to embed mathematical formulae in documents. LaTeX can be embedded in markdown cells by surrounding latex code with the dollar symbol ($), for example:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5002e66f-36f8-42ea-a1f1-92fcc1658a97",
   "metadata": {
    "tags": []
   },
   "source": [
    "Euler's Identity: $e^{i\\pi} + 1 = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dddca11-53dc-4772-b79c-2431a08c23a6",
   "metadata": {},
   "source": [
    "Euler's Identity: $e^{i\\pi} + 1 = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22a61b8-d3a3-49f9-977f-9dce7a6dfa67",
   "metadata": {},
   "source": [
    "Expressions can be rendered on their own separate line by surrounding the LaTex code with a pair of dollar symbols ($$):"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5fd9c5f6-bc4b-428d-950b-e0c8a5bb28c2",
   "metadata": {},
   "source": [
    "Euler's Identity: $$e^x=\\sum_{i=0}^\\infty \\frac{1}{i!}x^i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c27878-0011-417f-979b-22d7c4999c3b",
   "metadata": {},
   "source": [
    "Euler's Identity: $$e^x=\\sum_{i=0}^\\infty \\frac{1}{i!}x^i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26eaa17-ee05-4059-860b-db37361928f6",
   "metadata": {},
   "source": [
    "#### HTML\n",
    "\n",
    "Use the **%%html** magic to embed html code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91295549-6ccc-471f-a826-4fc316949e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<iframe src=\"https://jupyter.org/\", width=100%, height=500>\n",
    "</iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66ec946-8639-4814-9c27-fb5deb6b83de",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sharing and collaboration with Jupyter Notebooks\n",
    "More often than not when producing a Notebook you will want to show your findings to somebody else, or indeed you may want to work with someone else on the same project.  Jupyter lends itself well to this.\n",
    "\n",
    "#### Creating HTML documents\n",
    "A simple and easy way to do this is to convert your Notebook to a regular read-only HTML file that can be viewed by the end-user.  Do this using the drop-down top menu:\n",
    "\n",
    "*File -> Export Notebook As… -> Export Notebook to HTML*\n",
    "\n",
    "This will generate an HTML file that may be shared with others.\n",
    "\n",
    "\n",
    "#### Github\n",
    "Individuals can make their Notebooks available online or collaborate on the same project by using a Git repository website (such as GitHub).  Indeed, there is already an interesting collection of Jupyter Notebooks already posted on that website: https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks\n",
    "\n",
    "#### Google Colab\n",
    "Another location where Jupyter Notebooks can be shared is Google Colab.  Take a look at this single cell RNA-seq analysis to get an idea of what can be achieved in a Jupyter Notebook: https://colab.research.google.com/github/buettnerlab/scanpy_demo/blob/main/tutorial_scanpy_basics.ipynb?hl=en#scrollTo=GSZEq9ZnWdjq\n",
    "\n",
    "\n",
    "### Other JupyterLab features\n",
    "\n",
    "#### Text editor\n",
    "Jupyterlab contains a basic text editor to write plain text documents, or write Python code (in fact the text editor highlighting is compatible for a wider range of languages).\n",
    "\n",
    "#### Markdown editor\n",
    "Markdown is a lightweight markup language that you can use to add formatting elements to plain text documents. \n",
    "\n",
    "#### Python console\n",
    "Code consoles enable you to run code interactively in a kernel. The cells of a code console show the order in which code was executed in the kernel, as opposed to the explicit ordering of cells in a notebook document. Code consoles also display rich output, just like notebook cells.\n",
    "\n",
    "#### Command line shell\n",
    "JupyterLab terminals provide full support for system shells (bash, tsch, etc.) on Mac/Linux and PowerShell on Windows. You can run anything in your system shell with a terminal, including programs such as vim or emacs. The terminals run on the system where the Jupyter server is running, with the privileges of that user.\n",
    "\n",
    "#### Viewing character-delimited datafiles\n",
    "JupyterLab has an application to view datafiles comprising rows and columns of data in which columns are separated by a pre-defined delimiter (e.g. tab-delimited files and comma-separated files).  This application was written to handle enormous datafiles (far larger than those that can be handled by Excel for example).\n",
    "\n",
    "#### Viewing images\n",
    "If you double click on an image file (e.g. JPEG or PNG) in the file browser menu, you will open an image viewer.  You can move the image in the window using the mouse pointer.  Also, you can zoom in/out with the keys <kbd>=</kbd> / <kbd>-</kbd> respectively.  You can also rotate right/left with the <kbd>[</kbd> and <kbd>}</kbd> keys respectively.  The key <kbd>0</kbd> will reset the image. \n",
    "\n",
    "#### Extension manager\n",
    "Software plug-ins developed by the Jupyter community can be installed into Jupyter (click the \"jigsaw-shape\" icon in the left-hand side toolbar).  The extension manager allows free-text searches to aid in the identification of potential useful plug-ins.  One such popular plugin is \"jupyterlab-variableInspector\" which is broadly analogous to the Environment window in RStudio.\n",
    "\n",
    "Installing an extension is often simply a matter of clicking the relevant install button, but sometimes additional software may need to be installed on your system before this can be carried out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c2a92b-fcd5-49db-bf81-060d0075750b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Alternatives to JupyterLab and Jupyter Notebook</b>\n",
    "<br>\n",
    "<br>\n",
    "The Jupyter Project produces the most widely used software for viewing, interacting with, editing and creating these Notebooks.  However, there are alternative ways to do this.  Probably the best option is <b>Visual Studio Code</b>.  Thanks to an active developer marketplace this text editor has a wide and growing range of functionality, including compatibility with Jupyter Notebooks.\n",
    "<br>\n",
    "<br>\n",
    "The software's homepage is at: <a href=\"https://code.visualstudio.com\">https://code.visualstudio.com</a   \n",
    "<br>\n",
    "<br>\n",
    "Although Microsoft develops the application it is free to use and available on Windows, Mac and Linux systems.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50abece2-74c5-458a-b49f-9e6c885781ed",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## Exercise 2\n",
    "\n",
    "**a1.** Open a new notebook.\n",
    "\n",
    "**a2.** In the first cell on the notebook enter the code:\n",
    "\n",
    "`print('Hello World!')`\n",
    "\n",
    "Then run the cell.  What do you see?\n",
    "\n",
    "**a3.** Create a new cell and convert it to a markdown cell.  Enter the text:\n",
    "\n",
    "`This is regular font`\n",
    "\n",
    "`*This is in italics*`\n",
    "\n",
    "`**This is in bold**`\n",
    "\n",
    "`` `This is in-code highlighting` ``\n",
    "\n",
    "`# Heading1`\n",
    "\n",
    "`## Heading2`\n",
    "\n",
    "`### Heading3`\n",
    "\n",
    "Then run the cell.  What do you see?\n",
    "\n",
    "**a4.** Move the markdown cell to the top of the notebook.\n",
    "\n",
    "**a5.** Copy the first cell and convert it to raw format.  Run the cell.  What is the output?\n",
    "\n",
    "**a6.** Delete the cell you have just made.  \n",
    "\n",
    "**a7.** Save the notebook in your current directory and name it: \"course_exercises.ipynb\".  \n",
    "\n",
    "**a8.** Close the notebook.\n",
    "\n",
    "<hr>\n",
    "\n",
    "**b1.** Re-open the notebook you have just made and run the following magic command in a code cell.  What is it telling you?\n",
    "\n",
    "`%pwd`\n",
    "\n",
    "**b2.** Copy and paste the code below into cell and run the cell.  What do you see?\n",
    "\n",
    "    import seaborn as sns\n",
    "    df = sns.load_dataset(\"penguins\")\n",
    "    df   \n",
    "    \n",
    "    \n",
    "    \n",
    "**b3.** Copy and paste the code below into a cell and run the cell.  What do you see?   \n",
    "\n",
    "    sns.pairplot(df, hue=\"species\")\n",
    "\n",
    "\n",
    "**b4.** Export this notebook as an HTML file.\n",
    "\n",
    "<hr>\n",
    "\n",
    "**c1.** Using the file navigator menu in JupyterLab, look in the folder \"course_exercises_data/exercise2\"\n",
    "\n",
    "You should be able to see files in there.\n",
    "\n",
    "**c2.** Open the file \"data.tsv\" with JupyterLab.  What is the data?\n",
    "\n",
    "**c3.** Open the file \"image.svg\" with JupyterLab.  What is the image?  Can you rotate the image and zoom-in / zoom-out?\n",
    "\n",
    "<hr>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a56ea9-990d-4d98-9193-7d4cb5d2254b",
   "metadata": {},
   "source": [
    "# Python you need to know\n",
    "\n",
    "Ideally you will be familiar already with the syntax of the Python language and this chapter will be a brief reminder of the Python terms used in this course.  If you are not familiar with Python, this chapter will help you understand key Python concepts you will need.\n",
    "\n",
    "The Python Homepage which provides the language's canonical documentation is found at: https://www.python.org.\n",
    "\n",
    "## Data types and expressions\n",
    "### Integers (`int`)\n",
    "Integers in Python have the same meaning as in mathematics: these are numbers with no values after the decimal point and can be positive, negative or zero.  For example: 10, 23 and -18 are all integers.  In contrast: 1.5, -0.2 and $\\sqrt2$ are not integers, since they have values after the decimal point.\n",
    "\n",
    "Integers can be manipulated by operators.  The **addition (+) and subtraction (-) operators** will be familiar to you from basic maths.\n",
    "\n",
    "Calculations can be performed in Jupyter Notebook cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106699e7-a3ab-4eae-9285-ca4760d49022",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bed894d-6fce-4198-ad3d-c979b97cad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "3 - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d21929-9803-4654-b3ce-6b317b9e63e5",
   "metadata": {},
   "source": [
    "Python can also perform multiplication.  The multiplication symbol used by Python is not the same as used in standard maths textbooks, for it is an asterisk (*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32936859-da83-474c-bae4-061262688598",
   "metadata": {},
   "outputs": [],
   "source": [
    "5 * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3d6969-fd68-4377-8a7b-f9c199670c1d",
   "metadata": {},
   "source": [
    "Furthermore, it is possible in Python to raise a number to a given power. This is denoted by a **double asterisk operator (\\**)**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cfd829-900e-4d2e-9c60-42d06e41a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "5 ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53eb37d-e10a-43b6-88cc-a562bd1ce98b",
   "metadata": {},
   "source": [
    "### Floats (`float`)\n",
    "Floats - or to use the full term: “floating point numbers\" - are used by computers to store non-integer numbers.\n",
    "\n",
    "Floats have two components: the **significand** and the **exponent**.  The former stores the significant numbers (which can be positive or negative), while the exponent defines the position of the decimal place.  For example, the value 0.5 has a significand of 5 and an exponent of -1.  \n",
    "\n",
    "(In fact, integer values may be represented as floats, for example 1000 would have a significant of 1.0 and an exponent of 3, but storing integers in this way uses more of the available memory than simply storing as an `int` datatype.)\n",
    "\n",
    "Having said all this, you generally won’t notice any difference when entering floats in the Jupyter Notebook as compared to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b751c1fe-dcc3-4991-99bf-9f5041e4bae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A float: significand:1, exponent: -1\n",
    "0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdd9cac-2c72-4bcb-802f-31dd6ffd7e41",
   "metadata": {},
   "source": [
    "One noteworthy difference is that floats may be entered using scientific notation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cb393e-764b-4433-ab62-6460b48b6f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "3.0E-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3ff842-fbcf-43b3-bcae-15480568985f",
   "metadata": {},
   "source": [
    "Floating point numbers are particularly important with regards to division.  This is because most division operations (even those involving only integers) will return fractional values and thus a `float`.  Indeed, division operations in Python always return the `float` type (even if the value returned is not fractional).\n",
    "\n",
    "To divide in Python, use the forward slash (/) character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f163628-d82b-44c2-8f3d-4f8bdf7db743",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ce63f1-b7b4-41f2-a128-fd69aab9679a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**A note on floats**\n",
    "\n",
    "Many numbers cannot be reported with infinite precision using standard decimal notation.  For example, one-third is represented as 0.33333 recurring, but since we cannot store an infinite number of 3s in memory, the stored value will only an approximation to one-third.\n",
    "\n",
    "In a similar vein, computers work in binary (base 2) and there are seemingly simple decimal values that cannot be stored with complete precision in binary.  For example, the value 0.1 is stored as 0.10000000000000000555 (to 20 decimal places) in Python.  Floats are accurate to around 17 decimal places, but look out for these slight inaccuracies when performing calculations.\n",
    "\n",
    "Warning: these tiny discrepancies do not cause a problem in almost all situations, but do be careful when checking if two results exactly equal one another when working with floats\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6f74fb-d402-4dae-839e-83fbf6e1856b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compound expressions\n",
    "All the expressions so far listed involve one operator and one value, but a single expression may contain many values and expressions.  Here is a simple example involving only integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f5ab38-96bf-4426-a04d-86e564c42e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "5 + 5 * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a9f8d7-edaa-4597-8057-8389ad39ff2d",
   "metadata": {},
   "source": [
    "If one performed the above calculation in a left-to-right order, the answer would be 30 and not 20 (i.e. 5 + 5 = 10 and then 10 * 3 = 30).  \n",
    "\n",
    "However, Python follows **orders of precedence** and will perform the multiplication before the addition (which are the formal rules in mathematics).  Thus, 5 * 3 = 15.  Then add 5, which makes 20. You could of course learn the rules of precedence and write code accordingly, but virtually no programmer does this.  \n",
    "\n",
    "The way around this extra complexity is to use parentheses in your code.  The expression inside the parentheses is evaluated first and then this is passed to values outside the parentheses.  Python also allows nested parentheses (brackets within brackets), which are useful in complex expressions.  Don’t worry about using multiple parentheses in your code; in fact, their inclusion should help make your code easier to read.\n",
    "\n",
    "Consequently, you could re-write the above expression as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4823d0-6297-45f4-ad47-626044b36d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(5 + 5) * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75520d2a-aa69-4d94-ba87-231c13cd437e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Strings (`str`)\n",
    "\n",
    "These store Unicode characters, whether that is a letter, number or a symbol of some kind.  Essentially, they constitute a “string” of characters – although a solitary single character is also classified as a string.  \n",
    "\n",
    "To create a string you will need to enclose your text within either single or double quotation marks.  Double and single quotation marks have the same meaning in Python and you are free to use either, but the opening and closing quotes need to be of the same type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0653c07-01d1-4ef8-9b96-648e66ed9447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a string with single quotation marks\n",
    "'abcde12345'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34124160-2d10-4be7-b594-edef0ba19346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a string with double quotation marks\n",
    "\"abcde12345\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d610a8c-b8fd-4cf5-8388-7b6efca921cb",
   "metadata": {},
   "source": [
    "Placing numbers between quotation marks will create a string, not a numerical datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00647c8f-f561-4383-bd62-1a4076b40222",
   "metadata": {},
   "outputs": [],
   "source": [
    "'12345'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae59eb9-2a5b-4c66-9cb5-ad5dfa025ebc",
   "metadata": {},
   "source": [
    "Although you may think of plus (+) as to be used solely with numbers, in Python it can also be used to concatenate (i.e. join) strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff95ca65-c559-4015-bd66-bed40bf8a496",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Love' + 'Marriage'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69cedcb-a8e8-4275-bd06-4f5ebce69371",
   "metadata": {},
   "source": [
    "In a similar fashion, the multiplication operator can be used on strings. Multiplying a string by an integer causes the string to be repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07b5e4c-4ae9-458f-ad29-8a19e6039db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Go forth ' * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d914ad-f585-4641-a560-5cf1042115e4",
   "metadata": {},
   "source": [
    "### Booleans (`bool`)\n",
    "The Boolean datatype has only two values: `True` or `False`.  Boolean values are generated when performing logical evaluations using **comparison operators**.  This term may sound quite formal, but you are no doubt already familiar with many of these operators from school-level maths.\n",
    "\n",
    "| Comparison Operator | Description |\n",
    "| --------------------| ----------- |\n",
    "|          ==         | If the values of two operands are **equal**, then the condition is `True` | \n",
    "|          !=         | If values of two operands are **not equal**, then the condition is `True` |\n",
    "|           >         | If the value of left operand is **greater than** the value of right operand, then the condition is `True`   |\n",
    "|           <         | If the value of left operand is **less than** the value of right operand, then the condition is `True`  |\n",
    "|           >=        | If the value of left operand is **greater than or equal to** the value of right operand, then the condition is `True`  |\n",
    "|          <=         | If the value of left operand is **less than or equal to** the value of right operand, then the condition is `True`  |\n",
    "\n",
    "For all of the above, if the condition is not met then the returned value is `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45c0669-8aa8-4765-a204-4fb6a4f0d5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015f7b23-3c3f-4447-8062-b420bc0f8c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67920b67-7030-4378-8f9b-c77738d46084",
   "metadata": {},
   "outputs": [],
   "source": [
    "2 > 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afdd393-627c-4430-82f5-6ba91b62f81e",
   "metadata": {},
   "source": [
    "Please note that `True` or `False` values are case sensitive.  Not following this syntax will raise an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ed40f7-7a6a-43e7-a3b5-1f450b0fc6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f868af-d1cc-4013-af98-5515fe3e9bb5",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "# Raises exception (tagged cell with 'raises-exception')\n",
    "true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55317376-7f53-4716-a59e-005c11957f46",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>A note on Error Messages</b>\n",
    "<br>\n",
    "<br>\n",
    "If a mistake is encountered on executing a cell, the Jupyter Notebook will return an error message detailing the problem (such as shown above).  These Error Messages are shaded in red and should be read keenly as they should, at least in-part, explain why a bloc of code failed to run successfully.\n",
    "\n",
    "Sometimes you may be presented with a Warning Message instead of an Error Message.  Code returning a Warning Message will have run to completion, but you are being made aware of a potential problem with you code.  For example, sometimes Warning Messages alert programmers to forthcoming changes to the Python language that when instigated will render the current code invalid.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b23577-5c08-44ad-92ea-21915133f09a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "## Exercise 3\n",
    "\n",
    "Calculate in code cells:\n",
    "\n",
    "**a1.** Five plus seven (5 + 7)\n",
    "\n",
    "**a2.**\tEight minus ten\n",
    "\n",
    "**a3.** Nine multiplied by eleven\n",
    "\n",
    "**a4.** Minus fifteen divided by three\n",
    "\n",
    "**a5.** Three cubed\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "Calculate in code cells:\n",
    "\n",
    "**b1.** The square root of 2 (remember: determining the nth root of a number is the same as raising that number to the power of 1/n).\n",
    "\n",
    "**b2** One trillion is 1,000,000,000,000.  Multiply 3.2 trillion by 2.5.  To simplify this calculation, use scientific notation to represent a trillion.\n",
    "\n",
    "**b3** Determine the value in grams of 2.3 picograms multiplied by 45.3.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Write **one-line expressions** to do the following comparisons.  The answer should be a **boolean** value.\n",
    "\n",
    "**c1.** Evaluate whether 0 is equal to -0\n",
    "\n",
    "**c2.**\tEvaluate whether 10 is not equal to 10.000\n",
    "\n",
    "**c3.** Evaluate whether (856 * 7) is greater than (864 * 7.2)\n",
    "\n",
    "**c4.** Is 9 / 3 less than or equal to 33 / 11?\n",
    "\n",
    "<hr>\n",
    "    \n",
    "Use a code cell to write **one-line expressions** to calculate the following (use parentheses to make the calculations more readable):\n",
    "\n",
    "**d1.**  I buy 5 sandwiches at £1.20 and 8 rolls at £2.15.  How much will they all cost?\n",
    "\n",
    "**d2** One thousand pounds is shared equally between 20 men and 30 women.  How much does each person receive?\n",
    "\n",
    "**d3** I work for 3 hours at £15.20 per hour, 9 hours at £17.45 per hour and 2 hours at £24.00 per hour.  I then pay 20% income tax on the money earned.  How much money do I take home?    \n",
    "    \n",
    "<hr>    \n",
    "\n",
    "**e1.** Concatenate the following strings into a single one-line string: \\\n",
    "Con \\\n",
    "cat \\\n",
    "en \\\n",
    "ate\n",
    "\n",
    "**e2.** Concatenate the phrase “To be or not to be” from its constituent words (think about how to create the spaces between words).\n",
    "\n",
    "**e3.** Write a single-line expression that comprises the following phrase 20 times: \"All work and no play makes Jack a dull boy\". (You don't need to type out the phrase 20 times!)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acd5a81-e5be-4e07-9b0f-4da6d3e26b2e",
   "metadata": {},
   "source": [
    "## Names, functions and methods\n",
    "You are probably already aware that in algebra letters are used to represent numbers.  This idea is a central concept of Python and is achieved using an assignment statement.  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7d9094-203c-4b01-9ed4-1bcfa90799e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2208182-f987-4716-a643-06476755e4ab",
   "metadata": {},
   "source": [
    "This assigns the **name (or variable)** `a` to the value 1.  Names can be assigned to integers, strings and other data types.  As you may expect, when assigning to a string you will need to surround your string with quotation marks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792b721b-9f2b-4381-9b41-7817de5f56b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 'Text'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02240ca7-a5b7-4230-8268-74daff52d5e9",
   "metadata": {},
   "source": [
    "Notice that nothing is displayed on the line after your input text.  This is because what you have entered is a **statement**, which unlike expressions in the previous section, **do not return values**. \n",
    "\n",
    "If you now type `a` or `b` in a cell, you will see the value of that name is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de72b311-1331-45ce-9990-1e340338aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14947d9-fc36-40c2-807f-9cf140a16efe",
   "metadata": {},
   "source": [
    "It is possible to assign a name to an existing name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b8f89f-a3bb-4403-9769-97e9d40799e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = b\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ced8cb-ad05-4822-a6e9-3956e24f0222",
   "metadata": {},
   "source": [
    "Another useful feature of Python is that it is possible to assign a name to a value as it is being calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720ab3da-3b95-4633-ac25-ef09b49c67bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 10 * 5\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851e39eb-a4b0-4804-adff-8a72efe0959b",
   "metadata": {},
   "source": [
    "This is an important concept in programming languages, for it now means that names may be manipulated as one would manipulate the values to which they are assigned.  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b26bd2-d1eb-4f05-a363-4b4961b8b4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "b = 2\n",
    "c = a + b\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3443f54c-7d69-4ca6-aaa4-a913fc506140",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "### Functions overview\n",
    "Previously in this course we came across the following Python command:\n",
    " \n",
    "    print(\"Hello World!\")\n",
    "\n",
    "This is an example of a function.  A function comprises several components: firstly, every function has a name, which in this case is \"print\".  \n",
    "\n",
    "Following the function name comes a pair of brackets.  There may be nothing between these brackets, or alternatively there may be one or more items termed **arguments**.  In this example, the argument passed to the print function is the \"Hello World!\" string.  If there is more than one argument, they should be separated from one another using commas.  \n",
    "\n",
    "Every function returns a value.\n",
    "\n",
    "Also, take note of what happens when passing a variable to this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc432686-371f-44c8-a841-bdb396b05d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forPrinting = 'Print Me!'\n",
    "print(forPrinting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac792fa5-b37d-488b-ae6f-f18eab4e5800",
   "metadata": {},
   "source": [
    "The string 'Print Me!' is assigned to the name `forPrinting`.  Calling the function `print()` with the argument `forPrinting` causes the **value** associated with that name to be printed to the screen.\n",
    "\n",
    "The `print()` function is one of Python’s **built-in functions**.  There are many other built-in functions.  The function `len()` for example returns the length of a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15632918-8e7c-4b6f-bdfd-cac57411c772",
   "metadata": {},
   "outputs": [],
   "source": [
    "len('Supercalifragilisticexpialidocious')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29098d38-b01b-4f4d-aaf5-483c9ad91dcb",
   "metadata": {},
   "source": [
    "### Functions and data types\n",
    "\n",
    "We have discussed already that there are different datatypes in Python (i.e. `int`, `float`, `str`,…).  Up until now we have not been able to ascertain directly the data type of a given object.  However, this is possible using the `type()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaed3d2-ee27-41d2-99b6-f8ca0b38447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(378163771)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9ba1a7-68ad-4e3e-961c-0c4688ee4c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "type('Hello World!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8135b8-b24e-4bc6-96dd-be2c698c0342",
   "metadata": {},
   "outputs": [],
   "source": [
    "type('378163771')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10375075-4ded-49b1-baca-5de3e25c8c94",
   "metadata": {},
   "source": [
    "That may be all well and good, but should we really care how Python is storing these values?  Well the answer is yes!  Suppose we have the integer 378163771 stored as a string.  Any numerical calculations we want to do with this will then fail.  To get around this we would need to convert a string to a number and then perform our numerical operations.  This process of converting one datatype to another is called **casting**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adbe39c-dcc5-40a6-847e-0e57849954fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "int('378163771') - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755c58f0-094c-43f8-b8e5-e63a1e2657d3",
   "metadata": {},
   "source": [
    "In this example we have converted a string to an integer, but we could of course converted to a float.  \n",
    "\n",
    "Casting in python is therefore done using constructor functions:\n",
    "\n",
    "`int()` - constructs an integer\n",
    "\n",
    "`float()` - constructs a float\n",
    "\n",
    "`str()` - constructs a string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8e8d7c-526a-4ac9-bab2-364805c3a21c",
   "metadata": {},
   "source": [
    "### Methods\n",
    "Methods are very similar to functions.  Specific data types in Python have the capability to run different methods.  To call (execute) the method, simply place a **dot** after the name of the datatype and then enter the method name.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e3b33-8611-4111-a9a4-41fe4f39ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'abracadabra'.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e90166-11be-4877-aa18-b25584d02ba7",
   "metadata": {},
   "source": [
    "Similar to functions, **methods may also take arguments**.  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6b979f-0bc5-48e1-ac76-35df19ef9296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of 'a'\n",
    "'abracadabra'.count('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023be43b-0c48-4bf5-b413-bd40a861defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "magic = 'abracadabra'\n",
    "magic.count('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274b12fe-c1f4-408e-af20-053c60e4ba57",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>A note on functions, methods, arguments and parameters</b>\n",
    "<br>\n",
    "<br>\n",
    "    \n",
    "As we have learnt already, <b>functions</b> and <b>methods</b> define blocks of code that run when they are called.  Collectively functions and methods are known as <b>calls</b>.  The difference between a method and a function is that methods are associated with Python objects, but functions are not.\n",
    "    \n",
    "Some calls can be passed values termed <b>arguments</b>.  These arguments are taken by the call and their values are assigned to <b>parameters</b>.\n",
    "\n",
    "To prevent ambiguity if a call accepts more than one argument, the order in which the arguments are passed is used to set the parameters.  Consider the following method:\n",
    "    \n",
    "<code>np.random.normal(0.0, 1.0, 100)</code>\n",
    "\n",
    "This generates 100 (size) randomly selected number from a Normal distribution which has a mean value of 0 (loc) and a standard deviation of 1.0 (scale). \n",
    "\n",
    "Alternatively, parameters may be named explicitly when making a call. Importantly, argument order is not important when making calls in this way e.g. the calls below are equivalent to one another and the call made previously:\n",
    "\n",
    "<code>np.random.normal(loc=0.0, scale=1.0, size=100)</code>\n",
    "\n",
    "<code>np.random.normal(size=100, scale=1.0, loc=0.0)</code>\n",
    "\n",
    "Naming the parameters to which arguments are to be assigned is more verbose, but it can be easier to comprehend when dealing with more complex functions and methods.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8e6615-242e-4859-b9b2-a1eddbf330b5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## Exercise 4\n",
    "\n",
    "**a1.** Check the datatype returned for each of the following calculations:\\\n",
    "10 * 3\\\n",
    "22 / 7\\\n",
    "'10' * 3\n",
    "\n",
    "**a2.** Convert the result of '10' * 3 into an integer and then check it is an integer.\n",
    "\n",
    "<hr>\n",
    "\n",
    "**b1.**  Assign the following DNA sequence to a variable named `dna`:\n",
    "GATATCTAGTCTTCTGATAGAGATCTGATGGGGATTATTATAGCTTCTGATCGGTTT\n",
    "\n",
    "**b2.** Display the sequence using the `print()` function on the newly created variable `dna`.\n",
    "\n",
    "**b3.** What is the length of the DNA sequence? (Hint: use the `len()` function)\n",
    "\n",
    "**b4.**  How many times does the BglII restriction site AGATCT occur in the sequence? (Hint: we already covered this method). \n",
    "\n",
    "**b5.** Convert the sequence to lower case. (Hint: We've not covered this method yet, but its name is intuitive.) \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12be94f2-41ed-44a0-b501-a5e5f2287fa9",
   "metadata": {},
   "source": [
    "## Collections\n",
    "We  discussed previously the **primitive data types** found in Python which are useful in a wide number of situations but are nevertheless not adequate for the more complex tasks performed by software.  \n",
    "\n",
    "This section describes the compound data types that contain multiple objects in structures called **collections** (or sometimes containers - although this should not be confused with specialist container software such as Docker). Each object in a collection is referred to as an **element** or **item**.   Becoming familiar with their usage will enable you to dramatically increase the range of tasks to which you can code solutions.  Commonly used collections include sets, tuples, generators, ranges, lists and dictionaries.  \n",
    "\n",
    "**We shall discuss ranges, lists, tuples and dictionaries in this section.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bc765e-635a-4358-a306-a695c2c2d494",
   "metadata": {},
   "source": [
    "### Lists\n",
    "Lists constitute a **mutable ordered sequence** of any type of element.  The code below shows how to create a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a96b536-9921-4213-9694-c0ea56fd83da",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3]\n",
    "print(a)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893ca2ac-7cf0-4d96-8b2b-721b67812a04",
   "metadata": {},
   "source": [
    "You may reference a specific element in a list using an indexing system.  The first index has a value 0, then next index has the value 1 and so on.  Place the index value between square brackets to access the item at that position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4c761c-f95e-4119-84c4-964fa2a9ce67",
   "metadata": {},
   "outputs": [],
   "source": [
    "beatles = ['John', 'Paul', 'George', 'Pete']\n",
    "print(beatles[0])\n",
    "print(beatles[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429a3647-0d2c-456d-be80-f3a8054519f5",
   "metadata": {},
   "source": [
    "Since lists may be changed after they have been created, there are assignment expressions or methods that are used to modify a list.  In fact, there is actually a wide variety of ways to modify a list, an example of which is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99033539-52f5-4922-b619-b51d79bc28d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "beatles = ['John', 'Paul', 'George', 'Pete']\n",
    "beatles[3] = 'Ringo'\n",
    "beatles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d06907a-8786-42d8-ac50-475de7af3ddd",
   "metadata": {},
   "source": [
    "It is possible to view more than one list entry simultaneously.  In the example below, the second, third and fourth elements are returned from the list.  The values 1:3 means return values at position 1 (the second element in the list) and all values **up to, but not including** 3.  \n",
    "\n",
    "Using the **colon operator** to retrieve contiguous values is known as **slicing**.  This concept will be encountered at multiple points in this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7351cc-8084-4871-9f5e-1b3585a111a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "beatles[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869e0a5d-5470-4faf-bc4b-ec4589d76d2d",
   "metadata": {},
   "source": [
    "It is also worth knowing that some methods modify a data structure directly, without the need of the assignment operator.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8304cb-9699-466f-9f11-2c803e52189d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Slicing</b>\n",
    "<br>\n",
    "<br>\n",
    "Slicing data is a concept in Python that comes up again and again in different contexts.  The syntax to do this is to place square brackets after the ordered data structure that is to be sliced.  Inside that bracket enter the position (indexing starts at 0) or positions of the data to be returned.\n",
    "\n",
    "`data[0]` - return data at index 0 (first position)\n",
    "\n",
    "`data[1]` - return data at index 1 (second position)\n",
    "\n",
    "Use negative values to start at the end of the ordered data:\n",
    "    \n",
    "`data[-1]` - return last data value\n",
    "    \n",
    "`data[-2]` - return second-to-last data value\n",
    "\n",
    "The colon operator (`:`) is used to specify contiguous positions.  The further examples below illustrates how this works:\n",
    "\n",
    "`data[0:4]` - select from index 0 to (but not including) index 4\n",
    "    \n",
    "`data[:4]` - this is a abbreviation of the previous slice and demonstrates that ommitting a starting number is interpreted as start from the beginning of the list\n",
    "    \n",
    "`data[2:]` - similarly, this means take a slice from index 2 until the end of the list\n",
    "\n",
    "This notation can also be used to increment by a constant value:\n",
    "\n",
    "`data[0:4:2]` - select from index 0 to (but not including) index 4, in increments of 2\n",
    "\n",
    "<img src='course_images/slicing.svg' title='Splicing'/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037c71d1-e17c-4c98-ac7f-93189a4190f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "beatles.sort()\n",
    "beatles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b55803-91ba-44d9-8c34-11f5f6dd1dad",
   "metadata": {},
   "source": [
    "Another important point that you may have noticed is that the `sort()` method has not returned a value, instead the original `beatles` list was sorted directly.  The list does not have to be re-assigned to itself i.e. we do **not** do the following:\n",
    "    \n",
    "    beatles = beatles.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16099f4-62c5-4181-b540-9afa7aa48adb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">Some methods return values, while others manipulate <i>their</i> object directly.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dae978-6e9e-4fbc-8c3f-5bee50e2afb4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## Exercise 5\n",
    "\n",
    "**a1.** Create a **list** of the planets, in order of distance from the sun:\\\n",
    "Mercury\\\n",
    "Venus\\\n",
    "Earth\\\n",
    "Mars\\\n",
    "Jupiter\\\n",
    "Saturn\\\n",
    "Uranus\\\n",
    "Neptune\n",
    "\n",
    "**a2.**  Check you have indeed created a list containing planets.\n",
    "\n",
    "**a3.**  Using the list, print out the name of the planet closest to the sun.\n",
    "\n",
    "**a4.**  Print out the name of the planet furthest from the sun.\n",
    "\n",
    "**a5.**  Print out the name of every third planet from the sun.\n",
    "\n",
    "**a6.**  Print out the names of the planets from the furthest from the sun to the closest.\n",
    "\n",
    "**a7.**  Print out the names of the planets in alphabetical order.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a1180f-0199-4b76-976f-50fa871f6f83",
   "metadata": {},
   "source": [
    "### Tuples\n",
    "Tuples can be thought of as lists that **cannot be modified** after their generation.  To create a tuple use round instead of square brackets.  Python syntax that often trips people up is when a tuple is declared to contain only one element.  In such situations, that single element must be followed by a comma.  These points are demonstrated below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c722720b-4c94-4f8d-94f9-ba1cd3a053ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "beatles = ('John', 'Paul', 'George', 'Pete')\n",
    "print(beatles)\n",
    "\n",
    "solo = ('Prince', )\n",
    "print(solo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ff616c-afb3-4f7c-b0e5-4408b3092372",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dictionaries\n",
    "\n",
    "Dictionaries (`dict`) are mutable structures that store data in what is known as **“key/value”** pairs.  The datatype name is intuitive since the key serves as the dictionary word to look-up, and the value serves as the definition of that word.  Importantly, the keys must be unique, whereas the values can contain duplicates. Also, each value (definition) **may only hold one object.**  Unlike real dictionaries however, the `dict` **keys are actually unordered**. \n",
    "\n",
    "To declare a dictionary, use the following syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9a2c9c-2cde-459c-beea-b61bd3f4cd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_team = {'Hannibal': 'Lieutenant Colonel John Hannibal Smith', 'Face': 'Lieutenant Templeton Arthur Peck', 'BA': 'Sergeant Bosco Albert Baracus', 'Murdock': 'Captain H.M. Murdock'}\n",
    "print(a_team)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc304e0-14d5-46e5-a73a-c3f7e340e0f1",
   "metadata": {},
   "source": [
    "This creates a dictionary named `a_team` which holds 4 key / value pairs, referring to an individual's nickname / real name.  For example: the key \"Hannibal\" is paired with the real name value \"Lieutenant Colonel John Hannibal Smith\".\n",
    "\n",
    "Values may be retrieved by entering the dictionary's name and then entering the relevant key, placed between square brackets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6fe381-9db1-40fa-bb93-65aa3a119e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_team['Face']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816ea3d3-375b-4ebc-9b83-e3a4de5ff717",
   "metadata": {},
   "source": [
    "You may add a new entry to a dictionary as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bf2a46-2791-47cb-b087-299d3ea41ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_team['Amy'] = 'Amy Allen'\n",
    "print(a_team)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec180fc9-879d-41a7-ba41-d482a8d7361b",
   "metadata": {},
   "source": [
    "And delete entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4993dc3d-83d2-4aa6-9613-f690ad8391c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del a_team['BA']\n",
    "print(a_team)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a73ea3e-264c-4019-af9a-dc7b9c2d10c6",
   "metadata": {},
   "source": [
    "### Ranges\n",
    "\n",
    "Ranges contain an ordered list of integers. You may create a range in several of ways, of which the simplest is to specify the stop value.  This will create a range from 0 to, but not including, that **stop** value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cea236c-f41a-437b-8ad5-49b2549c9dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "range(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfed161-b66f-4abf-b2c2-19f5056ed8c5",
   "metadata": {},
   "source": [
    "The returned value will show that a range has been created and also display the **start** and **stop** values.  If we pass this range to a list, you will see that the values of the range are 0, 1, and 2 but not 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c069846-0681-43c8-951c-bdb22d2d272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e9b293-3000-41ac-a871-ed5da412eeed",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Passing a range to a <code>list()</code> function highlights an important concept: <b>Python data structures may be generated from pre-existing data structures.</b>  \n",
    "<br>\n",
    "<br>\n",
    "Using this technique is often an efficient way to generate a desired collection.  For example, by creating a list from a range is quick way to generate a list with a large number of elements (you wouldn’t want to type out every number, now would you?).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5687327a-0152-4eba-a0d7-66f777fb3e19",
   "metadata": {},
   "source": [
    "If you wish the range to start at a value other that 0, then simply add this before the stop value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7549459-b1bd-4c6c-b9eb-60be38348455",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(100, 111))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4de9e7-eba1-41f8-960d-06f275f9e339",
   "metadata": {},
   "source": [
    "You may also pass a third argument when creating a range, namely a **step** value which sets the number by which the range should be incremented until it reaches the stop value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60a3ab0-fc78-4d57-a616-d0feebffeb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(2, 10, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c315dc68-84ac-46b7-a33b-804c45fced5e",
   "metadata": {},
   "source": [
    "If you choose an end value equal to or less than the start value, then the returned range will be empty.  If you choose a negative step value, then the stop value will need to be less than the start value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c778ff-f6d6-4cf4-836c-7ec894e697f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(3, -3, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bae789-95f1-4289-97a6-eed48e7412d2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56e09ca7-84f7-4ddc-b7ae-fd119b6e3dcf",
   "metadata": {},
   "source": [
    "### Introspection\n",
    "In computer programming, introspection is the ability to determine the type of an object at runtime.  This can be achieved in Jupyter Notebook by typing `?` or `??` before or after the name of the object of interest.  Using `?` gives  information about the object, and `??` can give even more information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aff79a-f56d-45ea-ae82-7b52beb4de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "?a_team"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b34bc23-def0-4ba4-8c2a-9237017d741d",
   "metadata": {},
   "source": [
    "Since this applies to objects, introspection will work for strings, collections and functions etc. and provide a useful way to keep track of what is what in a Jupyter Notebook. (Don't worry if you do not know what these terms mean, we shall introduce them later on.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b423fe2a-f3d0-42b6-b003-cc3e27aab31e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "That brings the Python section to an end and all being well most of it was familiar.\n",
    "\n",
    "If however, you have started this course but are new to Python then you may feel we have already covered a substantial amount of material.  And that is true, for learning to program is akin to learning a foreign language, requiring a considerable amount of time and effort to become fluent.  Although much new material may have been introduced here, it is just a small fraction of what Python has to offer.  To reinforce your newly acquired knowledge we recommend you attend a Python course.  But in the meantime, the Python we have covered so far should be all but everything you need to know to complete this course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49de1d2c-913c-4c96-a8b8-4ccccca5a634",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## Exercise 5.2\n",
    "\n",
    "**b1.**  Create a **dictionary** named \"elements\" of the chemical elements:\\\n",
    "H: Hydrogen\\\n",
    "Li: Lithium\\\n",
    "Na: Sodium\\\n",
    "K: Potassium\n",
    "\n",
    "**b2.**  Retrieve from the dictionary the name of the chemical element with symbol Na.\n",
    "\n",
    "**b3.**  Remove Hydrogen from the dictionary\n",
    "\n",
    "<hr>\n",
    "\n",
    "Generate the **ranges** objects described below (check your answers by passing the range to a list and view the results).\n",
    "\n",
    "**c1.**  Create a range of integers from 1 to 7 inclusive.\n",
    "\n",
    "**c2.**  Create a range of integers -5 to 3 inclusive.\n",
    "\n",
    "**c3.**  Create a range of all the odd numbers from -3 to 5 inclusive\n",
    "\n",
    "<hr>\n",
    "\n",
    "**\\*d1.**  Create a list that contains the planets list, the chemical elements dictionary and the three ranges objects.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7e3f0f-7ced-4270-9ca7-6da763d7da00",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pandas\n",
    "The process of manipulating and analysing datasets is performed using the Python library **pandas**.  This library is itself built upon another library named NumPy.  While we shall not go into detail discussing **NumPy**, we shall mention this library in passing because some of its methods can be applied to pandas data structures.  The NumPy library is mainly used to manipulate multi-dimensional matrices, which is common practice in areas such as machine learning.  But don’t be put off if this sounds a little daunting, all you need to remember so far as NumPy is concerned is that it can be used as an accessory tool when working with pandas. \n",
    "\n",
    "(If you do wish to know more about NumPy and machine learning, then please be aware that the LMB offers courses in both these subjects.)\n",
    "\n",
    "The software package pandas is a Python library, so to use pandas simply import it as you would any other Python library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29306b10-c9dc-449d-97d5-879d52a4f1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7e3f8b-0c88-4e9e-b7e5-eff66a6f3819",
   "metadata": {
    "tags": []
   },
   "source": [
    "This uses the familiar `import` command to make available the pandas module.  It is worth pointing out here that this command will result in the pandas module subsequently being referenced in the code as `pd`.  This is a widely used convention when using pandas and will be followed in this course.  We strongly recommend that you follow this convention when writing your code.\n",
    "\n",
    "The pandas schema involves categorising data in two types of data structure, known as pandas **Series** and a pandas **DataFrame**.\n",
    "\n",
    "## Pandas Series\n",
    "Panda Series are similar to lists in that they contain an ordered sequence of values.  When data – which can include numerical or string data types – has been imported into a Series, it may then be subject to a wide range of manipulation and analysis techniques.\n",
    "\n",
    "### Creating Series\n",
    "A pandas series may be created as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae329ee-c14d-420e-93db-deb4bc4d4db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "series1 = pd.Series([9, -3, 30, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a612dd-5ffc-497a-97ed-ef05ad8f3175",
   "metadata": {},
   "source": [
    "The command `pd.Series` (which uses the Pandas module) creates the Series.  The command has been passed a Python list object containing four integers.   (Other data types, such as a tuple or a dictionary could have been used.)\n",
    "\n",
    "As is the case for native Python objects, the `type()` command can be used to confirm a Pandas Series object has been created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a9cd34-1225-445f-8846-ce15f9152941",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(series1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b71180-316c-482d-8ebc-8f979f0e3dc0",
   "metadata": {},
   "source": [
    "Simply typing the variable name in the Jupyter Notebook will return more information about newly created objects.  In this case entering the name will list each of the four elements of the object.  Information is also provided on the data the Series actually holds, namely: `int64` – which means the Series contains integers, but not other data types.  \n",
    "\n",
    "Importantly, to the left of the integers values are the numbers 0 to 3.  Similar to Python list objects, each element within a Pandas Series is referenced by a numerical value, which, by default, starts at zero and increases incrementally by one.  This is known as the **index** of a Series and can be seen represented in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf61fd3d-d6bb-4dfd-8a46-3084bd17bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "series1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca23e55-06d1-4ad1-bef8-cd1e7474c11f",
   "metadata": {},
   "source": [
    "The index allows specific values within the Series to be accessed, in a fashion once again similar to Python lists.  For example, the second item in this Series may be retrieved as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6c7568-287f-4881-b284-7417d07a51f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "series1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4776fd1-12ac-4bfc-aaca-9cbf0f565543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide a list of values\n",
    "series1[[0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db68b58-aab9-4c8e-bb4b-0075007e0d8f",
   "metadata": {},
   "source": [
    "### Querying a Series\n",
    "Once you’ve made a Series, a common task is to check what it contains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74227e3-803f-4dd0-9bfe-58e5186ad034",
   "metadata": {
    "tags": []
   },
   "source": [
    "Pandas Series are objects that have **attributes** and **methods** associated with them.  Reading the official pandas documentation will provide a thorough overview of this subject, but we shall highlight some of the most useful attributes and methods here.\n",
    "\n",
    "To obtain an overall summary of a Series, use the in-built `describe()` method.   (You will see below that this method provides a summary report by returning another Series (`float64`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7689b1e2-86ef-41fc-a26b-dcb2081cca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "series1 = pd.Series([10, 20, 30, 40, 50])\n",
    "series1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da38701-87c8-4eda-964e-e49693ea770f",
   "metadata": {},
   "source": [
    "The information retrieved using the `describe()` method will vary depending on the input Series.  In the previous example the Series of interest contained only numbers and thus returning mean, quartile and other similar statistics make pertinent summary metrics.  If however – as in the example below – a Series were to contain character strings, then a different set of summary metrics would be needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af30b5-eda0-4dd2-9827-b9166600962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "series2 = pd.Series(['Cat', 'Cat', 'Dog', 'Cat', 'Dog'])\n",
    "series2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621399f6-9a65-4b47-b65c-f818e818712c",
   "metadata": {},
   "source": [
    "### Changing values\n",
    "Series are mutable objects, meaning they can be edited after their initial creation.  In the example below this is achieved using the assignment operator (`=`) to change the second element of the Series to the character \"a\".  (Also note that after having done this, the Series no longer holds only integers, but now contains a mix of different data types, which is reflected in the new `dtype` description)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9fe758-f24c-4469-a29e-8c0edc28c42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "series1[1] = 'a'\n",
    "series1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5f44b0-ec54-42c3-83c3-f3d00ea2865c",
   "metadata": {},
   "source": [
    "It is also possible to manipulate multiple values simultaneously in this way.  In the example below, two elements of the list are changed to the character 'b'.  (If you look at this syntax some more, it should become clear that a Python list containing the index values to alter, has been passed to the Series.)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7f7e8e-1db2-4c9d-bb51-9e9e6e5a9ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "series1[[2, 4]] = 'b'\n",
    "series1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb18ba10-7ab5-417a-954f-69e429e86bfd",
   "metadata": {},
   "source": [
    "Or we could modify more than element simultaneously, but on this occasion differing values.  Pass to the series a list of index values to edit and assign these the new values using a Python list.  This is probably illustrated more clearly by the code itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147138fd-03b9-4eac-af73-c4ef7e6b3310",
   "metadata": {},
   "outputs": [],
   "source": [
    "series1[[2, 4]] = ['c', 'd']\n",
    "series1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbba7990-6b55-4e50-934e-9a61338f860c",
   "metadata": {},
   "source": [
    "In the following example, rather than passing numbers directly to denote the index, we have used a colon to refer to the numbers from 1 until the end of the Series (using the splicing technique we encountered earlier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7108fc6a-ce87-4963-b8d7-c1277c134588",
   "metadata": {},
   "outputs": [],
   "source": [
    "series1[1:] = 'X'\n",
    "series1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722f6cb5-90ef-4f2b-99d5-11f1ef7ae5c3",
   "metadata": {},
   "source": [
    "### Calculations using Series\n",
    "A powerful feature of pandas is that all the individual elements of a Series may be manipulated in the same way using a single command.  To put it simply, suppose you had a Series of numbers and wanted to multiply all the individual values by 10, well that could be done as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e755f-20e7-4944-977f-b836d29e5390",
   "metadata": {},
   "outputs": [],
   "source": [
    "series1 = pd.Series([1, 0, 4.2, -10])\n",
    "series1 = series1 * 10\n",
    "series1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfa1b4f-ae1d-4e2c-bbd2-15b10d069127",
   "metadata": {},
   "source": [
    "### Filtering data\n",
    "A common task is to select only values from a dataset that meet a certain criterion.   There are 2 steps in the process:\n",
    "\n",
    "1. Perform a test with a logical operator (e.g. `==`, `<`, `>`, `<=`, `=>`) to generate a Boolean Series.\n",
    "\n",
    "2. Use that Boolean Series to filter the original series.\n",
    "\n",
    "Let’s use this approach to filter the previous Series, extracting all negative numbers \n",
    "\n",
    "Firstly, perform the Boolean test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed863ff7-ad43-42eb-921d-da677d29282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_series = series1 < 0\n",
    "boolean_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac458d99-c8a8-41d0-842e-c2a97f8e5012",
   "metadata": {},
   "source": [
    "Now use this Boolean Series to select the values that meet the logical criterion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3404a493-f5c3-4821-8a31-6caff8bfef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "series1[boolean_series]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7363ec-53d8-4d71-99fa-137a8b22cfa2",
   "metadata": {},
   "source": [
    "**(Note: notice in the above example, that the original index value of 3 is returned i.e. the index is not reset to 0.)**\n",
    "\n",
    "Actually, these above 2 steps can be combined into a one-line expression, in which the logical test is placed between the square brackets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623805fd-a3a5-4c81-90c7-69851b858fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "series1[series1 < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e9d6c0-c946-417a-87b4-6769e2a6749e",
   "metadata": {},
   "source": [
    "### Series index\n",
    "We introduced the concept of a Series index previously.  These are essentially the labels for each element of a Series.  By default, when creating a Series, these index value are assigned numerical values (starting at 0) and increment by 1 for each element of the Series.  And again as shown before, when filtering a Series the original index values are maintained in the new series.\n",
    "\n",
    "Although Series are assigned default numerical values, the coder may choose to override these and specify custom values.\n",
    "\n",
    "In the following example we generate a Series with default index values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f47264-fa5f-446c-8726-3463fe77d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_series =  pd.Series(['Apple', 'Banana', 'Cherry'])\n",
    "print(default_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb28c49e-b663-4036-83e3-b4e5e131bd2e",
   "metadata": {},
   "source": [
    "In contrast, in this example the coder specifies letters for the index, which is reflected in the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7730c93a-9ad5-46a9-8d90-cfedded104e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_series = pd.Series(['Apple', 'Banana', 'Cherry'], index=['a', 'b', 'c'])\n",
    "print(custom_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfde608-58c9-4b3b-a558-53c1199fa640",
   "metadata": {},
   "source": [
    "These user-specified index values may be used to retrieve their corresponding values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39d180b-404e-4a7a-9ebf-74a076dd2385",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_series['b']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60401edb-a92b-4d70-ae2f-45c2d7f37afd",
   "metadata": {},
   "source": [
    "Or to retrieve multiple values at once, pass a Python list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332429ac-f477-4eb0-8e1b-c9530bcd015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_series[['b', 'a']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15771bf-127d-4c90-b293-8bfe508de26c",
   "metadata": {},
   "source": [
    "This concept of having a \"label\" for a specific value may remind you of the Python dictionary.  And indeed, a dictionary may be used to create a series with custom index values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d6de14-8be7-492b-98ce-91098875ae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dict = {'a' : 'Apple', 'b' : 'Banana', 'c' : 'Cherry'}\n",
    "custom_series = pd.Series(custom_dict)\n",
    "custom_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4012db2a-816d-4791-8b90-2aeac79304d3",
   "metadata": {},
   "source": [
    "Suppose that upon creating a Series you wish to change the order of its elements, well that is possible by specifying the order to the `index` parameter of the Series constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cc564d-4379-488c-9d8f-963135924823",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order = ['b', 'c', 'a']\n",
    "custom_series = pd.Series(custom_dict, index=new_order)   # Specify the index parameter to order the elements\n",
    "custom_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71064040-6025-4455-b603-6fa76e31e0a1",
   "metadata": {},
   "source": [
    "### The `in` operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c39e51-281a-43ae-a510-e952374f6927",
   "metadata": {},
   "source": [
    "Here the `in` operator, which is a function of regular Python, can be used to determine whether a Series contains a specified index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b4acd5-f6e0-426d-9b44-70528cac4af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('a' in custom_series)\n",
    "print('z' in custom_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0085eb7f-d4b2-4e89-9a28-57e4425f0afc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Note:</b>  That is already quite a lot to take in, and indeed there are even more ways in which indexes can be used.  A Series could contain duplicated index values for example.  Alternatively, the numerical notation [0], [1],… can still be used to retrieve values from a Series even if the series has been specified custom strings instead of letters. However, if the Series has numerical and string index values, then the numerical notation [0], [1], may not be used.  You get the point, there is more to Series than discussed here, but we shall only cover the typical ways in which that are used for most applications and in most code.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9629acf8-fbec-46e4-ad6c-73259febee39",
   "metadata": {},
   "source": [
    "### Handling missing values\n",
    "Datasets are rarely perfect and it is common for them to be incomplete.  Leaving such elements as blank in a Series, or maybe entering a 0 are possible ways to denote such omissions.  However, pandas has a better solution, which is the `NaN` datatype.  It is preferable to become familiar with the concept earlier rather than later in your pandas training, so we shall introduce it here.\n",
    "\n",
    "The `NaN` value may be entered directly into datasets or can be generated as output from some computational process.  In the first example we generate a Series from a Python list, which contains `None` as its first term.  This will be interpreted by pandas as `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e6cba-24b3-4778-a317-5d91f4216284",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_series = pd.Series([None, 2, 3])\n",
    "missing_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eafd24a-c19e-4972-9e68-3d6951fcbb4f",
   "metadata": {},
   "source": [
    "In the second example, we make the `custom_dict` Series once more, and then order it by index.  However, attempting to order by a value not in the original index will create an `NaN` in the pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fe23e2-cf80-417f-88b9-d87e34c7386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dict = {'a' : 'Apple', 'b' : 'Banana', 'c' : 'Cherry'}\n",
    "custom_series = pd.Series(custom_dict)\n",
    "print(custom_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bc8850-b901-4d79-9aab-ba0c85744724",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order = ['b', 'c', 'a', 'd']\n",
    "custom_series = pd.Series(custom_dict, index=new_order)\n",
    "print(custom_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e058635-f3dd-4e82-8632-6f10f20fa32c",
   "metadata": {},
   "source": [
    "Pandas allows the user to identify for `NaN` values in a series with the `isnull()` pandas method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a840befa-aba9-4cef-96d0-3a2ddbcf3358",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(custom_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd1bbfc-e23a-4ac4-b544-bdffbe0f705a",
   "metadata": {
    "tags": []
   },
   "source": [
    "In fact, the same result may be achieved by using the `isnull()` method that is built into Pandas series: `custom_series.isnull()`\n",
    "\n",
    "There is also a `notnull()` method, which as you have probably guessed, generates the opposite output to `isnull()`.\n",
    "\n",
    "### Combining Series using index values\n",
    "A useful feature of the Series Index is that it can be used in operations involving more than one Series.  In the example in the following cell we have summed expression values from two Series in a gene-wise fashion.\n",
    "\n",
    "Notice that the order of GeneA and GeneB are different in the two Series.  Importantly, you will see that the addition is performed via **index matching** and not the order of the GeneA / GeneB in the datasets.  (In the example here the index has gene name values, but the result would be the same if numerical values were used instead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f10de0-6e2b-415d-bf59-353a52125b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_data_1 =  pd.Series({'GeneA' : 30, 'GeneB' : 80})\n",
    "expression_data_2 =  pd.Series({'GeneB' : 0,  'GeneA' : 100})\n",
    "\n",
    "total = expression_data_1 + expression_data_2\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488ae53d-cb16-4aff-842e-d328e44ab2dc",
   "metadata": {},
   "source": [
    "### The Series index object\n",
    "The Series index is an object in its own right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea0184b-7824-4da3-a66d-acd05683a28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(total.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80de623-9ed5-45d6-940c-d064c2cdf603",
   "metadata": {},
   "source": [
    "Finally, both the Series object and its ndex object may be assigned names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210a3a80-5e8c-4ceb-a1fa-66738749f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "total.name = 'Gene_Expression'\n",
    "total.index.name = 'Gene_Name'\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8eea6a-4101-483d-ba60-e8f9ccb7866f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## Exercise 6\n",
    "\n",
    "**a1.**  Create a Series named \"buildings\" which contains the following integers:\\\n",
    "2717, 2227, 2073\n",
    "\n",
    "**a2.**  Add an index to the `buildings` Series with the following names:\n",
    "Burj, Merdeka, Shanghai\n",
    "\n",
    "**a3.**  These are heights of buildings, but they are in feet, whereas we want height values in metres. To do the conversion divide all the existing heights by 3.281.\n",
    "\n",
    "**a4.**  Set the index name to: \"height_m\".\n",
    "\n",
    "**a5.**  Perform a logical test that reports whether a height is greater than 800 metres.  The test should return a Series of `True` / `False` values.\n",
    "\n",
    "**a6.**  Let's suppose the three building are to be extended by placing antennas on the top.  The height increases (metres) will be:\n",
    "\n",
    "Merdeka: 10\n",
    "Burj: 5\n",
    "Shanghai: 12\n",
    "\n",
    "Create a Python dictionary recording these value and create a new pandas Series named \"antennas\" from this dictionary.\n",
    "\n",
    "**a7.**  Now add the \"buildings\" and \"antennas\" Series together.  Does the order of the values in their respective Series affect the final totals?\n",
    "\n",
    "<hr>\n",
    "\n",
    "**b1.**  Create a Series called \"forename\" containing the first name of *3* people on this course.\n",
    "\n",
    "**b2.**  Create a Series called \"surname\" containing the surnames of the first *2* of those people (in the same order).\n",
    "\n",
    "**b3.**  Use the addition operator (+) to combine those two Series into a new Series named \"fullname\".\n",
    "\n",
    "**b4.**  Print out the `fullname` Series.  What do you see ?\n",
    "\n",
    "**b5.**  Use the `isnull()` method to identify `NaN` values in the `fullnames` Series.\n",
    "\n",
    "<hr>\n",
    "\n",
    "**\\*c1.** Create a pandas Series that contains the first 100 values of the Nine Times Table i.e. 9, 18,.., 891, 900.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a15e0d1-8b24-468b-b40f-01c42d607b3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pandas DataFrames\n",
    "So you’ve learnt that a Series is a collection of data.  Well, DataFrames are similar but store data as we are familiar with in everyday life in the form of tables.  A spreadsheet (as used in MS Excel) is a good example of arranging data in this way, in which the data is arranged into columns and rows.\n",
    "\n",
    "(If you are familiar with the statistical programming language R, you will be aware that it has an in-built datatype called a \"dataframe\" which is similar to the pandas object of the same name.)\n",
    "\n",
    "<img src='course_images/DataFrame_Schematic.svg' title='DataFrame Schematic'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1aebce-40ba-4f0c-8101-35bf6c7d04a0",
   "metadata": {},
   "source": [
    "### Creating DataFrames\n",
    "\n",
    "#### Using Lists\n",
    "A simple way to create a DataFrame is to use Python lists.  **Each separate list will constitute a separate row in the DataFrame.**  These lists should then be placed all together inside an \"outer\" list, which is then passed to the DataFrame constructor method. \n",
    "\n",
    "This may sound a little complex, but looking at the code below should make this clearer.  You can see three lists containing data inside a fourth list (hence the double square brackets).  This collection has then been passed as an argument to `pd.DataFrame()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d016ee80-8483-4f9e-af0c-4cbd2bbc4ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "        [[1, 2, 3],\n",
    "         [4, 5, 6],\n",
    "         [7, 8, 9]])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5746c8f-ad54-4033-908e-05de5ed05702",
   "metadata": {},
   "source": [
    "Instead of adopting the default numerical values, you can specify the column names (column index) when creating a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1aaa70-7ab5-44ec-8da3-683a700cbbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "        [[1, 2, 3],\n",
    "         [4, 5, 6],\n",
    "         [7, 8, 9]],\n",
    "    columns=['a', 'b', 'c'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d77edb-bdae-443c-aedb-e7e459fe03db",
   "metadata": {},
   "source": [
    "And, if you wish, the row names (row index) as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1498f620-8834-4e55-90ba-4992f3cc33d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "        [[1, 2, 3],\n",
    "         [4, 5, 6],\n",
    "         [7, 8, 9]],\n",
    "    columns=['a', 'b', 'c'],\n",
    "    index = ['one', 'two', 'three'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3954a9-bec2-4d15-89a6-1d3e75685e00",
   "metadata": {},
   "source": [
    "#### Using Dictionaries\n",
    "Another convenient way to create a DataFrame is to use a Python dictionary, or more specifically a dictionary of lists.  Yes - it is possible in Python to make such nested objects!\n",
    "\n",
    "Each dictionary key will denote a column name.  Associated with each key is a list, which corresponds to the DataFrame column values (notice that this is different from the previous example, in which each list formed a row, not a column, in the new DataFrame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebd692d-431a-4e79-bb46-1bbc8914c366",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\"a\" : [1, 2, 3],\n",
    "     \"b\" : [4, 5, 6],\n",
    "     \"c\" : [7, 8, 9]})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4225b3-8683-4e15-87cd-f756d9023abe",
   "metadata": {},
   "source": [
    "You could declare the dictionary separately to achieve the same objective:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b71f84-9afd-4f41-8cfc-f0544371e1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\"a\" : [1, 2, 3], \"b\" : [4, 5, 6], \"c\" : [7, 8, 9]}\n",
    "df = pd.DataFrame(data_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835cb52c-5af8-4133-b2a4-a6e6dbaa1312",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DataFrames and files\n",
    "Data can also be extracted from files and used to create a DataFrame, and vice versa. \n",
    "\n",
    "#### Importing file data into a DataFrame\n",
    "Data can be read from a file using the pandas `read_csv()` method.  This allows data to be imported which is in either one of the commonly used formats: Comma Separated Values (CSV) or Tab Separated Values (TSV).\n",
    "\n",
    "This method has many options, but the general command to import data is\n",
    "\n",
    "`imported_data = pd.read_csv(filename)`\n",
    "\n",
    "This will import a CSV file, to import a TSV file you need to specify that tabs are used as the delimiter (the character that separates columns from one another):\n",
    "\n",
    "`imported_data = pd.read_csv(filename, sep='\\t')`\n",
    "\n",
    "Other options allow the user to specify whether the input file has headers, whether to skip rows and what data format is found in each column.\n",
    "\n",
    "\n",
    "There is also a separate method to read Excel files.\n",
    "\n",
    "`imported_data = pd.read_excel(filename)`\n",
    "\n",
    "#### Exporting DataFrame data to a file\n",
    "Writing to a file is similar to reading from a file and entails running a DataFrame method to which the output file path has been passed as a string argument:\n",
    "\n",
    "`DataFrame.to_csv(filename)`\n",
    "\n",
    "`DataFrame.to_csv(filename, sep='\\t')`\n",
    "\n",
    "`DataFrame.to_excel(filename)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeb62f0-2cab-42cf-a802-2c51defa1baf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Importing Test datasets\n",
    "\n",
    "Often the simplest way to practice using pandas is to try out commands on test datasets.  The Python module seaborn (https://seaborn.pydata.org) has a variety of test datasets that can be used for a range of analysis techniques.  \n",
    "\n",
    "The lists of datasets may be viewed at:\n",
    "https://github.com/mwaskom/seaborn-data\n",
    "\n",
    "To access a dataset, simply import the seaborn module and load the desired dataset.  The example below imports the \"Penguins\" dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b734922-494f-4ecf-806d-7d9c96501da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "penguins = sns.load_dataset('penguins')\n",
    "\n",
    "penguins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f62ffe9-429b-4edd-a0d9-08309abad5b8",
   "metadata": {},
   "source": [
    "### DataFrame Structure\n",
    "After having made a DataFrame it is often useful to check that it is of the correct size.  Pandas DataFrames have a `shape` attribute to make this possible.\n",
    "\n",
    "(Although printing out a DataFrame to a Notebook will display the dimensions of that DataFrame as footer, these values cannot be easily assigned to a variable, but using the `shape` attribute overcomes this drawback.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa92737-ef6f-42ae-b4c2-48007038bcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed02bd8b-29e6-441e-80d5-a5b486981db6",
   "metadata": {},
   "source": [
    "This returns a **tuple** Python object that contains 2 pieces of information: the first entry reports the number of rows while the second reports the number of columns.  You will see that the returned result of 344 rows x 7 column matches that displayed in the cell above where the DataFrame is rendered to the screen.\n",
    "\n",
    "To retrieve programmatically the number of rows or number of columns then use the square brackets indexing notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd72dd8-4dbf-4f09-9d57-77a2e3771214",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(penguins.shape[0])   #Number of rows\n",
    "print(penguins.shape[1])   #Number of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7199335-fc7c-4679-b5b8-e48e1a249cb5",
   "metadata": {},
   "source": [
    "In addition, the `info()` method returns details on the type of data stored in a DataFrame or a Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4a1d76-fe47-47b6-a2f7-186cd1423bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2581e52-be1a-4f4a-bd15-1076430a25d8",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "**a1.**  Let's place the data looking at building heights from the previous exercise into a DataFrame.  Name the first column \"height\" and the second column \"antenna\".  Set the row names to the names of the buildings.\n",
    "\n",
    "**a2.**  Print out the \"antenna\" column.\n",
    "\n",
    "**a3.**  Print out the the row containing the Burj data.\n",
    "\n",
    "**a4.**  Create a Boolean list and use it to print the middle row only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0055dec-176e-4556-820c-5f1175596815",
   "metadata": {},
   "source": [
    "### Indexes (row and column names)\n",
    "\n",
    "Most people's introduction to data analysis is using MS Excel, which stores information in a spreadsheet comprising cells organised into rows and columns.  By default in Excel the rows are assigned numerical values while the columns are labelled using letters.  By comparison, pandas not only names rows using numbers, but also labels columns using numbers (starting a 0 and incrementing by 1: 0, 1, 2,...).\n",
    "\n",
    "Pandas DataFrames are constructed from three components \n",
    "1. a NumPy array, which stores the data - we shall introduce NumPy later\n",
    "2. an index that stores the row names\n",
    "3. an index that stores the column names\n",
    "\n",
    "Although by default both indexes have numerical values, they may be changed and given custom values - as we have seen already.  Also, duplicate values **are** allowed within an index.\n",
    "\n",
    "It is important to remember that index values should be thought of as labels (they are not akin to row number in Excel).  What does that mean?  **Well, suppose we re-order the rows of a DataFrame, this will result in the row indexes being re-ordered as well.**  That means that the first row may no longer have the index value of 0.  (We shall see an example of this when we sort DataFrames later in the course.)\n",
    "\n",
    "Let's illustrate these points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382714dc-c405-4b8e-9d54-58d8bc49fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4d939a-c271-458d-adc0-198358c9354b",
   "metadata": {},
   "source": [
    "To extract the contents of the array use the `values` attribute, which returns what is known as a **NumPy array**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49d80a9-1fe4-42fa-8c4d-8335fbec3167",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.values)\n",
    "print(type(df.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774c50a0-00cc-49a8-982f-103a4e78f153",
   "metadata": {},
   "source": [
    "We can also retrieve the row names and column names with the `index` and `columns` attributes respectively.  These values are stored in an **index object**.\n",
    "\n",
    "(This naming system may seem a little strange since `index` returns the rows index.  Why not call this attribute `rows` instead?  Well, that's just the way it is.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c525571-acd2-41d7-8d6f-c47f06ec1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f6e1dd-08cb-4ac9-9651-789f38c17ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd4d9dc-b1f7-46b2-8d75-6b5dae9a4b85",
   "metadata": {},
   "source": [
    "You will notice that the index object returned for the rows is not the same as for the columns.  This is because we are storing different types of data.  The row names index use the default numbering system - which is best stored as a Python range object.  The column names index stores custom values, which needs to be stored in a Python list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eb2f56-104d-4b70-a836-51834c588f55",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Now is a good point in the course to introduce the concept of <b>axis</b>.  This denotes whether we are referring to rows or columns.  The naming convention used by Pandas is as follows:\n",
    "    \n",
    "<b>Rows (horizontal axis): axis=0</b>  \n",
    "<b>Columns (vertical axis): axis=1</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b27514-7714-49b7-8149-f9b87f1a2ea9",
   "metadata": {},
   "source": [
    "Should you wish, it is possible to give names to your column and row indexes by setting the relevant attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e570292-220e-4a29-8148-f6a13afa0ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.name='Column_Index_Name'\n",
    "df.index.name='Row_Index_Name'\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76861e36-94ea-47cc-a355-a80eb1ad157c",
   "metadata": {},
   "source": [
    "### Accessing data\n",
    "\n",
    "#### dict-like notation\n",
    "Look at the dataset below of test scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e3d75b-9369-416e-bf6c-fce62942e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = pd.DataFrame(\n",
    "    {'Person' : ['Adele', 'Adele', 'Beyonce', 'Beyonce', 'Chesney', 'Chesney'],\n",
    "     \"Subject\" : ['Maths', 'English', 'Maths', 'English', 'Maths', 'English'],\n",
    "     \"Result\" : [91, 67, 54, 69, 80, 61]})\n",
    "\n",
    "tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f999cf6-5ede-4cac-98d3-0bf50bcc2095",
   "metadata": {},
   "source": [
    "The **dict-like access notation** entails placing between **square brackets** details of the rows or columns to retrieve.  This method can be used in several ways.  A column may be retrieved from the DataFrame using the notation shown below.  The object returned will be a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c914ef-5a22-4700-8261-fe9a8bc89ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests['Result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96fc95e-149a-4ee9-a6e0-0fd1ee6dd7df",
   "metadata": {},
   "source": [
    "In fact it is possible to return more than one column simultaneously from a DataFrame by using this notation.  To achieve this instead, pass a Python list of column names.  If for example we wanted to return the columns 'Person' and 'Result', place the Python list `['Person', 'Result']` between the square bracket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eac447-7710-4b0a-89d5-584d9dd94c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests[['Person', 'Result']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2425bc-59bc-4701-a7a2-8672816e7d9b",
   "metadata": {},
   "source": [
    "Notice the double square brackets used here, since we a passing a list rather than a single value.  The returned object on this occasion is a DataFrame rather than a Series.\n",
    "\n",
    "Also, we may retrieve columns **in any order** from the DataFrame and not simply adopt the original order.  In the example below the order is reversed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430633f3-1575-4391-8223-42709f45de1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests[['Result', 'Person']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656bd455-824a-4389-9b1f-f362e769da9a",
   "metadata": {},
   "source": [
    "Moreover, should we ever want to, we can duplicate columns in this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d55a3b-f48c-4749-aba5-84aecc2ba84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests[['Result', 'Person', 'Person']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f871ffa8-26c5-4336-b7cd-2eec7479e995",
   "metadata": {},
   "source": [
    "In addition, it is also possible to return specific rows rather than columns. To do this, pass a list of boolean values that correspond to the rows that are to be returned.  The example below returns the first, second and last rows only from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bf2d58-3e09-4a9e-80bb-2c6be451ab99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tests[[True, True, False, False, False, True]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9621a5ca-bc10-4e1d-b750-b54fc88b48e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### `iloc` index operator\n",
    "\n",
    "The `iloc()` index operator allows the user to specify single or multiple row and/or columns using **positional information**.  (By position information we mean that the first row and is labelled 0, the next row is labelled 1 and so on.  This **positional information is independent of the row index name** - although they may be the same.)\n",
    "\n",
    "Similarly, working from left-to-right, columns are labelled 0, 1, 2,..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d9e99d-903c-4288-b02b-d55081fc9d1a",
   "metadata": {},
   "source": [
    "Passing single numerical values as an argument using iloc will return the corresponding **row** as a Series.\n",
    "\n",
    "`.iloc[row]`\n",
    "\n",
    "\n",
    "Here we return the second row of the `tests` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0edbcf2-396a-42e5-8c19-9c9e77f38975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tests.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86dfb5b-2b02-414d-ac14-74aab01c3282",
   "metadata": {},
   "source": [
    "More commonly we would specify the **row and the column** to be returned.\n",
    "\n",
    "`.iloc[rows, columns]`\n",
    "\n",
    "For example, to select the first entry in the third column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430974ad-c03e-4c8d-bd30-e19e96027bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.iloc[0, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5679d4d1-f8ae-4993-a1cf-5c2d5263d6a1",
   "metadata": {},
   "source": [
    "Use a solitary colon to select entire rows or columns (this is a slice, which we encountered before, and it means select everything)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd911d5-9601-4161-97bd-8c287dc2a2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.iloc[1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b8ae8a-3c75-4f09-9c7b-712e93378b10",
   "metadata": {},
   "source": [
    "Likewise, to chose a whole column (the second column in this instance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60163b13-5be9-46fd-b062-3633d5c00e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c728f0-fc12-4855-9016-b879e81a2774",
   "metadata": {
    "tags": []
   },
   "source": [
    "It is also possible to select adjacent rows or columns by slicing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8cf419-4ab7-4e65-9a63-2fd276d6dbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.iloc[2:4, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cc2d91-c741-4745-ad11-b5f29d72ac4f",
   "metadata": {},
   "source": [
    "As well as specifically defined selections using Python lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bced89e1-3b52-4bf4-b9c4-a445c45e039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.iloc[[0, 4, 5], [2, 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114dca92-e8a1-4997-98f1-1113b995760c",
   "metadata": {},
   "source": [
    "(Notice the index values of the returned DataFrame are the same as in the original DataFrame.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177402dc-53ea-4acf-a9c7-bd0bed69da1a",
   "metadata": {},
   "source": [
    "Maybe a little bit surprisingly, `'iloc'` can also accept boolean values to retrieve rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9cfd03-b31b-4395-9bf9-160abb69e40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the fist, second and last row\n",
    "tests.iloc[[True, True, False, False, False, True]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7f4682-2b84-48ff-83a7-863d156c00c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the fist, second and last row from the second column\n",
    "tests.iloc[[True, True, False, False, False, True], [False, True, False]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232ea6b8-8326-4aff-9c9a-77ef00fa19dc",
   "metadata": {},
   "source": [
    "#### `loc()` index operator\n",
    "\n",
    "The `loc()` index operator allows single or multiple rows and columns to be selected simultaneously using **named values**\n",
    "\n",
    "The `loc()` index operator works in a similar fashion to `iloc()`, except that this method takes as input column names or row names.\n",
    "\n",
    "The `loc()` index operator can take single values, which will return the corresponding *row*.  It uses the *index* name.\n",
    "\n",
    "`.loc[index]`\n",
    "\n",
    "So to return the row with the index value=1 (the second row):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a19a73d-310d-46af-a0f3-2b6ccbdee99e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tests.loc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e506315-2296-4bc9-86c3-4ccb684ed482",
   "metadata": {},
   "source": [
    "In a similar fashion, it is also possible to pass a list of index values to return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fe50b2-b2d8-41a7-9234-b6a6a0bf576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.loc[[0, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af028183-5a9e-48a5-9db4-38dc16a76334",
   "metadata": {},
   "source": [
    "The `loc()` index operator will also accept a list of Boolean values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d338b247-995c-4026-9a6a-828415053252",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.loc[[True, False, False, False, False, True]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db57bc11-69e8-40df-88ca-700a0d8f6ea4",
   "metadata": {},
   "source": [
    "The `loc()` index operator can be used to retrieve specific **columns** as well.\n",
    "\n",
    "Passing a row name and a column name will return a single value.\n",
    "\n",
    "`.loc[rowname, column_name]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4358de7c-77cd-41bd-ad5c-5cecc2e414e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.loc[1, 'Result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c147f1-d9d8-406c-8584-dc629ee6df22",
   "metadata": {},
   "source": [
    "Similar to `iloc()`, we can pass splices to the `loc()` index operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b74b1d-798d-4ea7-8e3f-0c178f897ac1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tests.loc[2:4, 'Result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0922cdac-27b2-46f8-bf11-6f70210c5ead",
   "metadata": {},
   "source": [
    " **Notice that slicing with loc(), unlike other slices, will include the end value.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149cb820-f1c1-47b2-97d5-905715d8e10c",
   "metadata": {},
   "source": [
    "As before, the returned data is a Series.\n",
    "\n",
    "Use a Python list to return specific named columns:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50804499-f9ff-4ba8-a5bd-79c3030194d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.loc[:, ['Subject', 'Person']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75028dce-9d21-4fe5-bd67-3021c60d08c7",
   "metadata": {},
   "source": [
    "It is possible to use the row index values at the same time to access elements in the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96142dad-48c7-4ca1-a29a-f9a02a11a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.loc[[3,5,0], ['Result', 'Person']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02b169e-4bab-4478-a9f3-d27b0c62e13b",
   "metadata": {},
   "source": [
    "We can also perform a slice to extract contiguous columns from a DataFrame.  **Notice in the slice below, along other slices, we include the end value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f17ad2-287d-435b-91a7-14828a7e876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.loc[:, 'Person':'Subject']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b62add0-d11f-419f-ac9c-59c2a68f7000",
   "metadata": {},
   "source": [
    "Also, similar to `iloc()`, `loc()` can  accept boolean values to retrieve rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed70b7d8-dbf0-4b1f-9b57-951b48592c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the fist, second and last row\n",
    "tests.loc[[True, True, False, False, False, True]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b5e964-8f5c-4ffc-9b49-1ad3c0a4bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the fist, second and last row from the second column\n",
    "tests.loc[[True, True, False, False, False, True], [False, True, False]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c402bde6-de76-49f0-bc70-927b145dde40",
   "metadata": {},
   "source": [
    "So to summarise: `iloc()` accepts **positional information**, whereas `loc()` accepts **row and column index names**.  Often these will be the same since the default naming of a row / column follows the numbering convention 0, 1, 2,..  However, if this convention is not followed, or if a DataFrame is filtered or sorted then then **`iloc` and `loc` ids may not correspond to one another**.  The diagram below illustrates this point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538d5f2c-9939-4cdd-88a3-5cb19c648e75",
   "metadata": {},
   "source": [
    "<img src='course_images/loc_iloc_Schematic.svg' title='loc and iloc Schematic'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e90c400-ab62-420c-b968-c459078987a2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<b>Dot notation</b>\n",
    "\n",
    "You may encounter an alternative dot notation to access data from DataFrames, e.g.\n",
    "\n",
    "`tests.Result`\n",
    "\n",
    "We do not favour this naming convention as it may not work in some situations: such as if the desired column name is identical to a DataFrame property or if the column name contains spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15372806-871b-4cfa-8d08-f0b22e2e55f3",
   "metadata": {},
   "source": [
    "#### `head()` and `tail()`\n",
    "It is not feasible to print out large DataFrames in their entirety to the screen and so in such cases a Jupyter Notebook will only dislpay a subset of the data.  However, a user may simply be interested to view a small number of rows from the top or bottom of a DataFrame, which can be achieved with the `head()` or `tail()` methods respectively.\n",
    "\n",
    "Head is used to view the top of a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc66be5f-207d-42cc-be57-1ef695e11fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a2c229-3e1f-4842-845e-175589c4444d",
   "metadata": {},
   "source": [
    "By default, the row index and column headers are displayed, along with the first 5 rows of data.  (Admittedly this DataFrame is relatively small to begin with and so applying the `head()` method is of minimal use, but the point still stands.)\n",
    "\n",
    "The `head()` method may also be passed an integer argument to display a selected number of rows from the top of a DataFrame.\n",
    "\n",
    "Similarly, `tail()` is used to select from the bottom of a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41d35fb-bed1-4696-9f93-77c2253b4d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74470f64-2781-4c0a-987f-a48abc5d7f6b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>The <code>inplace</code> parameter</b>\n",
    "<br>\n",
    "<br>\n",
    "As you read the pandas documentation you will no doubt repeatedly encounter the parameter <code>inplace</code>.  When <code>inplace</code> is set to <code>True</code> the behaviour of a method is set so that it doesn't return anything, it instead modifies the original DataFrame.  (For most methods the <code>inplace</code> parameter is set to <code>False</code> by default).\n",
    "\n",
    "`df = df.my_method()`\n",
    "\n",
    "Instead, you can write this as:\n",
    "\n",
    "`df.my_method(inplace=True)`\n",
    "\n",
    "Which you choose is largely a matter of style.  Some coders find the latter less cluttered, particularly when a DataFrame is to undergo multiple manipulations.  However, the explicit use of the assignment operator can make it clearer that a DataFrame in undergoing changes, and this style will be adopted in this course.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0232db7c-cf7f-41a3-bbeb-c59d207a3cec",
   "metadata": {},
   "source": [
    "### Changing values\n",
    "Many of the concepts introduced with the Series object apply to DataFrames, including how to change pre-existing values by referencing the location to change and then assigning a new value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d68dbb6-3362-4ab7-9782-f8cf37aef302",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.loc[1, 'Result'] = 100\n",
    "tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5482a0a-73ab-41b0-9fc7-6dcefe58af02",
   "metadata": {},
   "source": [
    "Since we can select multiple DataFrame entries simultaneously, we can therefore change multiple DataFrame entries at simultaneously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f4373b-8ad5-4798-8fb1-072123fc8305",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tests.loc[[4, 5], 'Person'] = 'Dua Lipa'\n",
    "tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fa71a2-5b62-4c64-a520-308142a5f083",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "### Exercise 7\n",
    "\n",
    "**a1.**  Import the Seaborn Titanic test dataset.\n",
    "\n",
    "**a2.**  Use the `shape` attribute to report the number of rows and columns.\n",
    "\n",
    "**a3.**  Use the `info()` method to learn more about the dataset.\n",
    "\n",
    "**a4.**  Use `loc()` to print out the \"age\" column.\n",
    "\n",
    "**a5.**  Use `loc()` to print out the \"class\" and \"embark_town\" column\n",
    "\n",
    "**a6.**  Use `loc()` to print out the last 5 columns.\n",
    "\n",
    "**a7.**  Use `loc()` to print out the last 5 columns of the last 5 rows.\n",
    "\n",
    "**a8.**. Create a Boolean list and use it to print rows 2,4,6. - Need to make answer for this!\n",
    "\n",
    "<hr>\n",
    "\n",
    "**b1.**  Import the dataset file \"Biomass_of_Herbivorous_Fish.tsv\".\n",
    "\n",
    "**b2.**  View the top and bottom of the data with the `head()` and `tail()` methods.\n",
    "\n",
    "**b3.**  Use the `iloc()` method to print out the first three rows.\n",
    "\n",
    "**b4.**  Use `iloc()` to print out the second row and columns at **positions** 3, 5, 2 (in that order).\n",
    "\n",
    "**b5.**  Use `iloc()` to print bottom right-most element.\n",
    "\n",
    "**b6.**  Change the \"Shallow.Percentage\" value to 0 for all rows.\n",
    "\n",
    "<hr>\n",
    "\n",
    "**\\*c1.**  Import the file \"Premier_League_Final_Table_1999.txt\" into a DataFrame and append columns:\n",
    "\n",
    "i) \"GD\": Goal Difference (Goals For - Goals Against)\n",
    "\n",
    "ii) \"Pts\": Points (3 points for a win and 1 for a draw)\n",
    "\n",
    "Write out the modified table to an MS Excel file.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4183a2dc-b784-4823-b73d-3b950473b62c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sorting columns by values\n",
    "Often you will need to sort columns by their values, which can be done using the `sort_values()` method.  Specify the column by which you wish to sort the data. (Notice that the index values are sorted as well.) \n",
    "\n",
    "For columns containing any strings a lexicographical order is used to sort the data.  In contrast, if the column contains only numbers (or numbers and `NaN` values), then a numerical sort will be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f42002-5c47-4a03-b79b-e7ca6735350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.sort_values(by='Result')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45de93ee-280a-4956-a1a0-5a67018a43d5",
   "metadata": {},
   "source": [
    "It is possible to sort data by more than one column by passing a list of column names to use for sorting.  The data will be sorted by the first column in the list and any resulting ties will be resolved by then sorting the data by the second column in the list.  And so on. \n",
    "\n",
    "It is also possible to specify how the data should be sorted by passing boolean values to the `ascending` parameter (`True` means sort in ascending order, `False` means sort in descending order) .  \n",
    "\n",
    "To clarify, the example below sorts the data by the \"Person\" column in descending order and then by the \"Result\" column in ascending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0353e1-eb3c-4568-be64-4307f474dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.sort_values(by=['Person', 'Result'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7a4657-6b82-469b-961d-206b62916802",
   "metadata": {},
   "source": [
    "While we are discussing sorting by values, it is worth mentioning the `rank()` method that reports ordinal (1st, 2nd, 3rd,...) values of a given series.  In the example below we can see that the second row in the DataFrame would be in 1st place, were we to sort the \"Result\" column in descending order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2866d7-7933-45e9-80b2-a620ae13dad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tests['Result'])\n",
    "print()\n",
    "\n",
    "tests['Result'].rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c89e29-92f3-45b1-9944-dcae699e87ec",
   "metadata": {},
   "source": [
    "### Renaming rows and columns\n",
    "Column names can be set using the DataFrame attribute `columns`.  Simply pass the a Python list or a Series to rename all the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad545705-b04b-4413-a026-6a5fb1f9dbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.columns = ['ColA', 'ColB', 'ColC']\n",
    "tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d6e8d3-d183-47e0-bf64-e4079d92578c",
   "metadata": {},
   "source": [
    "It is also possible to change the **row** index of an existing DataFrame by using the `index` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1548ae18-9d6b-4e99-bf77-d6950c0c0c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.index = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b3e5dd-416f-4731-be09-ab42e1d46016",
   "metadata": {},
   "source": [
    "To rename the columns (or index values) you may find it easier to first extract the column names from the DataFrame, edit the desired entries, and then use this to rename the column names.\n",
    "\n",
    "Column names can in fact be retrieved using the DataFrame property `columns`.  This returns the column names as a pandas index which can then be converted to a Python list or a Pandas Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c558b9d4-31ac-4f2a-ba94-b441e90cb1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract column names\n",
    "column_names = tests.columns\n",
    "print(type(column_names))\n",
    "\n",
    "# Convert Pandas index to Pandas series\n",
    "column_names = column_names.to_list()\n",
    "print(type(column_names))\n",
    "print(column_names)\n",
    "\n",
    "# Edit the column names\n",
    "column_names[1] = 'Subject'\n",
    "print()\n",
    "\n",
    "# Use the columns property to rename the columns\n",
    "tests.columns = column_names\n",
    "print(tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7624d11-2035-4b8b-993a-34d1a36d33e5",
   "metadata": {},
   "source": [
    "Another way of renaming columns (and rows) is to use the `rename()` method.  This method is \"safer\" to use for it requires **both** the current index names and the new index names.  This approach makes it less likely that index names will be mislabelled - which is a catastrophic error.  \n",
    "\n",
    "The oldname-newname mapping is done using a Python dictionary.  Set the `axis` parameter to 0 to rename rows and set it to 1 to rename columns.  We shall rename the columns in the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5390a6f0-604e-49c9-866d-98275b046a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = tests.rename(mapper={'ColA' : 'Person', 'ColC' : 'Results'}, axis=1)\n",
    "tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f9f89a-8697-446b-9e22-530d5181e42a",
   "metadata": {},
   "source": [
    "### Calculations using DataFrames\n",
    "Also similar to Series, values in DataFrames may undergo mathematical operations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e95735-e0fe-40bc-80a8-07ac5679ef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)\n",
    "print()\n",
    "df2 = df * 10\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2752027-c9a8-4a36-8ae1-080cfa7d58b4",
   "metadata": {},
   "source": [
    "Here, the whole DataFrame has been multiplied by 10.  It is possible to perform mathematical operations on rows or columns by specifying the row or column explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98854888-5b9f-46c0-a2ba-d931cd7d4260",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['c'] = df['c'] / 3\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4912d42b-1e03-4e6a-9f1a-327a29ccf24b",
   "metadata": {},
   "source": [
    "As with Series that we encountered previously, we can perform mathematical operations on more than one DataFrame.  In the example below we add two DataFrames together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89df003-abde-4e9f-b8d3-9a0d93bcddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df + df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08352ca6-48f7-4d0d-aeb9-6c06813ba703",
   "metadata": {},
   "source": [
    "**But beware!**  As with Series, these mathematical operations take into account the index values and not the position within the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2171103-f2fb-4b82-97c8-2c9e3d50a483",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(\n",
    "        [[1, 2, 3],\n",
    "         [4, 5, 6],\n",
    "         [7, 8, 9]],\n",
    "    columns=['a', 'b', 'c'],\n",
    "    index = ['one', 'two', 'three'])\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "        [[9, 8, 7],\n",
    "         [6, 5, 4],\n",
    "         [3, 2, 1]],\n",
    "    columns=['c', 'b', 'a'],\n",
    "    index = ['three', 'two', 'one'])\n",
    "\n",
    "print(df1)\n",
    "print()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2910c996-b98e-4fac-b42f-009862fe633c",
   "metadata": {
    "tags": []
   },
   "source": [
    "If we add df1 to df2, we do not create a DataFrame which has values of all 10 since the **column names and row names are used to decide what value is added to which value**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcdff6c-e14c-49aa-a614-47daa96fb82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 + df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1592109b-de71-4cf1-bdd7-a7ea35328df4",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Handling `NaN` values in calculations**\n",
    "    \n",
    "It is worth mentioning at this point the behaviour of `NaN` values.  Performing a mathematical operation on a `NaN` will generated a `NaN`.  For example:\n",
    "\n",
    "`1 + 2 + 3 + 4 + NaN = NaN`\n",
    "\n",
    "So imagine you are adding together multiple DataFrames, of which some contain `NaN` values.  It is easy to see therefore how `NaN` may propagate with each successive addition of data.\n",
    "\n",
    "This behaviour may be desirable, but it may not and you need to decide how to handle `NaN` values - one regularly employed solution is to convert `NaN` values to 0.  You could do this to all the DataFrames to be analysed before performing the additions.  An alternative is to use the pandas methods to perform mathematical operations on DataFrames.\n",
    "\n",
    "`add()`\n",
    "`sub()`\n",
    "`mul()`\n",
    "`div()`\n",
    "`mod()`\n",
    "`pow()`\n",
    "\n",
    "Importantly, these methods have a parameter named `fill_values` which is used fill existing missing (`NaN`) values with this value before computation. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b797c7c9-9cef-40c8-98f3-145e4616c736",
   "metadata": {},
   "source": [
    "### Rounding\n",
    "\n",
    "In a previous example we divided the values in the column \"c\" by 3, which generated non-integer numbers.  To maintain a high degree of accuracy these non-integer values can be used in further calculations.  However, there are occasions when we need to round numbers, such as when presenting final summary results.  This can be achieved with the pandas `round()` method.  The method receives as an argument the number of decimal places required following rounding.  So, to round the `DataFrame` to 2 decimal places:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7b5c82-4503-406f-835f-906e377eb5cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebd98a1-c6cb-4f96-a4e6-29004b475b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now round\n",
    "df = df.round(2)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e952e7f-66e5-4066-b722-b787e1d098a9",
   "metadata": {},
   "source": [
    "## Deleting pandas objects\n",
    "\n",
    "While most modern computers have ample memory for most datasets, storage capacity is not infinite and so it may be prudent to delete no longer required pandas objects from RAM.  Also, keeping many unneeded objects can make your workspace cluttered and more prone to coding errors.  To delete pandas objects use the `del()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83084b52-ed65-4127-9785-0cfceaa82b15",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "# Cell raises exception - added \"raises-exception\" tag\n",
    "\n",
    "temp = [1, 2, 3]\n",
    "temp2 = [4, 5, 6]\n",
    "\n",
    "del([temp, temp2])   #Use del(temp) for 1 object at a time\n",
    "\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485dbe0c-6f03-4dc6-8eec-944dc4763f17",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Filtering\n",
    "\n",
    "### Using the subscript operator\n",
    "Series and DataFrames can be filtered.  If you look at the code below you will see that the DataFrame has been filtered to only include data where the \"Results\" column is greater than or equal to 80.\n",
    "\n",
    "A separate variable was created named 'filt' that stores boolean values.  This Series of booleans was then used to select the desired rows (remember from before that DataFrame rows can be selected in this way).\n",
    "\n",
    "(Notice that the filtered data is printed to the screen, but the original dataset is not modified.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9c3db8-57c0-4443-a5da-55555fc40e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = tests['Results'] >= 80     # Don't use the Python reserved word: \"filter\" \n",
    "print(filt)\n",
    "print()\n",
    "print(tests[filt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aba640-1fb3-4543-907b-912d71f1ce85",
   "metadata": {},
   "source": [
    "It is possible to simplify this by combing the two separate lines of code and dispensing with the filter variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87b059f-6d18-4bdc-9c7f-531577654574",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests[tests['Results'] >= 80]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014cd963-1cf9-4955-b817-6edd142c253c",
   "metadata": {},
   "source": [
    "In fact there are often many ways to achieve the same thing with coding and your choice will often be a trade-off between writing the fewest lines of code whist making each line of code easily understandable.  In this regard writing code is much like writing in English and you will develop your own style.\n",
    "\n",
    "#### Multi-conditional filtering\n",
    "A little more difficult are situations in which you need to filter on more than one term, but this can be achieved using Boolean evaluations that can be joined together with the and (`&`) / or (`|`) operators.\n",
    "\n",
    "These operators behave as the words \"and\" / \"or\" behave in the English language.  For example, to be able to drive a car in the UK you need to pass your theory test **and** practical test - both statements need to be true.  In contrast, a shop may accept either money **or** a credit card to buy an item - at least one statement needs to be true. \n",
    "\n",
    "Let's now demonstrate this using code where we want to retrieve test scores greater than or equal to 90, **and/or** any result for the subject \"Maths\".  This will require a multi-conditional filter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9bc2a5-b196-447e-89c1-308bf020173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c256ea-f72c-4476-8b81-5ed8c37237fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AND\n",
    "filt = (tests['Results'] >= 90) & (tests['Subject'] == 'Maths')\n",
    "tests[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4414f860-4e3f-4b6f-a85d-d9685da913fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR\n",
    "filt = (tests['Results'] >= 90) | (tests['Subject'] == 'Maths')\n",
    "tests[filt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd006332-b446-41a6-804c-cd5e25a7dd84",
   "metadata": {
    "tags": []
   },
   "source": [
    "We are making a Series of booleans named \"filt\", which will be passed to the tests DataFrame.  To make the filter, 2 logical tests have been performed: `tests['Results'] >= 95` and secondly `tests['Subject'] == 'Maths'`.  Both of these logical tests have been placed in round brackets to separate them.\n",
    "\n",
    "Either of these tests needs to be `True` for the filter (`filt`) to evaluate to `True`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94001585-8ade-41cd-98c3-70beeb68a364",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>A note on logical operators</b>\n",
    "<br>\n",
    "<br>\n",
    "You may be familiar with the Python logical operators <code>and</code> / <code>or</code>.  These will not work when comparing Ppndas Series/DataFrames, and so instead we need the Python logical <b>bitwise</b> operators.  We shan't explain the difference here, but the <b>bitwise and</b> is denoted by an ampersand (<code>&</code>) and the <b>bitwise or</b> is denoted by a pipe (<code>|</code>).  Usually, unless comparing Pandas objects or performing bitwise comparisons, you should use the <code>and</code> / <code>or</code> commands when writing Python code.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da1c995-1455-4c46-8f89-9f332d1fc2bb",
   "metadata": {},
   "source": [
    "Another useful feature to know is that tilde (`~`) operator which will invert `True` / `False` values in a Series/DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2454c1-a6c4-4bcb-abdb-924990b6e400",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests[~filt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0fa53b-1a4b-4d35-a4c6-eb0f855a95b8",
   "metadata": {},
   "source": [
    "### Using the `query()` method\n",
    "\n",
    "An alternative to this approach is to subset data is to use a DataFrame's in-built `query()` method.  To filter the `tests` DataFrame in which rows have a \"Results\" value of greater then or equal to 80, we would execute the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366a6e85-306c-4cda-8a18-ff11a9e5d144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tests.query('Results >= 80')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42473ae9-12ca-4116-96b3-7f31abc7bb8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Another query is shown below where we extract all the Maths results.  Any literal strings referenced in the query string will need to be placed in double quotes i.e the whole query is placed in single quotes, and literal values inside the query are placed in double-quotes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a949098-6f2d-41bd-8ead-6bd002f2f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.query('Subject == \"Maths\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdc2b87-8098-46e9-985b-26634e56ee6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "You will notice that the desired filtering expression is placed between speech marks.  Since the `query()` method is being performed on the `tests` DataFrame, pandas interprets \"Results\" as a column name within the DataFrame.  It is possible to pass variables to the `query()` method by prefixing them with the 'at' symbol (`@`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0063262d-e5e2-4cdf-bd0f-87579dddb79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 90\n",
    "tests.query('Results >= @threshold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb48c56-2278-4379-94a9-3ac5ee6f758b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Whichever approach you adapt is your decision and is a matter of style. We advise the `query()` method as I find it easier to read and can be chained to other methods (method chaining is described later in the course)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6610dbcd-0fac-4c39-a233-ca7f4ab4c39f",
   "metadata": {},
   "source": [
    "### Filtering using the `isin()` method\n",
    "The `isin()` method assess whether each element in Series/DataFrame is contained within some other collection object.  The method returns the results as a boolean Series. This is useful for sub-setting datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d907b366-e064-4a63-83e2-c1be3a1c8e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_select = ['Adele', 'Chesney', 'Dua Lipa']\n",
    "              \n",
    "filt = tests['Person'].isin(to_select)\n",
    "tests[filt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2164a0eb-8e13-436b-b44a-932deb854fa7",
   "metadata": {},
   "source": [
    "### Filtering using the `str.contains()` string method\n",
    "Another useful filtering method is to search the contents of each element of a DataFrame for a pattern.  For example, suppose we want to extract the results for all the People that contain a \"y\" in their name.  The method takes the lookup term as an argument and returns a boolean Series or boolean DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa61b083-faca-4247-a282-95b9a385e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = tests['Person'].str.contains('y')\n",
    "tests[filt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68f684c-a4a2-469c-8c9b-893683967cd4",
   "metadata": {},
   "source": [
    "### Removing duplicates\n",
    "Often you may need to remove rows that are duplicates.  For example, consider the following dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d3d613-3124-4618-866e-eadc2f0f35eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "exercise_data = sns.load_dataset('exercise')\n",
    "exercise_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133c9164-d761-4c7e-9cee-0c9911a9077e",
   "metadata": {},
   "source": [
    "Now, let's get the unique 'diet' / 'kind' combinations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767d1b7f-4788-4e0c-ad4f-8c1feb30ac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# De-duplicated data\n",
    "exercise_data.loc[:, ['diet', 'kind']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a869b8d2-0ac3-479b-956c-f47f964a2996",
   "metadata": {},
   "source": [
    "(In case it wasn't clear, when we say \"remove duplicates\" it is implied that we **retain one representative copy** of each duplicate in our final dataset.)\n",
    "\n",
    "Notice that we have joined together two methods during this de-duplication step.  The ability to join methods in this way is a useful feature of Python and pandas and is termed **method chaining.**\n",
    "\n",
    "We could de-duplicate a single DataFrame column - although of course, technically speaking, this is de-duplication a Series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd4ccc4-0b0b-4ef3-b0bc-936f1b336872",
   "metadata": {},
   "outputs": [],
   "source": [
    "exercise_data.loc[:, ['diet']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282129d8-9b98-4399-9f3c-3b4889c31eed",
   "metadata": {},
   "source": [
    "### Making new columns\n",
    "Creating a new column in a DataFrame is straight forwards.  Just specify the name of the new column along with the associated values. \n",
    "\n",
    "There are many ways to do this, but in the example below the new column is passed a Python list of values.  Since the DataFrame `tests` has already been created, it is understood that the Python list will be converted to a DataFrame column.  The new column will be appended to the right-hand side of the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf84d28-657b-4a02-a963-1377104f07c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests['Results2'] = [90, 91, 50, 72, 65, 47]\n",
    "tests['Results3'] = [67, 68, 35, 60, 63, 40]\n",
    "tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f3a4c0-2327-4aa1-88be-1434ee17323f",
   "metadata": {},
   "source": [
    "### Deleting rows and columns\n",
    "The `drop()` method is used to remove rows or columns from a DataFrame.  The user needs to specify the column/row labels (`labels` parameter) or column/row index values (`index` parameter).  The user also needs to pass the `axis` parameter value to specify whether rows or columns are to be removed.  These concepts are illustrated in the plots below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4704444b-d312-460c-9497-876fed2ec5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.drop(index=['A', 'B'], axis=0)    # Remove first two rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44723de-33ab-4761-80a4-565c0eabf6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = tests.drop(labels='Results3', axis=1)   # Remove the median column\n",
    "tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9745c81-cb5d-4191-9a8f-e9578798b742",
   "metadata": {},
   "source": [
    "Notice in the example above that a string value (rather than a Python list) was passed to the `labels` parameter.  This was allowed because a single column was removed, but if multiple columns need to be removed then a Python list needs to be passed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4b8d16-ba79-4d73-b9c7-8d3905c5e3c6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## Exercise 8\n",
    "**a1.** Re-import the data Herbivorous fish dataset.  Use the `sort()` method to sort the Deep.Mean.Biomass.\n",
    "\n",
    "**a2.**  Pass an argument to the `sort()` method so that \"Deep.Mean.Biomass\" is sorted from highest-to-lowest (rather than lowest-to-highest).\n",
    "\n",
    "**a3.**  Sort the data alphabetically by \"Family\" and then by \"Deep.Mean.Biomass\" (most to least)\n",
    "\n",
    "**a4.**  Use the `rank()` method to identify the greatest shallow percentage.\n",
    "\n",
    "**a5.**  Let's use proportions (relative to 1) rather than percentages (i.e. divide all the percentage columns by 100).\n",
    "\n",
    "**a6.**  Rename the percentage columns as appropriate.\n",
    "\n",
    "**a7.**  Round all the results to 1 decimal place.\n",
    "\n",
    "**a8.**  Create a new column that reports Deep.Mean.Biomass / Shallow.Mean_Biomass.  Name the column: \"Deep.Shallow.Ratio\".\n",
    "\n",
    "**a9.**  Produce a Series of the **unique** \"Family\" values (i.e. remove duplicates, retaining one representative copy).\n",
    "\n",
    "<hr>\n",
    "\n",
    "**b1.**  Import the \"Childrens_Indoor_Hobbies_During_Lockdown.csv\" into a DataFrame (notice this is a comma-separated values spreadsheet).\n",
    "\n",
    "**b2.**  Create a boolean series (`True` / `False`) representing rows where the 'Number' is greater than 100.  Filter the data using the boolean series.\n",
    "\n",
    "**b3.**  Create a boolean series (`True` / `False`) representing rows where the 'Number' is greater than 50 but less than 100. Filter the data using the boolean series.\n",
    "\n",
    "**b4.**  Retrieve the rows not returned above (hint: invert the boolean series with `~`).\n",
    "\n",
    "**b5.**  Use the `query()` method to return the value where Indoor.Hobby is \"Computer\"\n",
    "\n",
    "**b6.**  Use the `isin()` method to returns rows where Indoor.Hobby is any of \"Lego\", \"Toys\", \"Puzzles and Games\" or \"Buckaroo\".\n",
    "\n",
    "**b7.**  Use the `srt.contains()` method to return rows where Indoor.Hobby contains \"Video\".\n",
    "\n",
    "**b8.**  Delete the \"Percent\" column from the DataFrame.\n",
    "\n",
    "<hr>\n",
    "\n",
    "**\\*c1.** Take a dataset of your own and import it into a pandas DataFrame.  Try sorting it and filtering it and outputting fresh results.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b36bd66-28a1-4ab6-937a-7515d603bb41",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Handling missing values\n",
    "It is common for a dataset to be missing one or more expected datapoints.  In such cases, you will need to decide how to handle missing data.  \n",
    "\n",
    "In pandas, missing values have a special value and will be represented in Series or DataFrames as `NaN`.  **Please note: `NaN` is not a string value, it is a different data type.**\n",
    "\n",
    "To illustrate this point, let's import the \"penguins\" Seaborn sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146fd733-185a-4a54-b2e1-70a2b3e24fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = sns.load_dataset('penguins')\n",
    "penguins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973c0e11-91aa-4394-bf87-f9b74375845e",
   "metadata": {},
   "source": [
    "You will see the \"bill_length_mm\" column, among others, has missing data points, which are rendered to the screen as \"NaN\".  You can check whether a DataFrame contains any `NaN` values with the `isnull()` method.  This will convert the output to a boolean i.e. `NaN` values are rendered as `True`, whereas anything else is rendered as `False`.  You then need to use the method `any()` to list as a boolean any columns containing a `True` value.  Using the method again will assess whether any values in the DataFrame are `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdfde91-e866-4fe8-943d-5cff375eee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a52dbe-3208-4c7f-9af9-d04122689c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82479d27-b84e-4a5a-82be-f73cf7b85d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77205bd-d5ab-4371-a3d8-5001420b57e6",
   "metadata": {},
   "source": [
    "What should you do once you have identified `NaN` values?  Well, you could ignore them.  By default most methods will exclude them in calculations - it will be as if they do not exists.  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce779fe-32c0-4428-b511-390f6b048359",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins['bill_length_mm'].median() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31a047d-52e6-4e92-ad6a-b2c8cc95f58b",
   "metadata": {},
   "source": [
    "However, you may not wish to do this.  It is quite common for `NaN` values to be treated as zeros. Fortunately, pandas allows you to simply convert `NaN` values to 0 (or any other desired value) with the `fillna()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2e514e-e246-4199-9a6c-44ae7816ee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4060623e-2110-48ae-84b0-18a923f12cad",
   "metadata": {},
   "source": [
    "Alternatively, it may simplify subsequent analysis if any rows containing `NaN` are removed, which can be achieved with the `dropna()` method: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256b214b-c6f6-46d8-a2f1-6d4a71449a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7cc46c-b2c9-438d-bd99-2cf0aca61094",
   "metadata": {},
   "source": [
    "Of course, you may need to be more discriminating in the way you discard data.  The `dropna()` method by default removes rows that contain **any** `NaN` values.  Perhaps what is actually required is to remove rows that contain **all** `NaN` values.  This can be achieved by adjusting the `how` parameter of the `dropna()` method.  Alternatively, it may be the presence of `NaN` entries in only specific columns that causes problems.  If that is the case, the `subset` parameter should be used.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985547a9-2d3d-453b-84fb-ac5ab8571a98",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "**Method Chaining Styles**\n",
    "\n",
    "In this chapter we encountered method chaining whereby 3 methods where chained in one line of code :\\\n",
    "`penguins = penguins.isnull().any().any()`\n",
    "\n",
    "This is a useful feature of Python and pandas and enables us to write more succinct code.  Without it, we would have to have written 3 separate commands:\n",
    "\n",
    "`penguins = penguins.isnull()` \\\n",
    "`penguins = penguins.any()` \\\n",
    "`penguins = penguins.any()` \n",
    "\n",
    "Using method chaining is advantageous in that it reduces the need to write cumbersome code, but on the downside, as more methods are chained together, the code becomes more difficult to read.\n",
    "\n",
    "It is best to get the best of both words by adopting the method chaining styling of <b>method cascading</b>, as shown below:\n",
    "\n",
    "`penguins = (penguins`          \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`.isnull()`\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`.any()`\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`.any()`\\\n",
    "`)`\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36c3228-e8ff-4a1e-afc6-685974741b48",
   "metadata": {},
   "source": [
    "## Replacing values\n",
    "\n",
    "### `replace()` method\n",
    "Specific values can be renamed in Series or DataFrame using the `replace()` method.  In the example below, \"Male\" has been abbreviated to \"M\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7a9212-cba0-4880-aa27-b3537a34dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins['sex'].replace('Male', 'M')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bff130-da52-4d70-8f1c-590505f5dafa",
   "metadata": {},
   "source": [
    "It is also possible to rename more than one value simultaneously by passing a Python dictionary to the `rename()` method.  The dictionary should store the old value / new value as key-value pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e18641-fc06-4375-aad8-620842c23345",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins['sex'].replace({'Male' : 'M', 'Female' : 'F'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f39da8-467b-4b82-9019-a50d6bd6b07c",
   "metadata": {},
   "source": [
    "Values not specified will remain unaltered.\n",
    "\n",
    "### `str.replace()` method\n",
    "This is similar to the `replace()` method except it requires only a partial match rather than an exact match for the whole contents of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ecb425-7244-40a4-89a1-a6e2e466f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins['sex'].str.replace('ale', 'ALE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9825ebb8-3922-43ba-989a-c1d01fdb2db7",
   "metadata": {},
   "source": [
    "If \"ale\" is found anywhere in the column it is converted to \"ALE\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00de0f4-4113-4261-a890-efaad5efd510",
   "metadata": {},
   "source": [
    "## Casting values\n",
    "Earlier in the course, when we introduced Python, we mention that there are different data types.  This also applies to pandas, in which Series and DataFrames can store different types of values - such as integers, floats, strings and booleans.  This is not just of academic interest, for how data is stored directly impacts the operations that can be performed on it.  \n",
    "\n",
    "Look at the DataFrame below that stores the lengths of various bacterial species.  It is intended that the data has been stored in scientific notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd57a4ef-798c-4d73-8241-8a46f476c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "bacteria = pd.DataFrame({'Species': ['E. coli', 'Staphylococcus aureus', 'Bacillus anthracis'], 'Length': ['2E-3', '2E-3', '5E-3']})\n",
    "bacteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f68958-da70-448e-ab9f-23422b7c2146",
   "metadata": {
    "tags": []
   },
   "source": [
    "However, trying to obtain the mean value of these lengths raises an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550455fa-7d58-4ea4-86b7-7693479d0d2f",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "# Generates error: applied raises-exception cell tag\n",
    "bacteria['Length'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990f2ab0-b386-47f2-b041-c13136bf7c1e",
   "metadata": {},
   "source": [
    "Why is this happening?  Well, if we investigate the data types stored in the DataFrame we see that the Length column is storing \"object\" data, whereas we would have expected to report \"float\", which is how numbers generated using scientific notation are stored.\n",
    "\n",
    "(If you look at the DataFrame construction code you will see that the lengths have been input as strings rather than floats.  You could change this code, but we are demonstrating how to handle data presented in the wrong format - which is not unreasonable since results from external sources often needs \"cleaning up\" before analysis can begin.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2296c2-1813-4ca9-8d1d-3c052dfd6c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "bacteria.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c001222b-2a57-4e9d-b04c-b18675de2bd2",
   "metadata": {},
   "source": [
    "What we need to do is convert the data from the current type to the `float` datatype.  As mentioned before, this process of converting one datatype to another is known as **casting**.  It is achieved in pandas using the `astype()` method, which takes as an argument the target data type.  So, to convert elements in the \"Length\" column to floats run the command: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f1d4b8-3739-4431-b027-4e7c971b3339",
   "metadata": {},
   "outputs": [],
   "source": [
    "bacteria['Length'] = bacteria['Length'].astype(float)\n",
    "bacteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa40b241-7a6e-40d4-ba41-f349071e189b",
   "metadata": {},
   "source": [
    "Notice now that data in the \"Length\" column are now rendered as numbers e.g. \"2E-3\" is displayed as \"0.002\".  And as might be expected, the `dtypes` property now reports that the \"Length\" column holds floats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1514a763-9e63-4f8a-bc14-ee324f14fac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bacteria.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d9dec5-e885-4df4-a61d-93c6f64aa6f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "The `mean()` method can now be run on the \"Length\" column without any problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b692f454-89f0-47a5-b588-f338f8e19a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "bacteria['Length'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b303ad-f2de-4734-abe0-b7c894149a56",
   "metadata": {},
   "source": [
    "When importing from a file, pandas will make its best guess on what data type to use for each column. This will often work out fine, but sometimes an inappropriate data type will be chosen.  In such situations you could write code to cast the offending column to another data type.  Alternatively, it is possible to specify the most appropriate datatype on import.\n",
    "\n",
    "In the example below, the code when executed will import data from a comma-separated text file.  The `dtype` parameter ensures that data in the 'Chromosome' column is stored in memory as a string type.  (This example was chosen advisedly since mis-assigning chromosomes to integers is common when importing data from a file, since most chromosomes have numerical values.)  \n",
    "\n",
    "`imported_data = pd.read_csv(filename, dtype={'Chromosome' : str})`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075edfe1-8f1e-4612-af57-4195c63fc61b",
   "metadata": {},
   "source": [
    "## Manipulations using indexes\n",
    "\n",
    "### Sort by index name\n",
    "It is possible to sort a DataFrame by using the `sort_index()` method.  It takes as arguments the axis (default=0) to sort by, and whether to sort ascending (default) or descending using a boolean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2405e720-255d-49bf-bd57-e27e4b744f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.sort_index(axis=0, ascending=False)   # Sort by rows index values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1261d17c-ed0a-4fcc-8181-32b768fdd189",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.sort_index(axis=1, ascending=False)     # Sort by columns index values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bad9b36-fc88-462d-81a2-479bfee6fb26",
   "metadata": {},
   "source": [
    "Sometimes we may want to do more complex sorting.  However, we may not always want to type out explicitly the column names in our code as this can take a relatively long time, particularly for large datasets. Moreover, we simply may not know in advance the names of the columns and so we need to reference them in some other way. This is where the `columns` property of a DataFrame comes to our aid for it allows us to manipulate the order of the column names without the need for specifying them by name in the code.\n",
    "\n",
    "The example below uses index values to select columns. The column names from the DataFrame are extracted as an index object which is then parsed to a Python list. We then build a new Python list by using a custom order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ab0d53-8449-4ca7-8d08-003311931187",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_order = tests.columns.to_list()\n",
    "columns_order = [columns_order[1], columns_order[2], columns_order[0]]\n",
    "tests.loc[:, columns_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a038c-c329-42c0-9129-70a3aa030a5b",
   "metadata": {},
   "source": [
    "It is not so clear why this is useful for this small DataFrame, but suppose you were working with a DataFrame of 100 columns.  With this notation you could select the last 75 columns to be followed by the first 25 columns in one line of code.\n",
    "\n",
    "You may have noticed at this point that you are not obliged to select all the columns from the DataFrame and indeed this is a convenient way to remove columns.  This is illustrated in the example below. \n",
    "\n",
    "(The `drop()` method provides another way to remove unwanted rows and columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec97a5d9-7728-4a20-aa8c-cfeba74fdfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_order = tests.columns.to_list()\n",
    "columns_order = [columns_order[2], columns_order[0]]\n",
    "tests.loc[:, columns_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36320047-5f7a-43c0-b3e4-7d6f1d672f87",
   "metadata": {},
   "source": [
    "### Re-indexing\n",
    "Do you remember earlier in the course when we sorted by the contents of a column DataFrame and this in turn re-arranged the index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec12064-80d4-4cef-805c-51f221a5adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = tests.sort_values(by='Subject')\n",
    "tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81566bcc-3080-41c1-a09c-03af8a0ae586",
   "metadata": {
    "tags": []
   },
   "source": [
    "This is expected behaviour but it might not be desirable and for future analysis we may want to have a row index that increments by one as we move down the DataFrame.  To refresh the row index so that it increments by one use the `reset_index()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf63aac-c766-4f60-bb2a-a2c990f0a69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579619b2-5226-4373-9373-5ed023b9396c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Wait, what just happened?  This method has introduced a new column named \"index\".  Well, the `reset_index()` method not only generates a new index, but it also inserts into the DataFrame a new column containing the values of the previous index.  If this inserted column is not needed then set the parameter `drop=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f1618b-4fb6-44d9-8064-4e8b70f0e098",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = tests.reset_index(drop=True)\n",
    "tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0051ab7f-78f4-432d-89b5-974760c7d564",
   "metadata": {},
   "source": [
    "## Applying functions\n",
    "A powerful feature of pandas is the capability to apply a function to a Series or DataFrame using the aptly named `apply()` method.\n",
    "\n",
    "To see how this works let's suppose we want to know the length of the items in the first column in a DataFrame.  The `apply()` method takes as an argument the name of the function to run.\n",
    "\n",
    "### Applying built-in Python functions\n",
    "In the following cell you will see we have applied the Python function `len()` to determine the length of the strings in the first column of a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c49b8c-66b2-4e24-9b25-49d18d69960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_sequences = pd.DataFrame([['A', 'GA', 'CAG'], ['TTTT', 'CGGCC', 'TATGCA']])\n",
    "print(dna_sequences)\n",
    "print()\n",
    "\n",
    "dna_sequences.iloc[:, 0].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb57c3f2-20db-4feb-9574-bf344a7f65a3",
   "metadata": {},
   "source": [
    "Perhaps surprisingly, if you use this method on the whole DataFrame the length of each element will not be returned, but rather the length of each DataFrame row will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00b0079-c567-4a0e-a6fe-b183bc79ab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_sequences.apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552ec829-7ef8-44a2-a277-d56c155de8f9",
   "metadata": {},
   "source": [
    "To ascertain the length of each element within the DataFrame a related method, named `applymap()`, should be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbce6331-d2be-4285-8c84-4f2e4b1b3f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_sequences.applymap(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09abea8e-bd0e-4e7e-88e7-0af4ac6fab0c",
   "metadata": {},
   "source": [
    "### Applying user-defined functions\n",
    "It is possible to define your own functions in Python.  We shall discuss this point briefly as it highlights the power of using Python and pandas to analyse data.\n",
    "\n",
    "Python functions have this basic structure:\n",
    "\n",
    "    def function_name(any_arguments):\n",
    "        function body\n",
    "        return value\n",
    "\n",
    "In the example below the function returns the percentage GC content of a DNA sequence.  The `def` command is used to define the new function, which is named \"gc_content\" and takes an argument (the DNA sequence string) which will be named \"seq\" internally within the function.  \n",
    "\n",
    "The in-built Python method `count()` is then used to determine the number of \"G\" and \"C\" characters within the DNA sequence string.  The length of the string is also determined with the in-built Python function `len()`.  These three values are then used to calculate the percentage GC content of the DNA sequence.  This value is passed back from the function using the `return` command.  Note that function code is indented by four spaces to separate it from the rest of the Jupyter cell's contents.\n",
    "\n",
    "In the main body of the code, the user-defined function `gc_content` is applied to every element of the DataFrame using the `applymap()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3ea7f0-4bf5-4c90-99b4-79af9186a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to determine GC content\n",
    "def gc_content(seq):\n",
    "    g_count = seq.count('G')\n",
    "    c_count = seq.count('C')\n",
    "    perc_gc = 100 * (g_count + c_count) / len(seq)\n",
    "    return perc_gc\n",
    "    \n",
    "# Apply the function\n",
    "dna_sequences.applymap(gc_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a7bad8-1176-4121-94ff-5b0f9372fd19",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Indentation</b>\n",
    "<br>\n",
    "<br>\n",
    "Indentation is a key concept in Python, for indenting code in this way tells the Python interpreter how the code is structured into different \"code blocs\".  When indenting code, use 4 spaces for each indentation.\n",
    "<br>  \n",
    "<br>\n",
    "While we barely touch on this idea in the course, it is worth knowing as you expand your Python knowledge.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c271950-f089-4d47-93ac-441f2bb2a37e",
   "metadata": {},
   "source": [
    "## Understanding views and copies\n",
    "Before we start looking at summarising and combining DataFrames we should introduce the important pandas concept of **views** and **copies**.  To begin with, look at the following Python code (no pandas yet) and see if it makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b673071-3e1b-4d07-9af7-645a5d46c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two Python lists:\n",
    "my_list = ['A', 'B', 'C']\n",
    "my_list2 = my_list\n",
    "\n",
    "print(my_list)\n",
    "print(my_list2)\n",
    "print()\n",
    "\n",
    "# Modify the first list\n",
    "my_list[0] = 'D'\n",
    "\n",
    "print(my_list)\n",
    "print(my_list2)\n",
    "print()\n",
    "\n",
    "# Modify the second list\n",
    "my_list2[1] = 'E'\n",
    "\n",
    "print(my_list)\n",
    "print(my_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13421488-232a-4357-9f2d-8feff1ed0fbe",
   "metadata": {},
   "source": [
    "This behaviour may have taken you by surprise.  We have created a list (`my_list`), and then seemingly made a copy of this list (`my_list2`).  However, when we modify the original list we also modify the second list, and vice versa.  It is as though the two lists are magically linked.\n",
    "\n",
    "The reason for this is that the new list is referencing (or pointing to) the original object.  This can be demonstrated by using the Python `id()` function which returns a unique identification value of the object stored in the memory.  You will see that the two lists correspond to the same object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3cfcb3-9a78-42a3-bb36-002ace38e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the ids of the two lists\n",
    "print(id(my_list))\n",
    "print(id(my_list2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad85cb79-2718-4225-8810-e9f3ba7630aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "So, how would we create an entirely independent copy?  Well to do this use the list `copy()` method.  You will now see in the code below that changes made to one of the lists does not now affect the other.  Also, the two list objects have different object ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9988cf-2d79-454b-a3b6-6739b647e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two Python lists:\n",
    "my_list = ['A', 'B', 'C']\n",
    "my_list2 = my_list.copy()    # Use the copy() method\n",
    "\n",
    "print(my_list)\n",
    "print(my_list2)\n",
    "print()\n",
    "\n",
    "# Modify the first list\n",
    "my_list[0] = 'D'\n",
    "\n",
    "print(my_list)\n",
    "print(my_list2)\n",
    "print()\n",
    "\n",
    "# Modify the second list\n",
    "my_list2[1] = 'E'\n",
    "\n",
    "print(my_list)\n",
    "print(my_list2)\n",
    "print()\n",
    "\n",
    "# Print the ids of the two lists\n",
    "print(id(my_list))\n",
    "print(id(my_list2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c0470f-eaa1-49e1-b1bf-485b8ebc6254",
   "metadata": {
    "tags": []
   },
   "source": [
    "Pandas objects exhibit a similiar behaviour, as illustrated by the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d5d865-6d22-4236-a801-c6edea6ec789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two Pandas DataFrames:\n",
    "df = pd.DataFrame([['A', 'B', 'C'], ['D', 'E', 'F']])\n",
    "df2 = df    # Makes a 'view' on the original dataframe\n",
    "\n",
    "print(df)\n",
    "print()\n",
    "print(df2)\n",
    "print()\n",
    "\n",
    "# Modify the first list\n",
    "df.iloc[0, 0] = 'X'\n",
    "\n",
    "print(df)\n",
    "print()\n",
    "print(df2)\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Modify the second list\n",
    "df2.iloc[1, 2] = 'Y'\n",
    "\n",
    "print(df)\n",
    "print()\n",
    "print(df2)\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Print the ids of the two lists\n",
    "print(id(df))\n",
    "print(id(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73882bdf-a7bd-4168-bcc3-0b183f1d5df5",
   "metadata": {},
   "source": [
    "Like with lists in regular Python, we use the `copy()` method of a pandas DataFrame (or indeed a Series) to create independent replicate objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fc6047-5c55-4a38-ab21-7f271318d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two Pandas DataFrames:\n",
    "df = pd.DataFrame([['A', 'B', 'C'], ['D', 'E', 'F']])\n",
    "df2 = df.copy()    # Makes a 'copy' on the original dataframe\n",
    "\n",
    "print(df)\n",
    "print()\n",
    "print(df2)\n",
    "print()\n",
    "\n",
    "# Modify the first list\n",
    "df.iloc[0, 0] = 'X'\n",
    "\n",
    "print(df)\n",
    "print()\n",
    "print(df2)\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Modify the second list\n",
    "df2.iloc[1, 2] = 'Y'\n",
    "\n",
    "print(df)\n",
    "print()\n",
    "print(df2)\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Print the ids of the two lists\n",
    "print(id(df))\n",
    "print(id(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66027301-b39f-4ca7-90c9-0ac7f0876330",
   "metadata": {},
   "source": [
    "Why does this matter?  Well suppose you aren't aware of this behaviour and then you go ahead and make a view on a Pandas DataFrame structure.  You then modify this view without realising you have modified the original DataFrame.  You then perform some calculations on the original DataFrame and this analysis may now be incorrect because you accidentally modified the data.\n",
    "\n",
    "In fact the situation is even more hazardous since extracting a Series from a DataFrame also creates a view on that DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2687dac-bc09-471e-965e-debefae81aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_view = df[0]      # Create series from data frame\n",
    "print(series_view)\n",
    "print()\n",
    "\n",
    "print(id(df))            # The series and DataFrame have different ids\n",
    "print(id(series_view))\n",
    "print()\n",
    "\n",
    "series_view[0] = 'Z'    # But, changing the series view changes the original DataFrame!\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "df.iloc[1, 0] = '!'    # And vice versa\n",
    "print(series_view)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61738a00-24c8-4480-a58f-3f5f9c45e895",
   "metadata": {},
   "source": [
    "This feature of pandas can catch out the novice and even those familiar with the language.  Unfortunately the rules that govern whether a view or a copy of a pandas data structure is returned following the use of the assignment operator (=) is complex and depends on the data types contained within the pandas object.  Pandas does try to help you by raising warnings if changes are made to an object with an associated view, but not always!  \n",
    "\n",
    "** With this in mind, we advise that if you take a subset for any purpose other than immediately analysing, then you should do so by using the `copy()` method. **\n",
    "\n",
    "(Those a little more experienced with computing may be aware that making such copies places more demands on computational resources than making a view.  Nevertheless this is only usually problematic when dealing with very large datasets and so for most purposes erring on the side a caution and making a copy is less likely to cause you problems.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f47e388-19ae-441e-b126-65f967c06982",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    " Just to reiterate this point: <b>we advise that if you take a subset or a copy of Series/DataFrame for any purpose other than immediately analysing, you should do so by using the <code>copy()</code> method.</b>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535b1fdb-1e8f-4089-88d7-2bdd5639fc84",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## Exercise 9\n",
    "**a1.**  Import the \"Biomass_of_Herbivorous_Fish.tsv\" dataset once again. You should be able to see missing values.  Confirm this with the `isnull()` method.\n",
    "\n",
    "**a2.**  Decide how you want to deal with the rows containing `NaN`.  Either convert the `NaN` values to 0 with the `fillna()` method or remove the offending rows with the `dropna()` method.\n",
    "\n",
    "**a3.**  Let's abbreviate the \"Morpho.Functional.Group\".  Remove \"ivore\" from all entries using the `str.replace()` method.  (Hint: removing text is the same as replacing it with '').\n",
    "\n",
    "**a4.**  On further thoughts, let's just use the first letter of each \"Morpho.Functional.Group\".  Use the `replace()` method to do this.\n",
    "\n",
    "<hr>\n",
    "\n",
    "**b1.**  Let's import the children's indoor hobbies again and then sort the DataFrame by \"Number\" (most-to-least).  Notice the index numbers no longer increment by 1. Let's fix this with the `reset_index()` method (remember to drop the original index values).\n",
    "\n",
    "**b2.**  Convert all the hobby counts to binary values using the `applymap()` method and the Python `bin()` function.\n",
    "\n",
    "**b3.**  Make the hobby name the index of the DataFrame by setting the index attribute of the DataFrame.  (Prior to doing this, convert space (' '), ampersand('&') and forward slash  '/' to the underscore (_) character.)\n",
    "\n",
    "<hr>\n",
    "\n",
    "**\\*c1.** Write a function that performs the text editing steps described in b3.  Use this function on the \"Hobby\" column.\n",
    "\n",
    "**\\*c2.**  Import some of your own data into a DataFrame.  Create a novel function to analyse the data.     \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c9ce8b-8f9b-40b8-b7f0-150e03996a43",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Summarising Data\n",
    "### describe()\n",
    "\n",
    "Pandas DataFrame objects have a useful method named `describe()` to summarise datasets.  The method returns a DataFrame listing useful information such as a count of the number of variables as well as mean, standard deviation, maximum, minimum and quartile values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d04db4-c0e8-4290-9e81-484b9036eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773e5e3-0feb-419b-b0ad-b6048aca140a",
   "metadata": {},
   "source": [
    "### Summarising rows and columns\n",
    "Pandas puts at your disposal a large variety of methods for analysing datasets.  Imagine that you need to know the **median** values for categories in a dataset, how would you go about obtaining this?  Well, firstly you need to extract the columns of interest i.e. all the numerical values that are to be included in the calculation of the median (which in this example is the columns named 'Results' and 'Results2').  Then the `median()` method is applied to the extracted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a17a79-cf48-4d5e-ad25-b41bbb980333",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.iloc[:, 2:].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903efb19-2df3-452f-86c7-4845106470a9",
   "metadata": {},
   "source": [
    "That has indeed returned the median values for each column.  But suppose we need the median values for each row.  How do we do this?  Well, we use the same method, we just apply it in a different way.\n",
    "\n",
    "By consulting the Pandas documentation (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.median.html) you will observe that the `median()` method may be passed the named parameter: `axis`.  This determines whether the median method is applied in a **row-wise** or a **column-wise** fashion.  Column-wise is the default, so let's explicitly tell Pandas to calculate median values in a row-wise manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e341ac-39e7-43b7-8d3e-21ff9ef3cf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.iloc[:, 2:].median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d720cbc5-7fc0-4b0a-af4b-dd4a635c293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests['Median'] = tests.iloc[:, 2:].median(axis=1)\n",
    "tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e02d12-0f1e-4f7f-bb2f-fe6b617047ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "Typically we would want to add this new summany value to our DataFrame:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42634837-427b-4d5b-ad9a-4b27205e4771",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>DataFrame Axis</b>\n",
    "<br>\n",
    "<br>    \n",
    "Instructing a method which axis to use is required time and time again in pandas:\n",
    "\n",
    "0 - horizontal axis i.e. rows \n",
    "<br>\n",
    "1 - vertical axis i.e. columns\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505ba46d-c254-4831-96fa-19b1a5fc27c2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "The official pandas documentation is found online at:\n",
    "\n",
    "https://pandas.pydata.org/docs/\n",
    "\n",
    "Here you can find accurate and complete information on pandas.  While it is always a worthwhile resource to consult, this canonical documentation can be a little jargon-heavy for the novice and so consulting other online sites (e.g. computing help forums) may give a easier-to-interpret advice.  Most pandas questions can usually be answered by using the official documentation in conjunction with more informal web pages.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623b1221-a4c7-4d19-a961-7369d02b65d1",
   "metadata": {},
   "source": [
    "### Tallying results with the `value_counts()` method\n",
    "\n",
    "Tallying the number of identical entries in a dataset is often needed, so let's see how to do this using the Penguins test data set we imported previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a43125-89dc-41d0-bb57-42535bf2ba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74a249b-1b1a-42db-bb46-8fb71b0ac42e",
   "metadata": {},
   "source": [
    "Suppose we wanted to know how many penguins there are of each species.  Well, we can find this out using the `value_counts()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1053d728-6c0b-46ec-be6d-70996b74f168",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins['species'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5f2dcb-f05a-4739-a82f-83e404a73884",
   "metadata": {},
   "source": [
    "In fact this method is more versatile, as it can be used to return combinations of values.  For example, suppose we wanted a tally of penguins on each island, broken down by species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e629d88e-9ce3-4fec-8388-11c19d11f9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.loc[:, ['island', 'species']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336f7ba2-fad6-4f31-804b-7fe211af453a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Grouping data\n",
    "Pandas has a useful feature for summarising data known as the `GroupBy` object.  To see how it works let's look once again at the Iris dataset we used earlier.\n",
    "\n",
    "The dataset is a favourite of people working in the area of machine learning and it contains length and width measurements for petals and sepals for 3 different species of flower, namely: serosa, versicolor and virginica.  Typically this dataset is used to build flower classification models.  We won't be doing that here, but we will be using the `GroupBy` object to summarise the data.\n",
    "\n",
    "The species column is what is of interest to us i.e. we want to summarise the data for each of the three different species of Iris (setosa, versicolor and virginica).  So, firstly we need to create the relevant  object using the `groupby()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fc86fe-a3c8-4f1e-a424-6aaeaccaf35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_grouped = iris.groupby(by='species')\n",
    "species_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f23288b-5836-4fb4-a0f1-508cc8a62325",
   "metadata": {},
   "source": [
    "Once we have created a `GroupBy` object, it is possible to retrieve all the data for a given group using the `get_group()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636b1f19-d87c-4b3c-b5a8-d3fc1094ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_grouped.get_group('setosa')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e09fa1-22a0-41fa-b144-b2e6ed14e495",
   "metadata": {},
   "source": [
    "The `GroupBy` object provides us with powerful tools to summarise data.  Suppose one wanted to know the mean of each species, running the `mean()` method on this object would return this information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dd6dae-7512-4ab5-b50b-b4d93b9521b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_grouped.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87669c15-2ad3-4a54-ab59-be4096f01312",
   "metadata": {},
   "source": [
    "It is also possible to apply more that one calculation to the `GroupBy` object using the `agg()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5f1079-7a68-44d0-a0da-363ca3aaf653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "species_grouped.agg([max, min])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73372d67-8508-4688-9d99-de0368a8f5f5",
   "metadata": {},
   "source": [
    "(Note: the `agg()` method will accept a function as an argument (as above) or a string function name (as below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30587303-808f-4e47-90b2-69e980513504",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_grouped.agg(['max', 'min'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd6a6ef-25be-4a37-ab5c-3fad44495b6c",
   "metadata": {},
   "source": [
    "## Combining DataFrames / Series\n",
    "\n",
    "### Appending with `concat()`\n",
    "The `concat()` method provides a simple way to append one DataFrame (or Series) to another.  The concatenation may be performed in a row-wise (`axis=0`) or column-wise (`axis=1`) fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eabeea-3a6e-4951-bf20-f89347e077f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'Person': ['Herbert', 'Frederick', 'Percival'], 'Age': [10, 9, 10]})\n",
    "df2 = pd.DataFrame({'Person': ['Sydney', 'Percival', 'Cuthbert'], 'Age': [8, 10, 9]})\n",
    "\n",
    "pd.concat([df1, df2], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce911cf3-7990-4d20-b357-4f65719cd526",
   "metadata": {},
   "source": [
    "You can see in the example above that the DataFrames that need combining have been passed to the `concat()` method all together inside a Python list.  Multiple DataFrames and/or Series can be passed in this way, and will be joined together in the order specified in the list.  Notice that the original row index values have been retained.  Also, \"Percival\", which is present in both input DataFrames is present twice.  We simply have combined one dataset to another.\n",
    "\n",
    "In the example below we repeat this concatenation, but have and additional 'Height' column.  The result is probably what you would expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99331002-01c3-4937-b41b-0bc507eff77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'Person': ['Herbert', 'Frederick', 'Percival'], 'Age': [10, 9, 10], 'Height' : [120, 110, 140]})\n",
    "df2 = pd.DataFrame({'Person': ['Sydney', 'Percival', 'Cuthbert'], 'Age': [8, 10, 9], 'Height' : [105, 140, 130]})\n",
    "\n",
    "pd.concat([df1, df2], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b58c3e-9806-4ccf-8fc4-4e6f45dd34ba",
   "metadata": {},
   "source": [
    "Now suppose a column is found in one DataFrame, but not the another; what will happen when we concatenate the pair?  Well you can see below that the resulting \"missing\" values are assigned the value `NaN` by pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2973bde3-f86d-40dd-9ec3-bf2c24c9093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'Person': ['Herbert', 'Frederick', 'Percival'], 'Age': [10, 9, 10]})         # Age only\n",
    "df2 = pd.DataFrame({'Person': ['Sydney', 'Percival', 'Cuthbert'], 'Height' : [105, 140, 130]})   # Height only\n",
    "\n",
    "pd.concat([df1, df2], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d60cb3-fa36-434c-bc9c-d1ac600219a8",
   "metadata": {},
   "source": [
    "Let's see how the behaviour is changed if we join by columns (axis=1).  You will observe that a four-column DataFrame is created, with the Person and Age columns repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d31acbd-16e2-456e-85e7-79ebeca4dff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'Person': ['Herbert', 'Frederick', 'Percival'], 'Age': [10, 9, 10]})\n",
    "df2 = pd.DataFrame({'Person': ['Sydney', 'Percival', 'Cuthbert'], 'Age': [8, 10, 9]})\n",
    "\n",
    "pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cc1494-6070-4ab0-9b32-b10126269f17",
   "metadata": {
    "tags": []
   },
   "source": [
    "The rows from the different DataFrames are concatenated by using the row index.  Whenever row index values don't match, NaN values will be created.  Look what happens below in the concatenation below when `df2` is allocated different index values from `df1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822ce157-d055-4d34-b92f-604e3a7b5f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'Person': ['Herbert', 'Frederick', 'Percival'], 'Age': [10, 9, 10]})\n",
    "df2 = pd.DataFrame({'Person': ['Sydney', 'Percival', 'Cuthbert'], 'Age': [8, 10, 9]}, index=['A', 'B', 'C'])\n",
    "\n",
    "pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc7bf79-5cf8-4ca7-9613-c103cf6be631",
   "metadata": {},
   "source": [
    "Or just one diffing row index name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4f8ab7-ef44-4fe9-a32f-4f9375491098",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'Person': ['Herbert', 'Frederick', 'Percival'], 'Age': [10, 9, 10]})\n",
    "df2 = pd.DataFrame({'Person': ['Sydney', 'Percival', 'Cuthbert'], 'Age': [8, 10, 9]}, index=[0, 1, 3])\n",
    "\n",
    "pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1f666d-ddce-4ee1-b4c4-9c08a59c364a",
   "metadata": {},
   "source": [
    "In the example below, notice that the row index ids are used to combine the DataFrames rather then the row's position in the DataFrame.  (When creating `df2` the default row index has been adjusted by passing a Python list to the `index` parameter.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd8f90c-c74b-4e97-a133-da782eee6bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'Person': ['Herbert', 'Frederick', 'Percival'], 'Age': [10, 9, 10]})\n",
    "df2 = pd.DataFrame({'Person': ['Sydney', 'Percival', 'Cuthbert'], 'Age': [8, 10, 9]}, index=[2, 1, 0])\n",
    "\n",
    "pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fafc62-aa52-4926-a4eb-bf616a466b58",
   "metadata": {},
   "source": [
    "### Joining on a field using `merge()`\n",
    "It is common to combine data from various sources, whether that be distinct data sets, combining metadata with the main observations, or some other form a necessary data manipulation.  Pandas makes this relatively straightforwards using its `merge()` function.\n",
    "\n",
    "This function takes 4 arguments:\n",
    "i) the name of a DataFrame to merge (left dataset)\n",
    "ii) the name of the other DataFrame to merge (right dataset)\n",
    "iii) how to merge the datasets\n",
    "iv) the name of the column on which to merge the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a670028-d6a0-45b1-852f-cc552e61f87e",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src='course_images/merge_schematic.svg' title='Merge Schematic'/>\n",
    "<figcaption><i>The diagram illustrates how DataFrames may be merged.  The \"left merge\" selects items in the left DataFrame, irrespective of whether they are found in the right DataFrame.  This logic is reversed for a \"right merge\".  An \"inner merge\" select items present in both DataFrames, whereas an \"outer merge\" selects all items i.e. they may be found in either one or both DataFrames.</i></figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdb9773-f0bd-4332-9de5-37fb4b83c2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'Person': ['Herbert', 'Frederick', 'James'], 'Age': [31, 19, 23]})\n",
    "df2 = pd.DataFrame({'Person': ['Frederick', 'James', 'Danniel'], 'Height': [185, 169, 172]})\n",
    "\n",
    "print(df1)\n",
    "print()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c1910b-5c6b-49af-871c-8055ef3e32b6",
   "metadata": {},
   "source": [
    "An \"inner merge\" ensures that the same Person must be present in both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39734ef9-3fc7-4c21-805e-2a287914b94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, how='inner', on='Person')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a295b84-be4f-45f3-a762-780aefc78c49",
   "metadata": {},
   "source": [
    "A \"left merge\" returns values for all Persons in the left-hand side (i.e. df1) DataFrame.  If that person is not present in the right-hand side DataFrame a value of `NaN` is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5d3c73-2968-42f7-97f8-8bb2ce046c22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, how='left', on='Person')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd26f0e7-27bd-4f55-a1d3-f1c397921169",
   "metadata": {},
   "source": [
    "A \"right merge\" returns values for all Persons in the left-hand side (i.e. df2) DataFrame.  If that person is not present in the right-hand side DataFrame a value of `NaN` is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8788f802-b13f-4190-b4ff-896cfd988de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, how='right', on='Person')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ff6873-00e7-45dc-bdcd-9804925d9fd4",
   "metadata": {
    "tags": []
   },
   "source": [
    "An \"outer merge\" returns values for all Persons listed in either DataFrame.  If a person is not present in one of the DataFrames a value of `NaN` is returned in the appropriate column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae799ea-335d-4aaa-946d-50485205b804",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, how='outer', on='Person')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1809f8-c5a3-44a3-84c2-4ff4282e830e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## Exercise 10\n",
    "\n",
    "**a1.**  Import the datasets \"Brain_Bodyweight_data.tsv\" and \"Brain_Bodyweight_Metadata.tsv\" into separate DataFrames. Try the `describe()` method on both DataFrames.  What do you see?\n",
    "\n",
    "**a2.**  Use the `merge()` method to combine the data with the metadata.\n",
    "\n",
    "**a3.**  Use the `value_counts()` method to give a tally of the different unique entries in the \"Category\" column.\n",
    "\n",
    "<hr>\n",
    "\n",
    "**b1.**  Import the Indoor and Outdoor Lockdown hobbies data into separate DataFrames.  Use `concat()` to combine the DataFrames.\n",
    "\n",
    "<hr>\n",
    "\n",
    "**c1.**  Import the Seaborn test dataset \"exercise\".  Use the `groupby()` method to group the samples by the \"kind\" column.\n",
    "\n",
    "**c2.**  Report the mean \"pulse\" value for each \"kind\" category.\n",
    "\n",
    "<hr>\n",
    "\n",
    "**\\*d1.**  Take a dataset of your own and create a new metadata file describing your data.   Combine your data with the metadata.  Use this combined dataset to produce summary results that incorporate the metadata. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38af0db2-c602-425f-8e95-49f6a1b515a6",
   "metadata": {},
   "source": [
    "## Reshaping Data\n",
    "One of the main challenges you will encounter is getting your data in the correct format.  We have already discussed methods for handling missing variables, but there are other points to consider.\n",
    "\n",
    "Since this course is aimed at scientists, you should already be familiar with the importance of meticulous and consistent data collection.  However, you may not be familiar with how best to store your data. \n",
    "\n",
    "\n",
    "### Atomised data\n",
    "You should separate data as much as possible when adding to a table, database or of course a pandas DataFrame.  For example, if you have been given the results from a time series which records date and time information, you should record the day and date in separate columns, which enables easier subsequent manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e82206-d43c-485b-ae5f-04ad6c912205",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_course = pd.DataFrame({'Day/Time': ['1 12:00', '1 18:00', '2 00:00', '2 06:00'], 'Score': [10, 15, 21, 29]})\n",
    "time_course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e57ec02-87cd-4d72-844a-4edfb32b9abf",
   "metadata": {},
   "source": [
    "What we need to do here is split the day and the time values.  Fortunately there is consistency in how the data have been entered i.e. the \"Day\" and \"Time\" values are separated from one another by a single space.  We can use the `str.split()` method to split the Day/Time pairings into separate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1586db-d840-4111-82cb-bcc8ba2ae183",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_course[['Day', 'Time']] = time_course['Day/Time'].str.split(pat=' ', expand=True)    #Different syntax\n",
    "time_course = time_course.loc[:, ['Day', 'Time', 'Score']]\n",
    "time_course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e845b27f-d9dc-43ce-93c1-f554beb235b8",
   "metadata": {},
   "source": [
    "This method takes a delimiter (character(s) used to split the data) argument, as well as a boolean value for the `expand` parameter.  Setting expand to `True` causes the value after the delimiter to be placed in a separate column.\n",
    "\n",
    "Now that you have a new DataFrame with the atomised values, you can combine this with your original DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8159920f-d9ea-4d5e-a6ef-d2051d83c447",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Joining columns\n",
    "\n",
    "While atomised data is desirable in most instances, there may be occasions when you need to join columns.  Let's reverse the operation we just performed on the `time_course` DataFrame to illustrate this point.\n",
    "\n",
    "The Python operator `+` when applied to strings will join values together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad825a0f-d60a-4548-bf1f-8a3fefe8bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_course['Day/Time'] = time_course['Day'] + ' ' + time_course['Time']\n",
    "time_course = time_course.loc[:, ['Day/Time', 'Score']]\n",
    "time_course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f41836-1dfa-40d2-8f34-022a936daa73",
   "metadata": {},
   "source": [
    "### Transposing data\n",
    "\n",
    "A common operation in data analysis is to convert rows-to-columns and columns-to-rows.  Consequently the column names become index names and vice versa.  **One point to note is that re-arranging the data this way can impact the datatype of columns since we are changing their data composition.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191ceaf0-84cd-4300-8410-6e12d2548fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_course.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2e2cbf-36af-4f7d-bfe2-b3b814137cb6",
   "metadata": {},
   "source": [
    "### Convert Wide to Long format\n",
    "Much of the data you encounter will be in **wide format**, such as the example in the next cell, which shows gene expression values in different conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91e3cef-0e39-4484-9524-695177b98a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression = pd.DataFrame(\n",
    "        [['Brain', 1.3, 2.4],\n",
    "         ['Liver', 1.4, 2.6],\n",
    "         ['Heart', 1.6, 2.9]],\n",
    "    columns=['Tissue', 'GeneA', 'GeneB'])\n",
    "\n",
    "gene_expression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f120eddd-1be1-4418-8c4e-c879991ee23c",
   "metadata": {},
   "source": [
    "This is a simple and intuitive way to represent this data and for visualisation purposes it is fine.  But, it doesn't scale well.  For example, suppose in a subsequent experiment we measure an additional gene - GeneC.  To accommodate this extra gene, we need to add an extra column to our DataFrame.  So, the width of our DataFrame cannot be fixed without knowing in advance all the genes being measured.  So, we may end up in a situation where every experiment has a different number of columns.  This is not a standardised way of working and standardisation is key when trying to analyse code programmatically.\n",
    "\n",
    "Furthermore, if we were to measure say 20,000 genes, we will end up with a DataFrame which is over 20,000 columns wide. Such layouts can no longer be easily represented on a screen.\n",
    "\n",
    "This is where **tidy** or **long format** comes to the rescue.  By using the `melt()` function we can convert wide to long format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136cd5ee-89f1-40f2-82b0-1bbd73325d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression = pd.melt(gene_expression, id_vars='Tissue', var_name='Gene', value_name='Expression')\n",
    "gene_expression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e297e55-09e1-4224-971b-715f717bf3bb",
   "metadata": {},
   "source": [
    "The `id_vars` parameter sets the column(s) to use as identifier variables.  The newly created column names for variable names and value columns are set by the parameters `var_name` and `value_name` respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5463ebdc-4b8d-4989-9cf5-e71477b26812",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<b>Tidy data</b>\n",
    "\n",
    "Tidy data is a standardised way of structuring data in accordance with its underlying meaning. \n",
    "\n",
    "For Tidy data:\n",
    "    \n",
    "1. Each variable forms a column.\n",
    "2. Each observation forms a row.\n",
    "3. Each type of observational unit forms a table.\n",
    "\n",
    "Data that is not in tidy format is termed \"messy\".\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7ff811-0309-420a-a5c9-700590102e37",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Convert long to wide format\n",
    "Although long/tidy format is preferred for most analyses, sometimes wide format is advantageous as it assists with the perusal of small datasets. It also benefits from not repeating values and consequently reduces memory overheads.\n",
    "\n",
    "Use the `pivot` method to convert long/tidy format to wide format.  Consider the following example in which the `gene_expression` dataset is converted back to its original wide format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c18e3d6-f022-4016-b96c-e5ba64df26f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression = gene_expression.pivot(index='Tissue', columns='Gene', values='Expression')\n",
    "gene_expression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24544c8-b0e5-4105-b147-964f57481aef",
   "metadata": {},
   "source": [
    "You will notice that the \"Tissue: information is now given in the index.  As we discussed previously, this can be extracted to the first column using the `reset_index()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a688ca49-57ff-442a-80b4-7d87d3302d67",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## Exercise 11\n",
    "    \n",
    "**a1.**  Import the dataset \"Cuttlefish_Buoyancy.tsv\".  Edit the dataset to only include the columns:\\\n",
    "ID\\\n",
    "treatment\\\n",
    "hatching_date\\\n",
    "days_until_sampling\\\n",
    "floating\\\n",
    "density\n",
    "\n",
    "**a2.**  Split days/month/year for the hatching_date into separate columns.  Remove the original column.\n",
    "\n",
    "**a3.**  Edit the ID column so it comprises the current ID in addition to the treatment applied.  Drop the original treatment column.\n",
    "\n",
    "**a4.**  Observe how the cuttlefish DataFrame is structured after using `transpose()` method.  Transpose the data back again.\n",
    "\n",
    "**a5.**  Convert the cuttlefish DataFrame to long/tidy format.  Write the data to Excel an file.\n",
    "\n",
    "**a6.**  Convert the data back to wide format (notice the column/row labels have now changed).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab6c02b-06d2-4c92-aaf4-857cb6b4f9ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Additional functionality using other Python libraries\n",
    "Before too long you will encounter other data analysis libraries such as NumPy and SciPy.  In this section we shall go on a whistle-stop tour of these libraries, highlighting their popular features which can be used in conjunction with pandas.  (If you would like a more detailed overview, there is a separate LMB course covering NumPy in some depth.)\n",
    "\n",
    "## Numpy\n",
    "NumPy (https://numpy.org) is an acronym of the term \"Numerical Python\".  Similar to pandas, it allows users to store information in complex NumPy data structures.  NumPy is ideal for more complex analyses, such as those applied in machine learning. \n",
    "\n",
    "Although we shan't be looking at NumPy in substantial detail, it is worth knowing how to import NumPy data into pandas (in fact, under the hood pandas is built on NumPy).  NumPy also has several methods that can be applied to pandas.\n",
    "\n",
    "### Importing Numpy data\n",
    "The code below imports the NumPy library and then creates a NumPy array, which is then subsequently converted to a pandas DataFrame.  (If the NumPy array were 1-dimensional then it could have been converted to a Pandas Series.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf4225d-8909-45d8-a266-5c6cdb2eb438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "my_array = np.array([[1, -220, 0],[43, 5, -99]])\n",
    "\n",
    "print(type(my_array))\n",
    "print(my_array)\n",
    "print()\n",
    "\n",
    "my_array = pd.DataFrame(my_array)\n",
    "print(type(my_array))\n",
    "print(my_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cc6349-05f5-458a-b908-37bdbca7fc69",
   "metadata": {},
   "source": [
    "### Adding NaN values\n",
    "NumPy enables coders to explicitly incorporate `NaN` values into a Series or DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72c0174-3d79-4991-bc2c-4c4d9083dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.Series([1, 2, np.NaN])\n",
    "print(df)\n",
    "print()\n",
    "print(df.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f55d31b-a59e-41f6-ba47-514312a463f8",
   "metadata": {},
   "source": [
    "### Mathematical transformations\n",
    "NumPy makes available a wide range of mathematical transformations.  Please see the list at https://numpy.org/doc/stable/reference/routines.math.html for more details.  The example below shows a log<sub>10</sub> transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2ba487-8627-4f60-921f-8097c3fda649",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(pd.DataFrame([1, 10, 100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92cb5c7-f08e-4c62-8710-c0659f51665c",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  Distribution\n",
    "NumPy can be used to create mathematical distributions.  In the example below, we use NumPy to randomly sample 10 values from a Normal distribution which has a mean value of 0 and a standard deviation of 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d87e42-f4cc-4a7f-9e70-c1d3402089b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.normal(loc=0.0, scale=1.0, size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598bc9e2-6bdd-4e76-9e2a-f773a8514bbb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Conditional operations with the NumPy `where()` method\n",
    "\n",
    "The NumPy `where()` method can be used to return elements from a pandas data structure that meet a specified condition.  The method returns the index positions of values that pass the condition.  The method can also take additional arguments that are to be returned if condition evaluated to `True` or `False`.  The code below illustrates these points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab8ed4-17bf-48c0-84f9-ff8e16f45cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "metals = np.array(['Gold', 'Copper', 'Iron', 'Gold'])\n",
    "\n",
    "print(np.where(metals == 'Gold'))   # Get index position\n",
    "print(np.where(metals == 'Gold', 'Collect', 'Ignore'))   # Alternative responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d319167-a5fa-4d57-8619-ef8753d7a035",
   "metadata": {},
   "source": [
    "## SciPy\n",
    "SciPy (https://scipy.org ) comprises a wide range of packages addressing common tasks in scientific computing, including  statistical analyses, handling sparse matrices and linear algebra.  Together, NumPy and SciPy comprise an extensive range of computational and mathematical techniques.\n",
    "\n",
    "## scikit-learn\n",
    "The project scikit-learn (https://scikit-learn.org) makes available a wide range of machine-learning techniques such as regression, PCA and random forest.\n",
    "\n",
    "## Keras\n",
    "Keras (https://keras.io) is a deep learning framework.  For more information, attend one of the LMB's Machine Learning Courses.\n",
    "\n",
    "\n",
    "## PyTorch\n",
    "PyTorch (https://pytorch.org) is a potential alternative to Keras and has grown rapidly in popularity in recent years.\n",
    "\n",
    "## BioPython\n",
    "BioPython (http://biopython.or) contains a suite of tools for manipulating a large range of bioinformatics file formats (e.g. FASTA) and querying online databases and manipulating sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb61e26-b51a-4a25-b8c0-a3580499079d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## Exercise 12\n",
    "    \n",
    "**a1.**  Import the Brain Bodyweight data file again.  Create 2 new columns that record the log<sub>2</sub> bodyweight and log<sub>2</sub> brain weight.\n",
    "\n",
    "**a2.**  Let's make a new column named Body.Weight.Classification.  Use `np.where()` to classify anything weighing less than 10kg as \"Small\" and anything else as \"Not_Small\".  Save the output in a format of your choosing.\n",
    "\n",
    "<hr>\n",
    "\n",
    "**b1.**  Go to the NumPy website: https://numpy.org.  Find out more about the mathematical operations and statistics tools available in this library.\n",
    "\n",
    "<hr>\n",
    "\n",
    "**\\*c1.**  We are investigating whether 2 drugs give different outcomes when treating a disease.\n",
    "50 patients receive Drug A of which 41 are cured and 59 are not cured. \n",
    "50 patients receive Drug B, of which 62 are cured an 38 are not cured.\n",
    "\n",
    "Perform a two-sided Fisher's Exact test to decide whether the drugs have different treatment outcomes (significance threshold: p < 0.01)\n",
    "\n",
    "**\\*c2.**  Try using some of these NumPy functions on some of your own datasets.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dc6f0d-65b5-4996-b52f-7b8f21212afc",
   "metadata": {},
   "source": [
    "# Creating plots\n",
    "Python has an extensive number of libraries and modules for generating plots.  In fact, pretty much any plot you are likely to need can now be generated using Python.  Perhaps the more important issue is the trade-off between generating plots quickly versus the need to create highly customised publication-quality figures.\n",
    "\n",
    "In this section we shall look at how to generate plots quickly using **pandas**.  Such graphs are ideal for personal exploration of data or presenting results at informal meetings.  We shall then use the Python library **Seaborn** to generate more complex plots.  These are generally of a quality that would suit most situations and even for published results.  Finally, we shall briefly discuss the Python library **Matplotlib**.  This is more complex than the other alternatives and takes more time to learn and write code.   This Python extension scores in that it should allow you to generate all the plots you will ever need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f78aa9-bf61-4038-b365-175bcbe79efa",
   "metadata": {},
   "source": [
    "## Generating plots with pandas\n",
    "Many plots may be generated easily by executing the appropriate DataFrame method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149bc2e9-2b79-4dea-a32f-a3b14041c81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test dataset\n",
    "experiment_data = pd.DataFrame(\n",
    "        [[0, 2.3, 4.3, 6.9, 10.0, 13.4, 15.1, 17.4, 19.3, 21.2],\n",
    "         [0, 3.3, 5.6, 10,3, 13.9, 17.4, 19.3, 23.1, 28.0]],\n",
    ")\n",
    "\n",
    "experiment_data = experiment_data.transpose()\n",
    "experiment_data.columns = ['A', 'B']\n",
    "\n",
    "print(experiment_data.shape)\n",
    "experiment_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236f165c-1eaa-4cf5-baf9-15c7b4e9efad",
   "metadata": {
    "tags": []
   },
   "source": [
    "Simply run the `plot()` method on the DataFrame to generate a line-plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca1690c-b2f2-4612-a85a-a8a805e43d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_data.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac17f446-f3ed-400b-9061-04eebc42e228",
   "metadata": {},
   "source": [
    "If you are only interested in displaying a subset of your data, then just select the require data before creating the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4141a299-e945-408b-92d1-0b396f932dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_data['A'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fbfbd1-46e4-4aee-88d5-0e4923484391",
   "metadata": {},
   "source": [
    "Use the `kind` parameter to specify the type of plot you require.  Got to: https://pandas.pydata.org/docs/user_guide/visualization.html for further information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41f9d6f-35e8-42df-b5f5-552ef6c2420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_data.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baed94ee-1e61-4d0e-90b8-c6bca55b95c7",
   "metadata": {},
   "source": [
    "For scatter plots you need to define explicitly the columns that constitute the x- and y-axis co-ordinates in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aeb265-a603-4802-b7f3-8fa508755dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_data.plot(kind='scatter', x='A', y='B')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88964f3e-8980-4622-9626-b37c3f0bd0e8",
   "metadata": {},
   "source": [
    "And that is how you can quickly generate plots in pandas.  This `plot()` method does have more options available, but in our experience if you are making a plot requiring more than very simple input parameters, then it is best to use Seaborn (or Matplotlib)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736e026e-1f23-45e1-9413-7aef0ba2efbd",
   "metadata": {},
   "source": [
    "## Generating plots with Seaborn\n",
    "\n",
    "### Creating individual plots\n",
    "Although a little bit more complex than panda's in-built plotting capabilities, Seaborn enables programmers to generate complex and publication-quality graphics in just a few lines of code.  To explain how Seaborn works we shall go through a couple of examples (these are taken from the Seaborn online documentation).\n",
    "\n",
    "Firstly, import Seaborn.  (You may have noticed that we actually imported Seaborn previously in the course to gain access to test datasets - but nevertheless it doesn't hurt to recap this code now.)   Having done that, we shall import the Seaborn test dataset \"tips\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c13cf8f-2364-4d35-918e-2f8e4cdf141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa7492c-2b76-4d3d-a3d4-b0b7e334bdf3",
   "metadata": {},
   "source": [
    "(To prevent this Notebook becoming too long we shall use Matplotlib functionality to generate plots smaller than the default size.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d1b6a4-8824-4457-9b7c-7479e70dcf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default image size\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (3.5, 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce33c720-2e46-4041-b339-90603e385703",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Seaborn is built on top of Matplotlib</b>\n",
    "<br>\n",
    "You can think of Seaborn as a kind of \"software manager\" that instructs Matplotlib how to generate plots. By doing this, users of Seaborn only need to handle a reduced number of options, making the task of generating plots easier.  This also means that Matplotlib can be used to fine tune a Seaborn plot.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4ba7f8-cac8-4cbe-abee-58df2eab4570",
   "metadata": {},
   "source": [
    "The tips dataset presents how the size of a restaurant tip varies with, among other factors, the price of the bill.  A scatter plot is a simple way to represent such correlations and the code below shows how to do this using Seaborn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789b34ff-e0e3-46dd-befa-3bf1ce29a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    data=tips,\n",
    "    x=\"total_bill\", y=\"tip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e1ff71-09a8-4c3c-9e3b-677f385df79c",
   "metadata": {},
   "source": [
    "The Seaborn `scatterplot` function generates the plot.  The parameter `data` specifies the source of the data i.e. the `tips` DataFrame.  The parameters `x` and `y` specify the corresponding x-axis and y-axis co-ordinates.\n",
    "\n",
    "We can add easily more information to the plot.  For example, suppose we wish to highlight categorical data on the plot.  Well this can be done using the `hue` parameter, which will colour points based on categorical information.  In the example below the Smoking/Non-smoking category is passed to the `hue` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d2d67-a713-47d8-ae5c-1806e8ee11b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    data=tips,\n",
    "    x=\"total_bill\", y=\"tip\", hue=\"smoker\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edb7017-5a99-43cd-8fa8-5391e0c3e655",
   "metadata": {},
   "source": [
    "In a similar fashion we can set the shape of the plotted points to reflect a category type (i.e. whether an individual is a smoker)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add3427e-70d0-40cf-95b6-a4080ac5cc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    data=tips,\n",
    "    x=\"total_bill\", y=\"tip\", hue=\"smoker\", style=\"smoker\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c354f8b0-f823-44dd-aaeb-82fced47a376",
   "metadata": {},
   "source": [
    "In the figure below we have set the size of the points to reflect the \"Size\" category in the input dataset.  This had the undesired effect of the legend covering many of the points on the plot and so we increased the size of the image, overriding the current settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4098599e-f6af-49c0-9638-23a145a68f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=tips,\n",
    "    x=\"total_bill\", y=\"tip\", hue=\"smoker\", style=\"smoker\", size=\"size\"\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63709c2c-ebfe-4d4c-8777-17e908f329f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Multiple plots\n",
    "It is possible to combine multiple graphs in the same figure.  To do this use the Matplotlib `subplots()` method, to which you should pass the dimensions of the figure (i.e. the row/column layout of the subplots in the main figure). \n",
    "\n",
    "So long as more than one subplot is required, this method will return a figure object and an array of axes objects.  The axes array will have the shape specified by the user when running the `subplots()` method.  \n",
    "\n",
    "Look at the example below which generates a main plot with a 2 x 2 subplot layout, comprising different graph types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c8574b-2e16-4b5e-aff1-6d15eefee296",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [14, 14]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2)    # 2 x 2 plot\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=tips,\n",
    "    x=\"total_bill\", y=\"tip\", \n",
    "    hue=\"smoker\", \n",
    "    style=\"smoker\", \n",
    "    size=\"size\", \n",
    "    ax=ax[0, 0]    # Top left\n",
    ")\n",
    "\n",
    "sns.histplot(\n",
    "    data=tips,\n",
    "    x=\"day\", \n",
    "    ax=ax[1, 0]    # Top right\n",
    ")\n",
    "\n",
    "sns.histplot(\n",
    "    data=tips,\n",
    "    y=\"time\", \n",
    "    ax=ax[0, 1]    # Bottom left\n",
    ")\n",
    "\n",
    "sns.boxplot(data=tips, \n",
    "            x=\"day\", \n",
    "            y=\"total_bill\",\n",
    "            hue=\"smoker\", \n",
    "            ax=ax[1, 1]    # Top right\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6b2629-4dee-4fc1-a019-b124d9b3e6ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Facet grid\n",
    "You may want to investigate relationships between multiple variables by several related plots - which is where the `FacetGrid` class should be used.\n",
    "\n",
    "In the example below we investigate the relationship between tip size and total bill, but split different times of the day into separate plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626e2c19-cf9d-4585-88e0-00e2a8bc54ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(tips, col=\"time\")\n",
    "g.map_dataframe(sns.scatterplot, x=\"total_bill\", y=\"tip\", hue=\"smoker\", style=\"smoker\", size=\"size\")\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e11164c-5c50-41d6-b520-dd3fe4fdb988",
   "metadata": {},
   "source": [
    "To use this class, initialise a `FacetGrid` object by passing the DataFrame of interest along with the category which should be used to segment the data to the constructor method `sns.FacetGrid()`.  In this example we have named the created object `g`.\n",
    "\n",
    "Run the `map_dataframe()` method and provide it with i) a plotting function and ii) the name(s) of variable(s) in the DataFrame to plot.\n",
    "\n",
    "Finally, we added a legend to `g` using the `add_legend()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877e459c-356a-4470-baf2-df9468dfb468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate smaller plots once again\n",
    "plt.rcParams[\"figure.figsize\"] = (3.5, 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1281098-119b-4188-b1a2-d4436c14bfd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Choosing aesthetics using themes\n",
    "There are a myriad number of ways in which a Seaborn plot may be adjusted.  A simple way to adjust the appearance of a plot is to use the `set_theme()` function, which can be used - among other things - to adjust the style of the plot and the choice of colour palette.\n",
    "\n",
    "We have chosen the \"colorblind\" palette for this demonstration.  It is worth remembering that a substantial proportion of the population has some kind of colour deficiency and it is best to choose colour schemes that are easy to discriminate by as many people as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febbe806-5486-490d-8f09-49ac2f3215c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\", palette=\"colorblind\")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=tips,\n",
    "    x=\"total_bill\", y=\"tip\", hue=\"day\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8024eb92-b448-4765-bb1f-69e93a8a0904",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"dark\", palette=sns.dark_palette(\"xkcd:golden\", 4))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=tips,\n",
    "    x=\"total_bill\", y=\"tip\", hue=\"day\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395b0b10-d91e-4ead-b662-6e14e9c6767b",
   "metadata": {},
   "source": [
    "Discover for yourself the themes you find most suitable:\n",
    "  \n",
    "https://seaborn.pydata.org/tutorial/aesthetics.html\n",
    "\n",
    "https://seaborn.pydata.org/tutorial/color_palettes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb130c6-cd16-4511-b119-24e4e60b3603",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Writing plots to file\n",
    "So far we have inserted plots directly into the Notebook, but of course often you will want to output the results to a file.  Again, there are multifarious options for writing images to a file.  \n",
    "\n",
    "The example below shows how to create an SVG file using the `savefig()` function of `plt`.  (The `bbox_inches='tight', pad_inches=0.5` parameters prevent the edges of the image from crossing the SVG border).  As you might expect, you can also create PNG files and other formats.  \n",
    "\n",
    "People often wonder which is better: PNG or SVG?  Well, SVGs are vector images that can be scaled up without damaging image quality and so will be perfectly crisp and clear, no matter how large their rendering.  These are generally ideal for publication-quality graphs and charts and can be fine-tuned in Adobe Illustrator or the free open-source tool Inkscape.  In contrast, PNGs experience loss of quality during re-scaling, although to ameliorate this problem they can be saved initially at high resolution.  PNGs are generally more compatible for use with other presentation tools - such as PowerPoint - and they are also better for saving very detailed images.  \n",
    "\n",
    "Having said all this, it is only an extra line of code to generate both SVG and PNG images, so it may be prudent to do that for important graphical output.\n",
    "\n",
    "As alluded to above, a code cell may generate more than one graph.  Indeed the number of graphs that may be generated is virtually limitless.  This is worth bearing in mind, for if you learn more about \"looping\" in Python, you can automate the generation of large numbers of output graphs, saving you much time and coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064c98d8-7bfd-43fe-ad73-a5df75579925",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\", palette=\"Set2\")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=tips,\n",
    "    x=\"total_bill\", y=\"tip\", hue=\"day\"\n",
    ")\n",
    "\n",
    "plt.savefig(fname='bills_scatterplot.svg', format='svg', bbox_inches='tight', pad_inches=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd866ed5-d633-4db0-85c7-6773b208dfe9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "That brings to an end this quick overview of Seaborn.  There are of course many types of plots that can be created (barplots, histograms and heatmaps etc.) and many themes and colour schemes that can be applied to those graphs.  Some of these possibilities will be looked at some more in the exercises, but as one might expect the degree of customisation is enormous with Seaborn, and even more so if using Matplotlib.  The documentation is extensive, but we recommend the following webpage as a starting point:\n",
    "\n",
    "https://seaborn.pydata.org/examples/index.html\n",
    "\n",
    "The page displays a range of specimen graphs along with code to show how they are generated: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb6ebdb-11c3-4e5f-9ec1-617caae7f36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<iframe src=\"https://seaborn.pydata.org/examples/index.html\", width=100%, height=500>\n",
    "</iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8ebd56-29c4-4ad1-ae24-05469abad4fb",
   "metadata": {},
   "source": [
    "It may take some time and effort to find the exact plot options you need, but for most purposes it is possible to generate a graph quickly with both pandas and Seaborn.\n",
    "\n",
    "## Introducing Matplotlib\n",
    "We have already mentioned that Matplotlib is a popular choice for plotting graphs in Python and although it is more complex to use than Seaborn, it is more versatile.  Importantly, Seaborn is built on-top of Matplotlib and consequently Matplotlib functions can be applied to Seaborn objects.  \n",
    "\n",
    "Since it is important to understand a little about Matplotlib, we shall introduce it briefly here.  If you already understand Seaborn, the Matplotlib code should make sense.  In fact, once you get to grips with Seaborn you should be able to let the Matplotlib documentation guide you in producing exactly the plot you desire (so long as the underlying data makes sense of course).\n",
    "\n",
    "Often the best way to build a Plot is to look at existing examples, and such a gallery can be found at:\n",
    "https://matplotlib.org/stable/gallery/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deba0a9-e673-48c7-a0fa-fb07ba4ea987",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<iframe src=\"https://matplotlib.org/stable/gallery/index.html\", width=100%, height=500>\n",
    "</iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a9fa29-d1f9-4258-aeb3-98f09254e91e",
   "metadata": {},
   "source": [
    "Somewhat strangely, Seaborn does not have a method for making Pie Charts, so we shall use Matplotlib to do this.  The example below passes multiple parameters to the `plt.pie()` method to illustrate the degree to which these plots can be tailored to your requirements.\n",
    "\n",
    "The code has 3 main components:\n",
    "\n",
    "1. Use the default naming convention to import Matplotlib as plt\n",
    "2. Write the pie chart and the title to the \"canvas\" using `plt.pie()` and `plt.title()`\n",
    "3. Now display the results with `plt.show()` (this simultaneously clears the canvas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d350a74-27be-4219-86ee-006e35b98371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data\n",
    "counts = pd.Series([1, 2, 3, 4])\n",
    "labels = pd.Series(['A', 'B', 'C', 'D'])\n",
    "explode = [0, 0, 0, 1]\n",
    "\n",
    "# Create plot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.pie(counts, \n",
    "        labels=labels, \n",
    "        autopct='%1.1f%%',\n",
    "        colors=['olivedrab', 'rosybrown', 'gray', 'saddlebrown'],\n",
    "        pctdistance=1.25, \n",
    "        labeldistance=0.6,\n",
    "        shadow=True, \n",
    "        startangle=90,\n",
    "        explode=explode\n",
    ")\n",
    "\n",
    "plt.title(label='Matplotlib Pie Chart', loc='left', pad=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d3ad50-c57b-4a80-b450-462ebe75000c",
   "metadata": {},
   "source": [
    "## Making interactive charts with Plotly\n",
    "Sometimes a chart can be easier to interpret by making it interactive.  This additional functionality is made possible with the Python library Plotly (https://plotly.com).\n",
    "\n",
    "We shan't describe how to create these interactive plots in this course as hopefully you will now feel confident enough to build your own Plotly charts by reading the relevant documentation and by studying previous examples.  Indeed, with this in mind the developers of Plotly produced a gallery of online figures to serve as a programming guide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d2c0ad-b412-4f99-8b11-2e3f2f00de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<iframe src=\"https://plotly.com/python/\", width=100%, height=500>\n",
    "</iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6e9e36-4f21-4b6b-b263-29a7025b0ef0",
   "metadata": {},
   "source": [
    "We copied the code for a couple of these figures into the cells below.  You will see that if you move the mouse pointer slowly over each figure additional information pops up.  This is particularly useful for displaying the extensive genomic information in the Volcano plot.  Indeed, it would be impossible to read this text without this interactive capability.  Each plot also has a menu, allowing users to zoom-in or zoom-out of figures, or download the images in PNG format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47321592-a46a-463a-84ee-98c88fbd6a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df = px.data.tips()\n",
    "fig = px.box(df, x=\"time\", y=\"total_bill\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3333c2-9de2-4c43-b8ab-913b72964ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dash_bio\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/plotly/dash-bio-docs-files/master/volcano_data1.csv')\n",
    "\n",
    "dash_bio.VolcanoPlot(\n",
    "    dataframe=df,\n",
    "    point_size=10,\n",
    "    effect_size_line_width=4,\n",
    "    genomewideline_width=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d076ec-2498-47f5-acc5-f494a0b29e12",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "## Exercise 13\n",
    "\n",
    "**a1.**  Import the dataset \"Biochemical_Oxygen_Demand.tsv\" into a DataFrame.  Use the DataFrame method `.plot()` to visualise the data.\n",
    "\n",
    "**a2.**  Now make a barplot using a DataFrame method.\n",
    "\n",
    "<hr>\n",
    "\n",
    "**b1.**  Import the Body size vs Brain size data you created earlier.  Make a scatter plot using Seaborn of log<sub>2</sub> brain size (y-axis) vs log<sub>2</sub> body size (x-axis).\n",
    "\n",
    "**b2.**  Use the hue parameter to display Small / Not_Small animals in different colours.  Change the theme to \"dark\".\n",
    "\n",
    "**b3.**  Merge this dataset with its associated metadata, as we did in a previous exercise.  Now create a scatterplot which uses the hue to differentiate between Small / Not_Small animals and uses different shape (style) to distinguish between Wild/Extinct/Domesticated species.\n",
    "\n",
    "**b4.**  Now use a facet grid to explore how the brain/body size relationship varies with our Wild/Extinct/Domesticated classification.\n",
    "\n",
    "**b5.**  Export the plot as PNG and SVG files.\n",
    "\n",
    "**b6.**  Use Plotly to make an interactive version of the first scatterplot you created.\n",
    "\n",
    "<hr>\n",
    "\n",
    "**\\*c1.**  Use NumPy to create 1000 random variables from a Normal distribution of mean=5, standard deviation=1.5.  Display these variables on a histogram.\n",
    "\n",
    "**\\*c2.**  Go to https://seaborn.pydata.org/examples/index.html and look at the code for graphs most relevant to your own work.  Can you make these plots for your own datasets?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9f4bc2-1e15-438e-babb-d96e30657e09",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Concluding remarks\n",
    "Well, that brings the Data Analysis with Python course to an end.  You should now have at your disposal a considerable range of data manipulation, analysis and visualisation techniques.\n",
    "\n",
    "We strongly recommend that you go out of your way to make use of your new-found skills in the coming weeks and months.  If you don’t build upon your current knowledge you will become less familiar with what we have covered.  Maybe there is some analysis that you could now perform with Python and pandas?  Even if it is easier to do the tasks in, say, MS Excel, reinforcing your new-found skills now will pay dividends in the future.    \n",
    "\n",
    "**Remember: learning to program is akin to learning a foreign language.  There is a great deal to take in and becoming fluent takes practice, practice, practice.**\n",
    "\n",
    "Happy coding!\n",
    "\n",
    "## Useful links\n",
    "\n",
    "We would like to bring to your attention the following resources that may help you in your data science career:\n",
    "\n",
    "\n",
    "**BioPython**\n",
    "\n",
    "[Biopython homepage](http://biopython.org)\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Jupyter**\n",
    "\n",
    "[Jupyter homepage](www.jupyter.org)\n",
    "\n",
    "[LMB JupyterHub](http://10.91.193.124/hub/login)\n",
    "\n",
    "[Notebook examples](https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks)\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Keras**\n",
    "\n",
    "[Keras homepage](https://keras.io)\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Matplotlib**\n",
    "\n",
    "[Matplotlib homepage](www.matplotlib.org)\n",
    "\n",
    "[Example plots](https://matplotlib.org/stable/gallery/index.html)\n",
    "\n",
    "<hr>\n",
    "\n",
    "**NumPy**\n",
    "\n",
    "[NumPy homepage](https://numpy.org)\n",
    "\n",
    "[Mathematical functions](https://numpy.org/doc/stable/reference/routines.math.html)\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Pandas**\n",
    "\n",
    "[Pandas homepage](https://pandas.pydata.org)\n",
    "\n",
    "[Cheat sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)\n",
    "\n",
    "[Example plots](https://pandas.pydata.org/docs/user_guide/visualization.html)\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Plotly**\n",
    "\n",
    "[Plotly homepage](https://plotly.com)\n",
    "\n",
    "[Plotly using Python](https://plotly.com/python)\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Python**\n",
    "\n",
    "[Python homepage](www.python.org)\n",
    "\n",
    "<hr>\n",
    "\n",
    "**PyTorch**\n",
    "\n",
    "[PyTorch homepage](https://pytorch.org)\n",
    "\n",
    "<hr>\n",
    "\n",
    "**scikit-learn** \n",
    "\n",
    "[scikit-learn homepage](https://scikit-learn.org)\n",
    "\n",
    "\n",
    "**SciPy**\n",
    "\n",
    "[SciPy homepage](https://scipy.org)\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Seaborn**\n",
    "\n",
    "[Seaborn homepage](https://seaborn.pydata.org)\n",
    "\n",
    "\n",
    "[Plot aesthetics](https://seaborn.pydata.org/tutorial/aesthetics.html)\n",
    "\n",
    "[Plot colour schemes](https://seaborn.pydata.org/tutorial/color_palettes.html)\n",
    "\n",
    "[Example plots](https://seaborn.pydata.org/examples/index.html)\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Test datasets**\n",
    "\n",
    "[Seaborn test datasets](https://github.com/mwaskom/seaborn-data)\n",
    "\n",
    "[Life Sciences Training Datasets](https://github.com/StevenWingett/LifeSciencesTrainingDatasets)\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c978291-4066-4ddc-a23a-85164e79fe03",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>ChatGPT and coding</b>\n",
    "\n",
    "We may be on the cusp of a revolution in how coding is carried out.  The barriers-to-entry for most people are the amount of jargon to learn, the unforgivingly precise nature of coding and the relatively long time it takes for a beginner to perform even the most basic tasks when more user-friendly alternatives are available (such as MS Excel).\n",
    "\n",
    "ChatGPT and other AI tools may change this situation within the next few years - or possibly even months.  Organisations have been using this advance in AI technology to produce tools that give coding suggestions as a programmer types.  (A leader in this field is [Copilot](https://github.com/features/copilot), developed by GitHub.)\n",
    "\n",
    "This does not mean that people can dispense with learning to program all together.  But what it may mean is that users no longer need to be fluent to program well, instead a familiarity with a program's syntax and logic is all that will be required.  An analogy would be that non-native English speakers may understand the language perfectly well when spoken by others, yet may struggle to formulate grammatically correct sentences themselves.  These new AI tools are akin to language translators that give syntactically correct suggestions that can be used by the programmer.\n",
    "\n",
    "So, we envisage a situation where novice programmers sketch out what they want to achieve and this can be developed by the AI assistant.  The coder can then accept pertinent recommendations and check the canonical  documentation to validate code that is unfamiliar.  Just to give some perspective on the current state of the art: the Copilot AI can read the code comments such as \"import TSV file\" and then report back code detailing how to populate a pandas DataFrames with external data from a file.\n",
    "\n",
    "This new way of working should be much faster, more efficient and intuitive for everyone, especially those new to coding.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e90be13-9186-465b-b67f-a672a548b961",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercise Answers\n",
    "\n",
    "## Exercise 1\n",
    "Talk-through answers.\n",
    "\n",
    "## Exercise 2\n",
    "\n",
    "Talk-through answers.\n",
    "\n",
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971a01f3-5f69-4faa-8563-8c6a141116a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1.\n",
    "5 + 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acd3ba8-c4ce-4f44-9afd-942b146ad3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a2.\n",
    "8 - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb06f8b-c77d-41e1-a633-9fac58dde9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a3.\n",
    "9 * 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566844c0-9b33-4e59-8f82-0a1e07769f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a4. \n",
    "-15 / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b16e784-a8b3-4b7c-87fa-a5f162e1eba7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a5.\n",
    "3 ** 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8455301-114c-49e8-aa0e-9ee391006a90",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa63dddb-8a20-48f9-b834-00fc6d19f5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b1.\n",
    "2 ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01654e87-38d4-421f-aab5-1ac2ee41f225",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# b2.\n",
    "3.2E12 * 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ae2f1b-ae68-41aa-97f9-c4255538f3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b3.\n",
    "2.3E-12 * 45.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4750ab89-5b2e-4d61-97f9-5f452b369eb1",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449d83bc-f7e5-40a7-aa9c-911f628dc508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c1.\n",
    "0 == -0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9798766-cc34-43a7-b92e-6acc5f3e8cf8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# c2.\n",
    "10 != 10.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396c4185-8478-4a2f-8a46-71f75764952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c3.\n",
    "(856 * 7) > (864 * 7.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76685e2d-77b2-4449-9012-c59eac19e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c4.\n",
    "9/3 <= 33 / 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390de546-662b-4c22-b7a4-bdd96e736331",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc9fbd5-35d8-4578-9d6a-f124d9357d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d1.\n",
    "(5 * 1.20) + (8 * 2.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565e893-b5ac-47c3-b176-8e247af3504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d2.\n",
    "1000 / (20 + 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6f79c0-1cb5-4c4c-ac2d-4e4b0409b467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d3.\n",
    "((3 * 15.20) + (9 * 17.45) + (2 * 24.00)) * ((100 - 20) / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03adecb1-5829-4a64-932c-56c839146477",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d8dd74-71a0-4c28-88a8-a96a1c2de90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e1.\n",
    "'Con' + 'cat' + 'en' + 'ate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8d1f07-cd55-45cb-8ee8-ff497bce9bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e2.\n",
    "'To' + ' ' + 'be' + ' ' + 'or' + ' ' + 'not' + ' ' + 'to' + ' ' + 'be'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e01ce7-e9c5-46b9-b28f-19977c2583a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e3.\n",
    "'All work and no play makes Jack a dull boy ' * 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2bef86-e7a9-4958-a344-d77e9c35fc56",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f77501-68ae-4e50-89ba-76df4cc43f7c",
   "metadata": {},
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e540f26-fc85-4ddc-8451-78b4579e7cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1.\n",
    "type(10 * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d44f825-87b0-4958-ae03-474c8e8b55ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a2.\n",
    "type(22 / 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87167e1d-380e-409b-815b-7f3cd47f732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a3.\n",
    "type('10' * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6428d040-6da7-4b4c-9b91-10bab4c0ae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a4.\n",
    "type(int('10' * 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741ae21b-4e61-4426-9d95-c49c2a6045dc",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57775e6-a13a-41fb-8e42-a3a3a406181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b1.\n",
    "dna = 'GATATCTAGTCTTCTGATAGAGATCTGATGGGGATTATTATAGCTTCTGATCGGTTT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64254ff8-e926-4805-8b3d-029683931daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b2.\n",
    "print(dna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077ed595-c439-4a27-ac82-98ef08a2da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b3.\n",
    "len(dna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437a561f-b3c3-4700-82b1-8bd64b9d0a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b4.\n",
    "dna.count('AGATCT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef87f5a-46f0-46d8-94bc-446dbff573b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# b5.\n",
    "dna.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad318f3f-aa0c-42f0-886f-9ca32312f273",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bb93b5-a3e2-495c-8bf7-46e902fda176",
   "metadata": {},
   "source": [
    "## Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7611c02-3334-445a-9b6a-35d2638e6c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1.\n",
    "planets = ['Mercury', 'Venus', 'Earth', 'Mars', 'Jupiter', 'Saturn', 'Uranus', 'Neptune']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f19660a-2d51-40da-8de1-2733fe15af09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a2.\n",
    "print(planets)\n",
    "type(planets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b3f767-1445-418a-bfea-92e3ae5c82bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a3.\n",
    "print(planets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb865f8-d79b-4f02-bc9a-99470027f3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a4.\n",
    "print(planets[len(planets) - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d6fa99-4b49-4631-a4e8-f1d232fb6dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a5.\n",
    "print(planets[2::3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d8bcb8-d399-4c63-92d9-5d071b1e90db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a5.\n",
    "print(planets[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1c8441-2e2c-462f-ad1a-4f7da5b8f134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a6.\n",
    "print(sorted(planets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddd8a0f-4475-4d91-bda1-e2eec8ebdaeb",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e395e95d-13cf-4300-a88f-c9bb0433c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b1.\n",
    "elements = {'H': 'Hydrogen',\n",
    "    'Li' : 'Lithium',\n",
    "    'Na' : 'Sodium',\n",
    "    'K' : 'Potassium'\n",
    "}\n",
    "\n",
    "print(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc8da67-7bb9-48b3-a111-409a03ed2bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b2.\n",
    "elements['Na']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0420426a-9bbd-4bce-a111-8a9272f686f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b3.\n",
    "del(elements['H'])\n",
    "elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa72eea-4840-4645-974f-16e2c197b05f",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4d1e74-64c6-4aed-a916-f5710f16155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c1.\n",
    "list(range(1,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ccf91c-00d4-453a-8efd-580d23d30e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c2.\n",
    "list(range(-5, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42873692-c18e-43cd-8540-0129dbd26d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c3.\n",
    "list(range(-5, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df1cacf-b93f-485c-89ac-fcff7aa37cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d1*\n",
    "variety = [planets, elements, range(1,8), range(-5, 4), range(-5, 4)]\n",
    "variety"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2350c1b8-4b29-4019-b9c1-4d768b8a93f6",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ced14e-96b4-4c48-8a5a-bb2cc051ff16",
   "metadata": {},
   "source": [
    "## Exercise 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592a600a-fe44-41fd-9a21-b7ea0f6ff2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1.\n",
    "import pandas as pd\n",
    "\n",
    "buildings = pd.Series([2717, 2227, 2073])\n",
    "buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f695c5d-e86d-4a92-bd84-feb4b91b84c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a2.\n",
    "buildings.index = ['Burj', 'Merdeka', 'Shanghai']\n",
    "buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9526e3ac-c9d6-4b08-b058-cc919e6e44f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a3.\n",
    "buildings = buildings / 3.281\n",
    "buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0afa78-0c63-4cd7-b05a-9e3cb50ed6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a4.\n",
    "buildings.index.name = 'height_m'\n",
    "buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1349067-cdbf-48b8-a3d8-1240d2423222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a5.\n",
    "buildings > 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b56bdc4-8cd8-420f-a09a-592e59186ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a6.\n",
    "antennas = pd.Series({'Merdeka' : 10, 'Burj' : 5, 'Shanghai' : 12})\n",
    "antennas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f06199-aa66-458e-901e-ab21112cf188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a7.\n",
    "buildings + antennas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a9d4f3-5d52-42ba-a298-4f2684011450",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6f5304-4180-46b6-b1c8-9e36b7a2c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b1.\n",
    "forename = pd.Series(['Joel', 'Abby', 'Ellie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60bb9bc-315b-48d4-82ee-c6a023002825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b2.\n",
    "surname = pd.Series(['Miller', 'Anderson'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92604141-23e9-451d-a268-091776b7b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b3.\n",
    "fullname = forename + surname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5db0d7-5a07-416c-a649-47cd74ddc7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b4.\n",
    "print(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cd8c57-4dff-4cda-8dc8-d3c78543b3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b5.\n",
    "fullname.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edef531-1a2b-46e3-91e2-5e796503406b",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11692d9b-ebd2-4f93-95ec-72f33a994cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *c1.\n",
    "pd.Series(range(9, (9*101), 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285e31d2-5e26-4d74-aab4-3aa4765a98bd",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9793fdd2-ec95-4412-8a73-52b6f59097f7",
   "metadata": {},
   "source": [
    "## Exercise 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a2c1cd-e987-45a3-8e09-82016ccc2be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1.\n",
    "heights = pd.DataFrame({'height' : buildings, 'antenna' : antennas})\n",
    "heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cda732-f463-43c0-a2d5-106c674e5e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a2.\n",
    "heights['antenna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca160ce8-9f01-4398-8b72-ad57cc99b171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a3.\n",
    "heights.loc['Burj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95623135-bbd6-4a87-92b8-ec62283a91b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a4.\n",
    "heights.loc[[False, True, False]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0638a1-28ed-423f-a22a-5ecbdf2b905f",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f966f8b-b7d8-4a3e-827e-1f4fcc1d8ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b1.\n",
    "import seaborn as sns\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac875eb4-73d8-4481-8a13-bce7e6b369f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b2.\n",
    "titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e070ebd-c4b7-4fa9-8c82-d854358291db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b3.\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2119b3-2687-4889-b0ff-ac6a66db608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b4.\n",
    "titanic.loc[:, 'age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6bd92d-4708-4fd4-95ce-37157bee30cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b5.\n",
    "titanic.loc[:, ['class', 'embark_town']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab38e16f-2878-4857-a33a-d31ca6ef158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b6.\n",
    "titanic.loc[:, 'adult_male':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ef622f-edd7-42d2-909a-2d484cc94863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b7.\n",
    "titanic.loc[886:, 'adult_male':]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acd2028-a4b7-4cab-9676-e5138c91f4f9",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a18a227-1abf-4a9e-9cd2-a2db55cc0aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# c1.\n",
    "fish = pd.read_csv('course_exercises_data/Biomass_of_Herbivorous_Fish.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c190769-3a35-42a4-b659-8957c1ad3798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c2.\n",
    "fish.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c74f92-8642-4a23-b53c-7ad2a1a0ff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c2.\n",
    "fish.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bf4f26-33b4-41c0-9f1e-a987b09a0544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c3.\n",
    "fish.iloc[:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d1e803-ca8c-4bb2-abe9-6a562a3c6000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c4\n",
    "fish.iloc[1, [2, 4, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcf9c4e-b0d6-448d-9c86-5e8b0c9e9bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c5\n",
    "fish.iloc[-1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886256d0-3143-4d8a-ab97-e04d835155a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c6\n",
    "fish['Shallow.Percentage'] = 0\n",
    "fish.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf4b2c2-8cea-4514-83fb-928697b7f058",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff8d99f-ebc7-4f53-b348-9df9cea119d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *d1.\n",
    "league_table = pd.read_csv('course_exercises_data/Premier_League_Final_Table_1999.txt', sep='|')\n",
    "league_table['GD'] = league_table['GF'] - league_table['GA']\n",
    "league_table['Pts'] = (league_table['W'] * 3) +  league_table['D']\n",
    "league_table.to_excel('Premier_League_Final_Table_1999.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd1aac4-54ec-4c5e-8c9c-4ca112e3beec",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bd4695-46f8-49d9-af5a-397f8f42cfea",
   "metadata": {},
   "source": [
    "## Exercise 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7088c1a7-a123-4820-9b5e-b2b817d3e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1.\n",
    "fish = pd.read_csv('course_exercises_data/Biomass_of_Herbivorous_Fish.tsv', sep='\\t')\n",
    "fish = fish.sort_values('Deep.Mean.Biomass')\n",
    "fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5512900-af10-4d38-8ab8-b2791a385ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a2.\n",
    "fish = fish.sort_values('Deep.Mean.Biomass', ascending=False)\n",
    "fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102c2f84-0518-48f5-8428-c4b9fc5194ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a3.\n",
    "fish = fish.sort_values(['Family', 'Deep.Mean.Biomass'], ascending=[True, False])\n",
    "fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9a023-3478-41d6-904a-d66d2dad8785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a4.\n",
    "fish['Shallow.Percentage'].rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3959956b-5fc9-4b88-9437-f10e8c3ec7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a5.\n",
    "fish['Deep.Percentage'] = fish['Deep.Percentage'] / 100\n",
    "fish['Shallow.Percentage'] = fish['Shallow.Percentage'] / 100\n",
    "fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834fb173-7eb6-4193-813a-14038805c456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a6.\n",
    "fish = fish.rename(mapper={'Deep.Percentage' : 'Deep.Proportion', 'Shallow.Percentage' : 'Shallow.Proportion'}, axis=1)\n",
    "fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37940368-6f1a-449d-83a0-882571c842c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a7.\n",
    "fish = fish.round(1)\n",
    "fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf74952-d311-40e4-b7dd-5fd1aa1cdcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a8.\n",
    "fish['Deep.Shallow.Ratio'] = fish['Deep.Mean.Biomass'] / fish['Shallow.Mean.Biomass']\n",
    "fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a733529-baca-4b74-af73-24fa222be4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a9.\n",
    "family = fish['Family'].drop_duplicates()\n",
    "family"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ea908e-d41e-4c87-8efd-3a7212fff8dd",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1098b641-ff33-4dff-a9bc-503da26ca7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b1.\n",
    "indoor_hobbies = pd.read_csv('course_exercises_data/Childrens_Indoor_Hobbies_During_Lockdown.csv')\n",
    "indoor_hobbies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9293dc02-a84c-4e6f-81f4-e55540b1a1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b2.\n",
    "filt = indoor_hobbies['Number'] > 100\n",
    "popular_indoor_hobbies = indoor_hobbies[filt]\n",
    "popular_indoor_hobbies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd13e3f-8100-4503-806d-beb20245d185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b3.\n",
    "filt = (indoor_hobbies['Number'] > 50) & (indoor_hobbies['Number'] < 100)\n",
    "fair_indoor_hobbies = indoor_hobbies[filt]\n",
    "fair_indoor_hobbies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daef4c38-4e7b-452c-9a8d-399281641603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b4.\n",
    "filt = ~filt\n",
    "other_indoor_hobbies = indoor_hobbies[filt]\n",
    "other_indoor_hobbies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21922fa0-d027-486c-8c7a-558a4d6d1dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b5.\n",
    "indoor_hobbies.query('Hobby == \"Computer\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3102660c-c6fc-4489-aa3a-5793f9b72a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b6.\n",
    "lookup = ['Lego', 'Toys', 'Puzzles and Games', 'Buckaroo']\n",
    "filt = indoor_hobbies['Hobby'].isin(lookup)\n",
    "indoor_hobbies[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3b8cfa-1ba8-4821-9dd3-ed40f2596de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b7.\n",
    "filt = indoor_hobbies['Hobby'].str.contains('Video')\n",
    "indoor_hobbies[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35a4686-7023-4ac2-9761-53ed3acce426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b8.\n",
    "indoor_hobbies = indoor_hobbies.drop('Percent', axis=1)\n",
    "indoor_hobbies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931170f1-34d9-4d17-92e6-efffef3106f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c18c497-8617-46cd-a901-cbf1aa419d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1. \n",
    "fish = pd.read_csv('course_exercises_data/Biomass_of_Herbivorous_Fish.tsv', sep='\\t')\n",
    "fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6288aafa-faa1-4a40-96e5-4ffc565ae009",
   "metadata": {},
   "outputs": [],
   "source": [
    "fish.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae4dc92-dfb8-4976-a233-a94c588d303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a2.\n",
    "fish.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6ffb15-d746-4134-8c32-8a58d5cdc81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fish.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e53d0d-8ce9-4a48-a06e-115db2e55d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a3.\n",
    "fish['Morpho.Functional.Group'] = fish['Morpho.Functional.Group'].str.replace('ivore', '')\n",
    "fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8298470-274d-4b12-9ff8-a796809cd8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a4.\n",
    "fish['Morpho.Functional.Group'] = fish['Morpho.Functional.Group'].replace({'Detrit' : 'D', 'Alg' : 'A', 'Omn' : 'O'})\n",
    "fish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70abd9f-8781-410a-930c-75800ea9e7b1",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b337e3-79ff-4436-9dc0-333be23cf7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b1.\n",
    "indoor_hobbies = pd.read_csv('course_exercises_data/Childrens_Indoor_Hobbies_During_Lockdown.csv')\n",
    "indoor_hobbies = indoor_hobbies.sort_values('Number', ascending=False)\n",
    "indoor_hobbies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6ffb74-26f7-45e2-962f-c991d6506e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "indoor_hobbies = indoor_hobbies.reset_index(drop=True)\n",
    "indoor_hobbies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a908ff18-e7f1-4444-bfaf-9d9eb819b0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b2.\n",
    "indoor_hobbies['Number'].apply(bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4452f614-bc6d-49c8-9fe9-aeaf44744e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b3.\n",
    "indoor_hobbies.index = (indoor_hobbies['Hobby'].str.replace(' ', '_')\n",
    "                                                  .str.replace('/', '_')\n",
    "                                                  .str.replace('_&_', '_')\n",
    ")\n",
    "                                    \n",
    "indoor_hobbies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1b27af-05e5-44c1-bcd8-3a9db861363f",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a38bde0-8fc7-4bf9-ad9d-d5076255ac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *c1.\n",
    "def tidy_text(text):\n",
    "    text = text.replace(' ', '_')\n",
    "    text = text.replace('/', '_')\n",
    "    text = text.replace('_&_', '_') \n",
    "    return(text)\n",
    "\n",
    "indoor_hobbies['Hobby'] = indoor_hobbies['Hobby'].apply(tidy_text)\n",
    "indoor_hobbies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c63fa12-18db-4b12-b1c9-b7774bb9f516",
   "metadata": {},
   "source": [
    "## Exercise 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a376dd4-58d2-4fe7-a17a-90120d8e8c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1.\n",
    "brain_body = pd.read_csv('course_exercises_data/Brain_Bodyweight_Data.tsv', sep='\\t')\n",
    "metadata = pd.read_csv('course_exercises_data/Brain_Bodyweight_Metadata.tsv', sep='\\t')\n",
    "\n",
    "print(brain_body.head(2))\n",
    "print()\n",
    "print(metadata.head(2))\n",
    "print()\n",
    "print(brain_body.describe())\n",
    "print()\n",
    "print(metadata.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ea558f-032f-42c8-bd70-a1ad6210b1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a2.\n",
    "brain_body = pd.merge(brain_body, metadata, how='left', on='Species')\n",
    "brain_body.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed01b9b5-5d79-4a5b-8a41-2a06e33e8b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a3.\n",
    "brain_body['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef7e35c-7709-4de6-8515-f33c0a567010",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c030f01e-61a9-4d3f-85e7-b56ca240e232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b1.\n",
    "hobbies_indoor = pd.read_csv('course_exercises_data/Childrens_Indoor_Hobbies_During_Lockdown.csv')\n",
    "hobbies_outdoor = pd.read_csv('course_exercises_data/Childrens_Outdoor_Hobbies_During_Lockdown.csv')\n",
    "\n",
    "print(hobbies_indoor.head(2))\n",
    "print()\n",
    "print(hobbies_outdoor.head(2))\n",
    "\n",
    "hobbies = pd.concat([hobbies_indoor, hobbies_outdoor], axis=0)\n",
    "hobbies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8194c839-363a-48cd-b11a-451c6ead9c81",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd7ce04-d6d6-475b-8ddd-6574052d3d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c1.\n",
    "exercise = sns.load_dataset('exercise')\n",
    "print(exercise.head())\n",
    "print()\n",
    "\n",
    "exercise_grouped = exercise.groupby(by='kind')\n",
    "print(exercise_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133d10d9-a921-49a2-9bfc-a879fc29eb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c2.\n",
    "exercise_grouped.mean()['pulse']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2707388e-e5aa-40c3-b31a-2c54cad3e280",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221e57fc-cc74-4f7d-b735-077254479932",
   "metadata": {},
   "source": [
    "## Exercise 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f9a7c-5112-4bed-a02f-bb7b59dae2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1.\n",
    "cuttlefish = pd.read_csv('course_exercises_data/Cuttlefish_Buoyancy.tsv', sep='\\t')\n",
    "cuttlefish = cuttlefish.loc[:, ['ID', 'treatment', 'hatching_date', 'days_until_sampling',  'floating', 'density']]\n",
    "cuttlefish[['hatching_day', 'hatching_month', 'hatching_year']] = cuttlefish['hatching_date'].str.split('.', expand=True)\n",
    "cuttlefish = cuttlefish.drop('hatching_date', axis=1)\n",
    "\n",
    "cuttlefish.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b893b6c0-180f-43ae-b3f2-f8ae777f3ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a2.\n",
    "cuttlefish['ID'] =  cuttlefish['ID'] + cuttlefish['treatment']\n",
    "cuttlefish.drop('treatment', axis=1, inplace=True)    # Notice inplace\n",
    "cuttlefish.tail()   # Used tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c1efa9-29b6-49a1-b680-a61db45ab42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a3.\n",
    "cuttlefish = cuttlefish.transpose()    # Transpose\n",
    "cuttlefish.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b166ac-5787-40b9-a9d0-4591c18d303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuttlefish = cuttlefish.transpose()   # Transpose back\n",
    "cuttlefish.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4846ed6a-10db-40f1-83c3-870dbbd87785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a4.\n",
    "cuttlefish = pd.melt(cuttlefish, id_vars='ID', var_name='Metric', value_name='Value')\n",
    "cuttlefish.to_excel('cuttlefish.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a30890-2f5a-4414-861d-2b6905037bc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a5.\n",
    "cuttlefish = cuttlefish.pivot(index='ID', columns='Metric', values='Value')\n",
    "cuttlefish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7badb83e-57bc-4f77-be29-ce7794fe9138",
   "metadata": {},
   "source": [
    "## Exercise 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55ab264-1349-437e-89b7-4b5dd88af098",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a1.\n",
    "import numpy as np\n",
    "\n",
    "brain_body = pd.read_csv('course_exercises_data/Brain_Bodyweight_Data.tsv', sep='\\t')\n",
    "brain_body['Log2.Body.Weight.kg'] = np.log2(brain_body['Body.Weight.kg'])\n",
    "brain_body['Log2.Brain.Weight.g'] = np.log2(brain_body['Brain.Weight.g'])\n",
    "brain_body.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807df0ff-101a-4177-b76e-1873a1cb1fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a2.\n",
    "brain_body['Body.Weight.Classification'] =  np.where(brain_body['Body.Weight.kg'] < 10, 'Small', 'Not_Small')   # Alternative responses\n",
    "brain_body.to_csv('brain_body_classification.csv', index=False)   # Look as file to see results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395c8fa1-5e2c-4596-970b-67a6a401a3d9",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed852624-70b1-4b17-a2ad-aa7b36514d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *c1.\n",
    "from scipy.stats import fisher_exact\n",
    "\n",
    "trial_results = pd.DataFrame([[41, 59], [62, 38]])\n",
    "trial_results.columns = ['Cured', 'Not_Cured']\n",
    "trial_results.index = ['Drug_A', 'Drug_B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c22ba9-4ab0-4afa-ac14-41cf828ba527",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dfb823-8681-453f-8e43-43c0cd3f7b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fishers_results = fisher_exact(trial_results, alternative='two-sided')\n",
    "p_value = fishers_results[1]\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8072e178-8e5a-49c5-8b9b-d96a7b791672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Therefore, the drugs DO perform differently (p < 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d55b07a-c099-496f-9521-f8d523d23857",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683b3bcf-c47c-4927-8bc6-8bb4708eac27",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1adf27a-0441-418f-bec6-25f7404722b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset to default plot sizes before starting exercises\n",
    "plt.rcParams[\"figure.figsize\"] = [6.4, 4.8]\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9050347c-01a5-4b5f-b62c-169e964a02db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1.\n",
    "oxygen = pd.read_csv('course_exercises_data/Biochemical_Oxygen_Demand.tsv', sep='\\t')\n",
    "print(oxygen)\n",
    "oxygen.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57c1057-79e7-4a82-aab1-b58008dba338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a2.\n",
    "oxygen.plot.bar(x='Time', y='Demand')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423ce202-6a77-4978-80d4-f267032beac9",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dace54e-3bc1-4861-aca1-1e57ea9076c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b1.\n",
    "brain_body = pd.read_csv('brain_body_classification.csv')\n",
    "sns.scatterplot(data=brain_body, x='Log2.Body.Weight.kg', y='Log2.Brain.Weight.g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c881141-800d-4d65-8f47-7865d7cdb97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b2.\n",
    "sns.set_theme(style=\"dark\")\n",
    "\n",
    "sns.scatterplot(data=brain_body, \n",
    "                x='Log2.Body.Weight.kg', \n",
    "                y='Log2.Brain.Weight.g',\n",
    "                hue='Body.Weight.Classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704efffc-cd40-4098-a688-f017dbea72a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b3.\n",
    "brain_body_metadata = pd.read_csv('course_exercises_data/Brain_Bodyweight_Metadata.tsv', sep='\\t')\n",
    "brain_body = pd.merge(brain_body_metadata, brain_body, how='right', on='Species') \n",
    "\n",
    "sns.scatterplot(data=brain_body, \n",
    "                x='Log2.Body.Weight.kg', \n",
    "                y='Log2.Brain.Weight.g',\n",
    "                hue='Body.Weight.Classification',\n",
    "                style='Category'\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec73f13-b747-4423-98f9-d7235745174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b4.\n",
    "g = sns.FacetGrid(brain_body, col=\"Category\")\n",
    "g.map_dataframe(sns.scatterplot, x=\"Log2.Body.Weight.kg\", y=\"Log2.Brain.Weight.g\")\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b831bb27-4762-49f4-84db-d9c4cd48e82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b5.\n",
    "g.savefig(fname='brain_body_facet.svg', format='svg', bbox_inches='tight', pad_inches=0.5)\n",
    "g.savefig(fname='brain_body_facet.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd38df67-d168-4c11-a787-d38969e7e2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b6.\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(brain_body,\n",
    "                    x='Log2.Body.Weight.kg', \n",
    "                    y='Log2.Brain.Weight.g',\n",
    "                    hover_name='Species',\n",
    "                )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d244ae-3f05-4ccf-b210-2ef247fbedac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *c1.\n",
    "norm_vals = np.random.normal(5.0, 1.5, 1000)    # Mean, STD, count\n",
    "norm_vals = pd.DataFrame(norm_vals)\n",
    "norm_vals.hist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
